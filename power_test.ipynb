{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Sample data\n",
    "X = np.random.rand(100, 3)\n",
    "\n",
    "# Fit PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "pt.fit(X)\n",
    "\n",
    "# Extract mean and scale from internal scaler\n",
    "mean_ = pt._scaler.mean_ if pt.standardize else None\n",
    "scale_ = pt._scaler.scale_ if pt.standardize else None\n",
    "\n",
    "# Save parameters to JSON\n",
    "params = {\n",
    "    \"lambdas_\": pt.lambdas_.tolist(),\n",
    "    \"method\": pt.method,\n",
    "    \"standardize\": pt.standardize,\n",
    "    \"mean_\": mean_.tolist() if mean_ is not None else None,\n",
    "    \"scale_\": scale_.tolist() if scale_ is not None else None\n",
    "}\n",
    "\n",
    "with open(\"power_transformer.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambdas_': [1.0957269930914402, 0.16103114021457582, 0.8917440342075538], 'method': 'yeo-johnson', 'standardize': True, 'mean_': [0.5424843776882878, 0.4065247845865687, 0.49068613184211896], 'scale_': [0.31042067075899316, 0.2053735423582608, 0.26530396805464357]}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"power_transformer.json\", \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Reconstruct PowerTransformer\n",
    "pt_loaded = PowerTransformer(method=params[\"method\"], standardize=params[\"standardize\"])\n",
    "pt_loaded.lambdas_ = np.array(params[\"lambdas_\"])\n",
    "\n",
    "# Restore internal scaler manually if standardization was used\n",
    "if params[\"standardize\"]:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    pt_loaded._scaler = StandardScaler()\n",
    "    pt_loaded._scaler.mean_ = np.array(params[\"mean_\"])\n",
    "    pt_loaded._scaler.scale_ = np.array(params[\"scale_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85029321, -0.07945715,  0.65010851],\n",
       "       [-1.49901919,  1.39220997,  0.65681734],\n",
       "       [-0.17317181, -1.41002437,  0.16703102],\n",
       "       [ 1.49792261,  0.91257639,  0.07502139],\n",
       "       [-0.88791432,  1.51986243, -1.28204888]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.random.rand(5, 3)\n",
    "pt_loaded.transform(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
