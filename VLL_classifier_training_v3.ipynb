{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:39:36.665684: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 10:39:38.490096: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 10:39:38.707927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748453978.997277 3581025 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748453979.277744 3581025 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748453980.627853 3581025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453980.627906 3581025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453980.627913 3581025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453980.627920 3581025 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 10:39:40.702151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Scikit-learn for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventReader:\n",
    "    \"\"\"Handles reading and preprocessing of particle physics event data.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "        # Define feature lists to read from files - KEEP ORIGINAL FEATURES\n",
    "        self.file_electron_features_list = [\n",
    "            'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2',\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "\n",
    "        # Define feature lists based on README\n",
    "        self.electron_features_list = [\n",
    "            'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2',\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "        \n",
    "        self.photon_features_list = [\n",
    "            'photon_pt', 'photon_eta', 'photon_phi',\n",
    "            'photon_time',\n",
    "            'photon_maxEcell_E',\n",
    "            'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "            'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "        ]\n",
    "\n",
    "        # Group electron features by type\n",
    "        self.electron_feature_groups = {\n",
    "            'kinematics': [0],         # E, pt - positive valued, potentially skewed\n",
    "            'angles': [1, 2],             # eta, phi - special circular treatment\n",
    "            'time': [3],                  # time - potentially outlier-sensitive\n",
    "            'track_params': [4, 5, 6],    # d0, z0, dpt - potentially outlier-sensitive\n",
    "            'count_data': [7, 8],         # nPIX, nMissingLayers - discrete values\n",
    "            'quality': [9],              # chi2_over_nDoF - potentially skewed\n",
    "            'shower_shape': [10, 11],     # f1, f3 - shape, ratios, potentially saturated\n",
    "            'position': [12]              # z - potentially normal distribution\n",
    "        }\n",
    "        \n",
    "        # Group photon features by type\n",
    "        self.photon_feature_groups = {\n",
    "            'kinematics': [0],         # E, pt - positive valued, potentially skewed\n",
    "            'angles': [1, 2],             # eta, phi - special circular treatment\n",
    "            'time': [3],                  # time - potentially outlier-sensitive\n",
    "            'energy_cell': [4],           # maxEcell_E - potentially skewed  \n",
    "            'shower_shape': [5, 6, 7, 8, 9, 10],  # f1, f3, r1, r2, etas1, phis1\n",
    "            'position': [11]              # z - potentially normal distribution\n",
    "        }\n",
    "\n",
    "        # Initialize scalers for each group\n",
    "        self.initialize_scalers()\n",
    "\n",
    "        # Load and preprocess all data\n",
    "        self.load_all_data()\n",
    "    def initialize_scalers(self):\n",
    "        \"\"\"Initialize specialized scalers for each feature group.\"\"\"\n",
    "        # Electron scalers\n",
    "        self.electron_scalers = {\n",
    "            'kinematics': PowerTransformer(method='yeo-johnson', standardize=True),  # For positive, skewed data\n",
    "            'angles': MinMaxScaler(feature_range=(-1, 1)),        # For angular variables\n",
    "            'time': RobustScaler(),                               # Handle outliers\n",
    "            'track_params': RobustScaler(),                       # Handle outliers\n",
    "            'count_data': StandardScaler(),                       # For discrete data\n",
    "            'quality': PowerTransformer(method='yeo-johnson', standardize=True),  # For skewed data\n",
    "            'shower_shape': StandardScaler(),                     # For shape data\n",
    "            'position': StandardScaler()                          # For positions\n",
    "        }\n",
    "        \n",
    "        # Photon scalers\n",
    "        self.photon_scalers = {\n",
    "            'kinematics': PowerTransformer(method='yeo-johnson', standardize=True),  # For positive, skewed data\n",
    "            'angles': MinMaxScaler(feature_range=(-1, 1)),        # For angular variables\n",
    "            'time': RobustScaler(),                               # Handle outliers\n",
    "            'energy_cell': PowerTransformer(method='yeo-johnson', standardize=True),  # For energy, likely skewed\n",
    "            'shower_shape': StandardScaler(),                     # For shape data\n",
    "            'position': StandardScaler()                          # For positions\n",
    "        }\n",
    "        \n",
    "        # Vertex scalers (simple case - 3 features)\n",
    "        self.vertex_scaler = StandardScaler()\n",
    "        \n",
    "    def load_all_data(self, max_files=70):\n",
    "        \"\"\"Load and preprocess data from HDF5 files.\"\"\"\n",
    "        print(\"Loading all data...\")\n",
    "        \n",
    "        # Initialize as None for first file\n",
    "        self.electron_features = None\n",
    "        self.photon_features = None\n",
    "        self.vertex_features = None\n",
    "        \n",
    "        file_count = 0\n",
    "        \n",
    "        for file_path in self.data_dir.glob(\"*.h5\"):\n",
    "            if file_count >= max_files:\n",
    "                break\n",
    "                \n",
    "            with h5py.File(file_path, 'r', rdcc_nbytes=10*1024*1024) as f:\n",
    "                n_events = len(f['events/PV_x'])\n",
    "                print(f\"Processing {file_path.name}: {n_events} events\")\n",
    "                \n",
    "                # Load all data at once\n",
    "                electrons = {feat: f[f'events/electrons/{feat}'][:] for feat in self.file_electron_features_list}\n",
    "                photons = {feat: f[f'events/photons/{feat}'][:] for feat in self.photon_features_list}\n",
    "                vertices = np.stack([\n",
    "                    f['events/PV_x'][:],\n",
    "                    f['events/PV_y'][:],\n",
    "                    f['events/PV_z'][:]\n",
    "                ], axis=1)\n",
    "                \n",
    "                # Process all events at once\n",
    "                e_mask = (electrons['electron_pt'] > 0) & (f[f'events/electrons/electron_isIsolated_Loose_VarRad'][:] == 0)\n",
    "                p_mask = (photons['photon_pt'] > 0) & (f[f'events/photons/photon_isIsolated_FixedCutLoose'][:] == 0)\n",
    "\n",
    "                # Initialize arrays for all events\n",
    "                e_feats = np.zeros((n_events, 4, len(self.electron_features_list)))\n",
    "                p_feats = np.zeros((n_events, 4, len(self.photon_features_list)))\n",
    "                \n",
    "                # Process all events at once\n",
    "                for feat_idx, feat in enumerate(self.electron_features_list):\n",
    "                    e_feats[..., feat_idx] = electrons[feat]\n",
    "                        \n",
    "                    e_feats[..., feat_idx] = np.where(e_mask, e_feats[..., feat_idx], 0)  # Zero out electrons failing selection\n",
    "                \n",
    "                for feat_idx, feat in enumerate(self.photon_features_list):\n",
    "                    p_feats[..., feat_idx] = photons[feat]\n",
    "                    p_feats[..., feat_idx] = np.where(p_mask, p_feats[..., feat_idx], 0)\n",
    "\n",
    "                # Apply event filtering: Require at least two objects\n",
    "                electron_count = np.sum(e_feats[:, :, 0] > 0, axis=1)\n",
    "                photon_count = np.sum(p_feats[:, :, 0] > 0, axis=1)\n",
    "                total_count = electron_count + photon_count\n",
    "\n",
    "                # Create mask for events with at least 2 objects\n",
    "                valid_events = total_count >= 2\n",
    "                \n",
    "                # Apply the filter\n",
    "                e_feats = e_feats[valid_events]\n",
    "                p_feats = p_feats[valid_events]\n",
    "                vertices = vertices[valid_events]\n",
    "\n",
    "                # Add to main arrays\n",
    "                if self.electron_features is None:\n",
    "                    self.electron_features = e_feats\n",
    "                    self.photon_features = p_feats\n",
    "                    self.vertex_features = vertices\n",
    "                else:\n",
    "                    self.electron_features = np.concatenate([self.electron_features, e_feats])\n",
    "                    self.photon_features = np.concatenate([self.photon_features, p_feats])\n",
    "                    self.vertex_features = np.concatenate([self.vertex_features, vertices])\n",
    "                \n",
    "                file_count += 1\n",
    "                print(f\"Processed {file_count} files, total events: {len(self.electron_features):,}\")\n",
    "        \n",
    "        print(f\"\\nFinal dataset:\")\n",
    "        print(f\"Total files processed: {file_count}\")\n",
    "        print(f\"Total events: {len(self.electron_features):,}\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")\n",
    "        \n",
    "        # Fit and apply specialized scalers\n",
    "        print(\"\\nFitting and applying specialized scalers...\")\n",
    "        self._fit_transform_features()\n",
    "\n",
    "        print(f\"Final dataset: {len(self.electron_features):,} events\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")    \n",
    "        \n",
    "    def _fit_transform_features(self):\n",
    "        \"\"\"Fit and transform features using specialized scalers.\"\"\"\n",
    "        # Create working copies to avoid modifying originals during processing\n",
    "        e_feats_transformed = self.electron_features.copy()\n",
    "        p_feats_transformed = self.photon_features.copy()\n",
    "        \n",
    "        # Process electron features by group\n",
    "        for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.electron_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Fit and transform all features in the group together\n",
    "            transformed_values = self.electron_scalers[group_name].fit_transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.electron_features.shape[0], self.electron_features.shape[1]\n",
    "                )\n",
    "                e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # Process photon features by group\n",
    "        for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.photon_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Fit and transform all features in the group together\n",
    "            transformed_values = self.photon_scalers[group_name].fit_transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.photon_features.shape[0], self.photon_features.shape[1]\n",
    "                )\n",
    "                p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # For vertices, simple standard scaling\n",
    "        self.vertex_features = self.vertex_scaler.fit_transform(self.vertex_features)\n",
    "        \n",
    "        # Update features with transformed versions\n",
    "        self.electron_features = e_feats_transformed\n",
    "        self.photon_features = p_feats_transformed\n",
    "    \n",
    "    def transform_new_data(self, electron_features, photon_features, vertex_features):\n",
    "        \"\"\"Transform new data using fitted scalers.\"\"\"\n",
    "        # Create working copies\n",
    "        e_feats_transformed = electron_features.copy()\n",
    "        p_feats_transformed = photon_features.copy()\n",
    "        \n",
    "        # Process electron features by group\n",
    "        for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                electron_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.electron_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    electron_features.shape[0], electron_features.shape[1]\n",
    "                )\n",
    "                e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # Process photon features by group\n",
    "        for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                photon_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.photon_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    photon_features.shape[0], photon_features.shape[1]\n",
    "                )\n",
    "                p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # For vertices, simple standard scaling\n",
    "        v_feats_transformed = self.vertex_scaler.transform(vertex_features)\n",
    "        \n",
    "        return e_feats_transformed, p_feats_transformed, v_feats_transformed\n",
    "    \n",
    "    def get_train_val_test_split(self, val_size=0.33, test_size=0.33, shuffle=True):\n",
    "        \"\"\"Split data into train, validation, and test sets.\"\"\"\n",
    "        indices = np.arange(len(self.vertex_features))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        # Calculate split points\n",
    "        test_split = int(len(indices) * (1 - test_size))\n",
    "        val_split = int(len(indices) * (1 - test_size - val_size))\n",
    "        \n",
    "        # Split indices\n",
    "        train_idx = indices[:val_split]\n",
    "        val_idx = indices[val_split:test_split]\n",
    "        test_idx = indices[test_split:]\n",
    "        \n",
    "        # Create split datasets\n",
    "        train_data = (\n",
    "            self.electron_features[train_idx],\n",
    "            self.photon_features[train_idx],\n",
    "            self.vertex_features[train_idx]\n",
    "        )\n",
    "        \n",
    "        val_data = (\n",
    "            self.electron_features[val_idx],\n",
    "            self.photon_features[val_idx],\n",
    "            self.vertex_features[val_idx]\n",
    "        )\n",
    "        \n",
    "        test_data = (\n",
    "            self.electron_features[test_idx],\n",
    "            self.photon_features[test_idx],\n",
    "            self.vertex_features[test_idx]\n",
    "        )\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "        \n",
    "    def save_scalers(self, output_dir):\n",
    "        \"\"\"Save scaler parameters for later use.\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save electron scalers\n",
    "        electron_scaler_params = {}\n",
    "        for group_name, scaler in self.electron_scalers.items():\n",
    "            # Save relevant parameters based on scaler type\n",
    "            params = {}\n",
    "            # Save scaler type\n",
    "            params['type'] = scaler.__class__.__name__\n",
    "            # Save feature indices this scaler applies to\n",
    "            params['feature_indices'] = self.electron_feature_groups[group_name]\n",
    "            \n",
    "            # Add parameters specific to each scaler type\n",
    "            if isinstance(scaler, StandardScaler):\n",
    "                params['mean'] = scaler.mean_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, RobustScaler):\n",
    "                params['center'] = scaler.center_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, MinMaxScaler):\n",
    "                params['feature_range'] = scaler.feature_range\n",
    "                params['min_'] = scaler.min_.tolist()\n",
    "                params['scale_'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, PowerTransformer):\n",
    "                params['lambdas'] = scaler.lambdas_.tolist()\n",
    "                params['method'] = scaler.method\n",
    "                params['standardize'] = scaler.standardize\n",
    "                if scaler.standardize:\n",
    "                    params['mean'] = scaler._scaler.mean_.tolist()\n",
    "                    params['scale'] = scaler._scaler.scale_.tolist()\n",
    "\n",
    "            electron_scaler_params[group_name] = params\n",
    "        \n",
    "        # Save photon scalers\n",
    "        photon_scaler_params = {}\n",
    "        for group_name, scaler in self.photon_scalers.items():\n",
    "            # Save relevant parameters based on scaler type\n",
    "            params = {}\n",
    "            # Save scaler type\n",
    "            params['type'] = scaler.__class__.__name__\n",
    "            # Save feature indices this scaler applies to\n",
    "            params['feature_indices'] = self.photon_feature_groups[group_name]\n",
    "            \n",
    "            # Add parameters specific to each scaler type\n",
    "            if isinstance(scaler, StandardScaler):\n",
    "                params['mean'] = scaler.mean_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, RobustScaler):\n",
    "                params['center'] = scaler.center_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, MinMaxScaler):\n",
    "                params['feature_range'] = scaler.feature_range\n",
    "                params['min_'] = scaler.min_.tolist()\n",
    "                params['scale_'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, PowerTransformer):\n",
    "                params['lambdas'] = scaler.lambdas_.tolist()\n",
    "                params['method'] = scaler.method\n",
    "                params['standardize'] = scaler.standardize\n",
    "                if scaler.standardize:\n",
    "                    params['mean'] = scaler._scaler.mean_.tolist()\n",
    "                    params['scale'] = scaler._scaler.scale_.tolist()\n",
    "            \n",
    "            # elif isinstance(scaler, QuantileTransformer):\n",
    "            #     params['quantiles'] = scaler.quantiles_.tolist()\n",
    "            #     params['n_quantiles'] = scaler.n_quantiles_\n",
    "            #     params['output_distribution'] = scaler.output_distribution\n",
    "            #     params['ignore_implicit_zeros'] = scaler.ignore_implicit_zeros\n",
    "            #     params['subsample'] = scaler.subsample\n",
    "            #     params['random_state'] = scaler.random_state if scaler.random_state is not None else None\n",
    "            #     params['references'] = scaler.references_\n",
    "            \n",
    "            photon_scaler_params[group_name] = params\n",
    "        \n",
    "        # Save vertex scaler\n",
    "        vertex_scaler_params = {\n",
    "            'mean': self.vertex_scaler.mean_.tolist(),\n",
    "            'scale': self.vertex_scaler.scale_.tolist(),\n",
    "            'type': self.vertex_scaler.__class__.__name__\n",
    "        }\n",
    "        \n",
    "        # Combine all scaler parameters\n",
    "        scaler_params = {\n",
    "            'electron': electron_scaler_params,\n",
    "            'photon': photon_scaler_params,\n",
    "            'vertex': vertex_scaler_params,\n",
    "            'electron_features_list': self.electron_features_list,\n",
    "            'photon_features_list': self.photon_features_list\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / 'scaler_params_v3.json', 'w') as f:\n",
    "            json.dump(scaler_params, f, indent=2)\n",
    "        \n",
    "        print(f\"Saved scaler parameters to {output_dir / 'scaler_params_v3.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY_ELECTRON = np.array([\n",
    "    -3.74531232e-01, -9.02301235e-03, -1.82138801e-06,  0.,\n",
    "     0.,  0.,  0., -3.40324104e-01, -1.86411055e-01,\n",
    "    -3.74529962e-01, -3.52771470e-01, -2.17548504e-01,  1.68711789e-04\n",
    "], dtype=np.float32)\n",
    "\n",
    "EMPTY_PHOTON = np.array([\n",
    "    -7.93930453e-01, -6.22533163e-05, -2.65618571e-07,  0.,\n",
    "    -3.84318226e-01, -7.16487544e-01, -3.47047918e-01, -7.88056580e-01,\n",
    "    -7.86572037e-01,  1.22903633e-03,  2.37914691e-03,  3.72620130e-04\n",
    "], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:43:44.634162: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "EMPTY_E = tf.constant(EMPTY_ELECTRON, dtype=tf.float32)   # (13,)\n",
    "EMPTY_P = tf.constant(EMPTY_PHOTON , dtype=tf.float32)    # (12,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data...\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000780.trees.h5: 7291 events\n",
      "Processed 1 files, total events: 1,482\n",
      "Processing data_00440499.f1321_m2153_p6000.43297168._000704.trees.h5: 354255 events\n",
      "Processed 2 files, total events: 71,379\n",
      "Processing data_00439607.f1310_m2149_p6000.43297168._000459.trees.h5: 4800 events\n",
      "Processed 3 files, total events: 72,322\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000284.trees.h5: 5337 events\n",
      "Processed 4 files, total events: 73,377\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000461.trees.h5: 183495 events\n",
      "Processed 5 files, total events: 109,484\n",
      "Processing data_00438277.f1307_m2145_p6000.43297168._000628.trees.h5: 200309 events\n",
      "Processed 6 files, total events: 148,735\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000661.trees.h5: 3178 events\n",
      "Processed 7 files, total events: 149,370\n",
      "Processing data_00436169.f1287_m2137_p6000.43297168._000157.trees.h5: 213958 events\n",
      "Processed 8 files, total events: 191,678\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000487.trees.h5: 9654 events\n",
      "Processed 9 files, total events: 193,572\n",
      "Processing data_00437744.f1305_m2142_p6000.43297168._000285.trees.h5: 166725 events\n",
      "Processed 10 files, total events: 226,724\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000785.trees.h5: 6270 events\n",
      "Processed 11 files, total events: 228,222\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000470.trees.h5: 249445 events\n",
      "Processed 12 files, total events: 277,609\n",
      "Processing data_00435831.f1283_m2137_p6000.43297168._000344.trees.h5: 89691 events\n",
      "Processed 13 files, total events: 295,455\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000485.trees.h5: 7988 events\n",
      "Processed 14 files, total events: 296,978\n",
      "Processing data_00440570.f1321_m2153_p6000.43297168._000745.trees.h5: 7728 events\n",
      "Processed 15 files, total events: 298,485\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000101.trees.h5: 174003 events\n",
      "Processed 16 files, total events: 332,814\n",
      "Processing data_00436377.f1287_m2137_p6000.43297168._000671.trees.h5: 12932 events\n",
      "Processed 17 files, total events: 335,285\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000707.trees.h5: 7365 events\n",
      "Processed 18 files, total events: 336,760\n",
      "Processing data_00438446.f1307_m2145_p6000.43297168._000298.trees.h5: 233700 events\n",
      "Processed 19 files, total events: 382,586\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000731.trees.h5: 63837 events\n",
      "Processed 20 files, total events: 395,057\n",
      "Processing data_00429027.r14190_p5449_p6000.43297168._000146.trees.h5: 179176 events\n",
      "Processed 21 files, total events: 436,737\n",
      "Processing data_00439798.f1313_m2149_p6000.43297168._000348.trees.h5: 4952 events\n",
      "Processed 22 files, total events: 437,665\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000755.trees.h5: 8385 events\n",
      "Processed 23 files, total events: 439,344\n",
      "Processing data_00439830.f1310_m2149_p6000.43297168._000576.trees.h5: 367171 events\n",
      "Processed 24 files, total events: 511,834\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000614.trees.h5: 140392 events\n",
      "Processed 25 files, total events: 539,369\n",
      "Processing data_00438219.f1305_m2145_p6000.43297168._000597.trees.h5: 229374 events\n",
      "Processed 26 files, total events: 584,406\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000715.trees.h5: 19103 events\n",
      "Processed 27 files, total events: 588,291\n",
      "Processing data_00428777.r14190_p5449_p6000.43297168._000087.trees.h5: 36015 events\n",
      "Processed 28 files, total events: 598,216\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000383.trees.h5: 13964 events\n",
      "Processed 29 files, total events: 600,998\n",
      "Processing data_00437744.f1305_m2142_p6000.43297168._000053.trees.h5: 3396 events\n",
      "Processed 30 files, total events: 601,716\n",
      "Processing data_00437062.f1294_m2137_p6000.43297168._000119.trees.h5: 3888 events\n",
      "Processed 31 files, total events: 602,498\n",
      "Processing data_00436656.f1294_m2137_p6000.43297168._000325.trees.h5: 6066 events\n",
      "Processed 32 files, total events: 603,692\n",
      "Processing data_00439927.f1310_m2149_p6000.43297168._000751.trees.h5: 162185 events\n",
      "Processed 33 files, total events: 635,632\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000103.trees.h5: 146965 events\n",
      "Processed 34 files, total events: 664,188\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000702.trees.h5: 30925 events\n",
      "Processed 35 files, total events: 670,319\n",
      "Processing data_00436041.f1287_m2137_p6000.43297168._000327.trees.h5: 251203 events\n",
      "Processed 36 files, total events: 720,036\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000401.trees.h5: 38707 events\n",
      "Processed 37 files, total events: 727,748\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000626.trees.h5: 3532 events\n",
      "Processed 38 files, total events: 728,444\n",
      "Processing data_00435854.f1284_m2137_p6000.43297168._000312.trees.h5: 196780 events\n",
      "Processed 39 files, total events: 766,689\n",
      "Processing data_00432180.r14190_p5449_p6000.43297168._000514.trees.h5: 172652 events\n",
      "Processed 40 files, total events: 799,119\n",
      "Processing data_00437898.f1305_m2142_p6000.43297168._000139.trees.h5: 394550 events\n",
      "Processed 41 files, total events: 876,712\n",
      "Processing data_00438234.f1307_m2145_p6000.43297168._000418.trees.h5: 79637 events\n",
      "Processed 42 files, total events: 892,207\n",
      "Processing data_00438234.f1307_m2145_p6000.43297168._000417.trees.h5: 202193 events\n",
      "Processed 43 files, total events: 931,598\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000651.trees.h5: 288264 events\n",
      "Processed 44 files, total events: 988,800\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000624.trees.h5: 3270 events\n",
      "Processed 45 files, total events: 989,442\n",
      "Processing data_00431178.r14190_p5449_p6000.43297168._000239.trees.h5: 125902 events\n",
      "Processed 46 files, total events: 1,012,474\n",
      "Processing data_00431215.r14190_p5449_p6000.43297168._000562.trees.h5: 330198 events\n",
      "Processed 47 files, total events: 1,073,257\n",
      "Processing data_00430341.r14190_p5449_p6000.43297168._000426.trees.h5: 6156 events\n",
      "Processed 48 files, total events: 1,074,628\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000105.trees.h5: 122986 events\n",
      "Processed 49 files, total events: 1,098,901\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000809.trees.h5: 8071 events\n",
      "Processed 50 files, total events: 1,100,521\n",
      "Processing data_00436863.f1294_m2137_p6000.43297168._000749.trees.h5: 1425 events\n",
      "Processed 51 files, total events: 1,100,782\n",
      "Processing data_00439529.f1310_m2149_p6000.43297168._000708.trees.h5: 8396 events\n",
      "Processed 52 files, total events: 1,102,449\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000718.trees.h5: 21361 events\n",
      "Processed 53 files, total events: 1,106,651\n",
      "Processing data_00438481.f1307_m2145_p6000.43297168._000538.trees.h5: 18435 events\n",
      "Processed 54 files, total events: 1,110,275\n",
      "Processing data_00431037.r14190_p5449_p6000.43297168._000235.trees.h5: 273824 events\n",
      "Processed 55 files, total events: 1,160,055\n",
      "Processing data_00430648.r14190_p5449_p6000.43297168._000294.trees.h5: 94321 events\n",
      "Processed 56 files, total events: 1,177,389\n",
      "Processing data_00436354.f1287_m2137_p6000.43297168._000583.trees.h5: 23763 events\n",
      "Processed 57 files, total events: 1,181,989\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000754.trees.h5: 8939 events\n",
      "Processed 58 files, total events: 1,184,018\n",
      "Processing data_00432180.r14190_p5449_p6000.43297168._000511.trees.h5: 276966 events\n",
      "Processed 59 files, total events: 1,236,524\n",
      "Processing data_00437898.f1305_m2142_p6000.43297168._000140.trees.h5: 415881 events\n",
      "Processed 60 files, total events: 1,318,701\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000602.trees.h5: 3333 events\n",
      "Processed 61 files, total events: 1,319,373\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000542.trees.h5: 104819 events\n",
      "Processed 62 files, total events: 1,340,137\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000643.trees.h5: 5222 events\n",
      "Processed 63 files, total events: 1,341,200\n",
      "Processing data_00429697.r14190_p5449_p6000.43297168._000116.trees.h5: 7316 events\n",
      "Processed 64 files, total events: 1,342,662\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000347.trees.h5: 15770 events\n",
      "Processed 65 files, total events: 1,345,780\n",
      "Processing data_00436496.f1294_m2137_p6000.43297168._000320.trees.h5: 191275 events\n",
      "Processed 66 files, total events: 1,383,588\n",
      "Processing data_00430542.r14190_p5449_p6000.43297168._000136.trees.h5: 299091 events\n",
      "Processed 67 files, total events: 1,437,665\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000582.trees.h5: 6631 events\n",
      "Processed 68 files, total events: 1,438,978\n",
      "Processing data_00430536.r14190_p5449_p6000.43297168._000161.trees.h5: 25415 events\n",
      "Processed 69 files, total events: 1,443,724\n",
      "Processing data_00431906.r14190_p5449_p6000.43297168._000282.trees.h5: 146089 events\n",
      "Processed 70 files, total events: 1,471,493\n",
      "\n",
      "Final dataset:\n",
      "Total files processed: 70\n",
      "Total events: 1,471,493\n",
      "Shapes: electrons (1471493, 4, 13), photons (1471493, 4, 12), vertices (1471493, 3)\n",
      "\n",
      "Fitting and applying specialized scalers...\n",
      "Final dataset: 1,471,493 events\n",
      "Shapes: electrons (1471493, 4, 13), photons (1471493, 4, 12), vertices (1471493, 3)\n",
      "Saved scaler parameters to output/scaler_params_v3.json\n"
     ]
    }
   ],
   "source": [
    "# Test data loading and preprocessing\n",
    "data_dir = \"/fs/ddn/sdf/group/atlas/d/hjia625/VLL-DP/VLL_classifier/hdf5_output\"\n",
    "reader = EventReader(data_dir)\n",
    "reader.save_scalers(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/val/test splits\n",
    "train_data, val_data, test_data = reader.get_train_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500307, 4, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electron_features, photon_features, vertices = train_data\n",
    "np.array(electron_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_data_e_v3.npy', electron_features)\n",
    "np.save('train_data_p_v3.npy', photon_features)\n",
    "np.save('train_data_v_v3.npy', vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_electron_features, val_photon_features, val_vertives = val_data\n",
    "np.save('val_data_e_v3.npy', val_electron_features)\n",
    "np.save('val_data_p_v3.npy', val_photon_features)\n",
    "np.save('val_data_v_v3.npy', val_vertives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_electron_features, test_photon_features, test_vertives = test_data\n",
    "np.save('test_data_e_v3.npy', test_electron_features)\n",
    "np.save('test_data_p_v3.npy', test_photon_features)\n",
    "np.save('test_data_v_v3.npy', test_vertives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_huber(y_true, y_pred, empty_vec, delta=20.0):\n",
    "    mask = tf.reduce_any(tf.not_equal(y_true, empty_vec), axis=-1)      # (B,N)\n",
    "    n    = tf.reduce_sum(tf.cast(mask, tf.float32), axis=1)            # (B,)\n",
    "    n    = tf.maximum(n, 1.)\n",
    "\n",
    "    # element-wise Huber\n",
    "    err  = y_true - y_pred\n",
    "    abs_ = tf.abs(err)\n",
    "    quad = 0.5 * tf.square(err)               # |err| â‰¤ delta\n",
    "    lin  = delta * (abs_ - 0.5 * delta)               # |err| > delta\n",
    "    huber = tf.where(abs_ <= delta, quad, lin)    # (B,N,F)\n",
    "\n",
    "    part_loss = tf.reduce_mean(huber, axis=-1)          # (B,N)\n",
    "    part_loss = tf.where(mask, part_loss, 0.)           # zero for empties\n",
    "    event_loss = tf.reduce_sum(part_loss, axis=1) / n   # avg per real particle\n",
    "    return tf.reduce_mean(event_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(jit_compile=True)                 # single XLA-compiled graph\n",
    "def masked_huber_fast(y_t, y_p, empty_vec, delta):\n",
    "    mask   = tf.reduce_any(tf.not_equal(y_t, empty_vec), axis=-1)        # (B,N)\n",
    "    n_real = tf.reduce_sum(tf.cast(mask, y_t.dtype), axis=1)             # (B,)\n",
    "    n_real = tf.maximum(n_real, 1.)\n",
    "\n",
    "    err = y_t - y_p\n",
    "    abs_err = tf.abs(err)\n",
    "    huber = tf.where(abs_err <= delta,\n",
    "                     0.5 * tf.square(err),\n",
    "                     delta * (abs_err - 0.5 * delta))          # (B,N,F)\n",
    "\n",
    "    per_part  = tf.reduce_mean(huber, axis=-1)          # (B,N)\n",
    "    per_part  = tf.where(mask, per_part, 0.)\n",
    "    per_event = tf.reduce_sum(per_part, axis=1) / n_real\n",
    "    return tf.reduce_mean(per_event)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY_E = tf.constant(EMPTY_ELECTRON, tf.float32)\n",
    "EMPTY_P = tf.constant(EMPTY_PHOTON , tf.float32)\n",
    "DELTA   = tf.constant(5.0, tf.float32)                 # keep as tf.constant\n",
    "\n",
    "def e_loss(y_t, y_p): return masked_huber_fast(y_t, y_p, EMPTY_E, DELTA)\n",
    "def p_loss(y_t, y_p): return masked_huber_fast(y_t, y_p, EMPTY_P, DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_network(input_dim, hidden_dim, output_dim):\n",
    "    \"\"\"Create a deep embedding network.\"\"\"\n",
    "    return keras.Sequential([\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(output_dim)\n",
    "    ])\n",
    "\n",
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer encoder block with multi-head attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        attention_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerDecoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer decoder block with multi-head self and cross attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.cross_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.layernorm3 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        self.dropout3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, encoder_outputs):\n",
    "        # Self attention\n",
    "        self_attention_output = self.self_attention(\n",
    "            query=inputs,\n",
    "            key=inputs,\n",
    "            value=inputs\n",
    "        )\n",
    "        self_attention_output = self.dropout1(self_attention_output)\n",
    "        out1 = self.layernorm1(inputs + self_attention_output)\n",
    "        \n",
    "        # Cross attention with encoder outputs\n",
    "        cross_attention_output = self.cross_attention(\n",
    "            query=out1,\n",
    "            key=encoder_outputs,\n",
    "            value=encoder_outputs\n",
    "        )\n",
    "        cross_attention_output = self.dropout2(cross_attention_output)\n",
    "        out2 = self.layernorm2(out1 + cross_attention_output)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        return self.layernorm3(out2 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_features_list = [\n",
    "    'electron_pt', 'electron_eta', 'electron_phi',\n",
    "    'electron_time',\n",
    "    'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "    'electron_nPIX', 'electron_nMissingLayers',\n",
    "    'electron_chi2',\n",
    "    'electron_f1', 'electron_f3', 'electron_z'\n",
    "]\n",
    "\n",
    "photon_features_list = [\n",
    "    'photon_pt', 'photon_eta', 'photon_phi',\n",
    "    'photon_time',\n",
    "    'photon_maxEcell_E',\n",
    "    'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "    'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleTransformer(keras.Model):\n",
    "    \"\"\"Complete transformer model for particle physics data.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_electrons=4,\n",
    "        max_photons=4,\n",
    "        electron_embedding_dim=14,\n",
    "        photon_embedding_dim=12,\n",
    "        vertex_embedding_dim=3,\n",
    "        common_embedding_dim=8,\n",
    "        num_encoder_layers=4,\n",
    "        num_decoder_layers=4,\n",
    "        num_heads=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input embeddings with different dimensions\n",
    "        self.electron_embedding = create_embedding_network(\n",
    "            len(electron_features_list),  # electron feature dim\n",
    "            electron_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.photon_embedding = create_embedding_network(\n",
    "            len(photon_features_list),  # photon feature dim\n",
    "            photon_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.vertex_embedding = create_embedding_network(\n",
    "            3,   # vertex feature dim\n",
    "            vertex_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "              \n",
    "        # Transformer encoder layers\n",
    "        self.encoder_layers = [\n",
    "            TransformerEncoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Transformer decoder layers\n",
    "        self.decoder_layers = [\n",
    "            TransformerDecoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Output projection layers\n",
    "        self.electron_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(electron_features_list))  # electron features\n",
    "        ])\n",
    "        self.photon_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(photon_features_list))  # photon features\n",
    "        ])\n",
    "        \n",
    "    def encode_particles(self, electron_inputs, photon_inputs, vertex_inputs):\n",
    "        # Embed particles\n",
    "        e_embedded = self.electron_embedding(electron_inputs)\n",
    "        p_embedded = self.photon_embedding(photon_inputs)\n",
    "        v_embedded = self.vertex_embedding(vertex_inputs)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = tf.concat([e_embedded, p_embedded, v_embedded], axis=1)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        encoded = combined\n",
    "        intermediates = []\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoded = encoder_layer(encoded)\n",
    "            intermediates.append(encoded)\n",
    "            \n",
    "        return encoded, intermediates\n",
    "        \n",
    "    def decode_particles(self, encoded, encoder_intermediates):\n",
    "        decoded = encoded\n",
    "        \n",
    "        # Pass through decoder layers with corresponding encoder outputs\n",
    "        for decoder_layer, encoder_output in zip(self.decoder_layers, encoder_intermediates):\n",
    "            decoded = decoder_layer(decoded, encoder_output)\n",
    "            \n",
    "        return decoded\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        ei, pi, vi = inputs[\"electron_input\"], inputs[\"photon_input\"], inputs[\"vertex_input\"]\n",
    "\n",
    "        enc, enc_int = self.encode_particles(ei, pi, vi)\n",
    "        dec          = self.decode_particles(enc, enc_int)\n",
    "\n",
    "        e_len = tf.shape(ei)[1]\n",
    "        p_len = tf.shape(pi)[1]\n",
    "\n",
    "        e_dec = dec[:, :e_len]\n",
    "        p_dec = dec[:, e_len:e_len + p_len]\n",
    "\n",
    "        # reconstruction\n",
    "        e_out = self.electron_reconstruction(e_dec)           # (B, e_len, 13)\n",
    "        p_out = self.photon_reconstruction(p_dec)             # (B, p_len, 12)\n",
    "\n",
    "        # masks: True where the *input* is exactly the EMPTY_* vector\n",
    "        e_mask = tf.reduce_all(tf.equal(ei, EMPTY_E), axis=-1)        # (B, e_len)\n",
    "        p_mask = tf.reduce_all(tf.equal(pi, EMPTY_P), axis=-1)        # (B, p_len)\n",
    "\n",
    "        # broadcast masks and overwrite outputs\n",
    "        e_out = tf.where(e_mask[..., None], EMPTY_E, e_out)\n",
    "        p_out = tf.where(p_mask[..., None], EMPTY_P, p_out)\n",
    "\n",
    "        return {\"electron_output\": e_out, \"photon_output\": p_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Data generator for particle physics events.\"\"\"\n",
    "    def __init__(self, data, batch_size=32, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.electron_data, self.photon_data, self.vertex_data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.vertex_data))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch.\"\"\"\n",
    "        return len(self.indices) // self.batch_size\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called at the end of every epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get one batch of data.\"\"\"\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Prepare batch data\n",
    "        x = {\n",
    "            'electron_input': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_input': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32),\n",
    "            'vertex_input': tf.convert_to_tensor(self.vertex_data[batch_indices, np.newaxis, :], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        y = {\n",
    "            'electron_output': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_output': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "Electrons: (500307, 4, 13)\n",
      "Photons: (500307, 4, 12)\n",
      "Vertices: (500307, 3)\n",
      "\n",
      "Validation data shapes:\n",
      "Electrons: (485593, 4, 13)\n",
      "Photons: (485593, 4, 12)\n",
      "Vertices: (485593, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set maximum number of events\n",
    "max_events = 2000000\n",
    "val_max_events = 1000000\n",
    "# Load and slice training data\n",
    "train_electron_features = np.load('train_data_e.npy')[:max_events]\n",
    "train_photon_features = np.load('train_data_p.npy')[:max_events]\n",
    "train_vertices = np.load('train_data_v.npy')[:max_events]\n",
    "\n",
    "# Load and slice validation data\n",
    "val_electron_features = np.load('val_data_e.npy')[:val_max_events]\n",
    "val_photon_features = np.load('val_data_p.npy')[:val_max_events]\n",
    "val_vertices = np.load('val_data_v.npy')[:val_max_events]\n",
    "\n",
    "# Group data into tuples for the generator\n",
    "train_data = (train_electron_features, train_photon_features, train_vertices)\n",
    "val_data = (val_electron_features, val_photon_features, val_vertices)\n",
    "\n",
    "print(f\"Training data shapes:\")\n",
    "print(f\"Electrons: {train_electron_features.shape}\")\n",
    "print(f\"Photons: {train_photon_features.shape}\")\n",
    "print(f\"Vertices: {train_vertices.shape}\")\n",
    "\n",
    "print(f\"\\nValidation data shapes:\")\n",
    "print(f\"Electrons: {val_electron_features.shape}\")\n",
    "print(f\"Photons: {val_photon_features.shape}\")\n",
    "print(f\"Vertices: {val_vertices.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'batch_size': 2048,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 1e-3,\n",
    "    'early_stopping_patience': 3,\n",
    "    'model_checkpoint_path': 'particle_transformer_v3.keras'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = ParticleDataGenerator(train_data, batch_size=training_config['batch_size'])\n",
    "val_generator = ParticleDataGenerator(val_data, batch_size=training_config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_69\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_69\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)      </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape    </span>â”ƒ<span style=\"font-weight: bold\">   Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to   </span>â”ƒ<span style=\"font-weight: bold\"> Traiâ€¦ </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚ electron_input    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ photon_input      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ vertex_input      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ particle_transfoâ€¦ â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>), â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,765</span> â”‚ electron_inpuâ€¦ â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ParticleTransfoâ€¦</span> â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)]  â”‚           â”‚ photon_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚       â”‚\n",
       "â”‚                   â”‚                 â”‚           â”‚ vertex_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ sequential_52     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_124 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_72    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_125 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_73    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_126 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ sequential_53     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_127 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_74    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_128 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">156</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_75    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_129 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ sequential_54     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_130 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_76    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_131 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_77    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_132 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoâ€¦</span> â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">261</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ sequential_63     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_149 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_86    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_150 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_87    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_151 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ sequential_64     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_152 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_88    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_153 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -              â”‚   <span style=\"font-weight: bold\">-</span>   â”‚\n",
       "â”‚ leaky_re_lu_89    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_154 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> â”‚ -              â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to  \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mTraiâ€¦\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚ electron_input    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ photon_input      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ vertex_input      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ particle_transfoâ€¦ â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m), â”‚     \u001b[38;5;34m9,765\u001b[0m â”‚ electron_inpuâ€¦ â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mParticleTransfoâ€¦\u001b[0m â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)]  â”‚           â”‚ photon_input[\u001b[38;5;34mâ€¦\u001b[0m â”‚       â”‚\n",
       "â”‚                   â”‚                 â”‚           â”‚ vertex_input[\u001b[38;5;34mâ€¦\u001b[0m â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚       \u001b[38;5;34m528\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ sequential_52     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_124 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚       \u001b[38;5;34m182\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚        \u001b[38;5;34m26\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_72    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_125 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚       \u001b[38;5;34m182\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚        \u001b[38;5;34m26\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_73    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_126 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚       \u001b[38;5;34m112\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚       \u001b[38;5;34m464\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ sequential_53     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_127 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚       \u001b[38;5;34m156\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚        \u001b[38;5;34m24\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_74    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_128 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚       \u001b[38;5;34m156\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚        \u001b[38;5;34m24\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_75    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_129 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚       \u001b[38;5;34m104\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m68\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ sequential_54     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_130 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚        \u001b[38;5;34m12\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚         \u001b[38;5;34m6\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_76    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_131 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚        \u001b[38;5;34m12\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚         \u001b[38;5;34m6\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ layer_normalizatâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalizatâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_77    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_132 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m32\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       \u001b[38;5;34m872\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerEncoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       \u001b[38;5;34m872\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerEncoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       \u001b[38;5;34m872\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerEncoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚       \u001b[38;5;34m872\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_encoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerEncoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     \u001b[38;5;34m1,176\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerDecoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     \u001b[38;5;34m1,176\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerDecoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     \u001b[38;5;34m1,176\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerDecoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ ?               â”‚     \u001b[38;5;34m1,176\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ transformer_decoâ€¦ â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mTransformerDecoâ€¦\u001b[0m â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚       \u001b[38;5;34m261\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ sequential_63     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_149 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m72\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_86    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_150 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m72\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_87    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_151 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)   â”‚       \u001b[38;5;34m117\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚    â””              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚       \u001b[38;5;34m252\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ sequential_64     â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)      â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_152 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m72\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_88    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_153 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚        \u001b[38;5;34m72\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â””           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)    â”‚         \u001b[38;5;34m0\u001b[0m â”‚ -              â”‚   \u001b[1m-\u001b[0m   â”‚\n",
       "â”‚ leaky_re_lu_89    â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”‚ (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚       â”” dense_154 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)   â”‚       \u001b[38;5;34m108\u001b[0m â”‚ -              â”‚   \u001b[1;38;5;34mY\u001b[0m   â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)           â”‚                 â”‚           â”‚                â”‚       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,765</span> (38.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,765\u001b[0m (38.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,765</span> (38.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,765\u001b[0m (38.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create model with specified input shapes\n",
    "electron_input = keras.Input(shape=(4, len(electron_features_list)), name='electron_input')\n",
    "photon_input = keras.Input(shape=(4, len(photon_features_list)), name='photon_input')\n",
    "vertex_input = keras.Input(shape=(1, 3), name='vertex_input')\n",
    "\n",
    "# Initialize transformer model\n",
    "model = ParticleTransformer(\n",
    "    max_electrons=4,\n",
    "    max_photons=4,\n",
    "    electron_embedding_dim=13,\n",
    "    photon_embedding_dim=12,\n",
    "    vertex_embedding_dim=3,\n",
    "    common_embedding_dim=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "outputs = model({\n",
    "    'electron_input': electron_input,\n",
    "    'photon_input': photon_input,\n",
    "    'vertex_input': vertex_input\n",
    "})\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        'electron_input': electron_input,\n",
    "        'photon_input': photon_input,\n",
    "        'vertex_input': vertex_input\n",
    "    },\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        training_config['model_checkpoint_path'],\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=training_config['early_stopping_patience'],\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-5\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=training_config['learning_rate'], epsilon=1e-7, clipnorm=1.0),\n",
    "    loss={\n",
    "        'electron_output': e_loss,\n",
    "        'photon_output':  p_loss\n",
    "    },\n",
    "    loss_weights={\n",
    "        'electron_output': 1,#15/28,\n",
    "        'photon_output': 1#13/28\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746814810.026469 2307816 service.cc:152] XLA service 0x7f279c0d0040 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746814810.980483 2307816 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-09 11:20:20.893675: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746814838.894831 2307803 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1660s\u001b[0m 3s/step - electron_output_loss: 291.0922 - loss: 714.9327 - photon_output_loss: 423.8407 - val_electron_output_loss: 290.4059 - val_loss: 711.8527 - val_photon_output_loss: 421.4466 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 3s/step - electron_output_loss: 287.3293 - loss: 708.9709 - photon_output_loss: 421.6415 - val_electron_output_loss: 285.8148 - val_loss: 695.9753 - val_photon_output_loss: 410.1605 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 2s/step - electron_output_loss: 280.2444 - loss: 687.0726 - photon_output_loss: 406.8282 - val_electron_output_loss: 273.1388 - val_loss: 652.7305 - val_photon_output_loss: 379.5917 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 2s/step - electron_output_loss: 268.8502 - loss: 636.1927 - photon_output_loss: 367.3425 - val_electron_output_loss: 249.1908 - val_loss: 571.0165 - val_photon_output_loss: 321.8257 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 2s/step - electron_output_loss: 239.6597 - loss: 541.5446 - photon_output_loss: 301.8850 - val_electron_output_loss: 209.2185 - val_loss: 435.9664 - val_photon_output_loss: 226.7482 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m635s\u001b[0m 3s/step - electron_output_loss: 193.7991 - loss: 388.4749 - photon_output_loss: 194.6758 - val_electron_output_loss: 146.2146 - val_loss: 229.7581 - val_photon_output_loss: 83.5436 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 2s/step - electron_output_loss: 124.8617 - loss: 169.4859 - photon_output_loss: 44.6242 - val_electron_output_loss: 60.0774 - val_loss: 60.4313 - val_photon_output_loss: 0.3539 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 2s/step - electron_output_loss: 36.7902 - loss: 37.5988 - photon_output_loss: 0.8086 - val_electron_output_loss: 1.7648 - val_loss: 2.6280 - val_photon_output_loss: 0.8632 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 2s/step - electron_output_loss: 1.7823 - loss: 2.5901 - photon_output_loss: 0.8078 - val_electron_output_loss: 1.4451 - val_loss: 1.9080 - val_photon_output_loss: 0.4630 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m244/244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 3s/step - electron_output_loss: 1.7988 - loss: 2.4977 - photon_output_loss: 0.6989 - val_electron_output_loss: 1.4787 - val_loss: 1.9540 - val_photon_output_loss: 0.4752 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=training_config['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_v3.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
