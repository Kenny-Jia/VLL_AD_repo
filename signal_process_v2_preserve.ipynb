{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 00:40:25.557844: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-30 00:40:25.856954: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-30 00:40:26.021259: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745998826.132700 3708235 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745998826.275788 3708235 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745998826.936433 3708235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745998826.936488 3708235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745998826.936493 3708235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745998826.936498 3708235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-30 00:40:27.001054: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "\n",
    "# Scikit-learn for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, PowerTransformer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataReader:\n",
    "    \"\"\"Handles reading and preprocessing of signal physics event data.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, scaler_path, job_id_to_model_map=None):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.scaler_path = Path(scaler_path)\n",
    "        self.job_id_to_model_map = job_id_to_model_map or {}\n",
    "\n",
    "        # Initialize storage for signal models\n",
    "        self.signal_models = []\n",
    "\n",
    "        # Load feature lists and scaler parameters\n",
    "        with open(self.scaler_path, 'r') as f:\n",
    "            self.scaler_params = json.load(f)\n",
    "\n",
    "        self.file_electron_features_list = [\n",
    "            'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2', 'electron_numberDoF',  # Keep original features\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "        \n",
    "        # Define feature lists based on README\n",
    "        self.electron_features_list = [\n",
    "            'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2', 'electron_numberDoF',\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "        \n",
    "        self.photon_features_list = [\n",
    "            'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "            'photon_time',\n",
    "            'photon_maxEcell_E',\n",
    "            'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "            'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "        ]\n",
    "        \n",
    "        # Initialize and load scalers\n",
    "        self._initialize_and_load_scalers()\n",
    "\n",
    "        # Load and preprocess all data\n",
    "        self.load_all_data()\n",
    "\n",
    "    def _extract_job_id(self, filename):\n",
    "        \"\"\"Extract the job ID from a filename.\"\"\"\n",
    "        # Pattern: signal_JOBID.other_parts\n",
    "        match = re.search(r'signal_(\\d+)\\.', str(filename))\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        return None\n",
    "\n",
    "    def _get_signal_model(self, job_id):\n",
    "        \"\"\"Get the signal model name from the job ID.\"\"\"\n",
    "        if not job_id:\n",
    "            return \"unknown\"\n",
    "        return self.job_id_to_model_map.get(job_id, f\"job_{job_id}\")\n",
    "\n",
    "    def _initialize_and_load_scalers(self):\n",
    "        \"\"\"Initialize specialized scalers for each feature group based on saved parameters.\"\"\"\n",
    "        print(f\"Loading specialized scalers from {self.scaler_path}...\")\n",
    "        \n",
    "        # Initialize electron scalers and feature groups\n",
    "        self.electron_scalers = {}\n",
    "        self.electron_feature_groups = {}\n",
    "        \n",
    "        for group_name, params in self.scaler_params['electron'].items():\n",
    "            # Get feature indices\n",
    "            self.electron_feature_groups[group_name] = params.get('feature_indices', [])\n",
    "            \n",
    "            # Create the appropriate scaler type based on the saved parameters\n",
    "            scaler_type = params.get('type', 'StandardScaler')\n",
    "            \n",
    "            # Initialize the scaler based on type and load its parameters\n",
    "            self._initialize_scaler(self.electron_scalers, group_name, scaler_type, params)\n",
    "        \n",
    "        # Initialize photon scalers and feature groups\n",
    "        self.photon_scalers = {}\n",
    "        self.photon_feature_groups = {}\n",
    "        \n",
    "        for group_name, params in self.scaler_params['photon'].items():\n",
    "            # Get feature indices\n",
    "            self.photon_feature_groups[group_name] = params.get('feature_indices', [])\n",
    "            \n",
    "            # Create the appropriate scaler type based on the saved parameters\n",
    "            scaler_type = params.get('type', 'StandardScaler')\n",
    "            \n",
    "            # Initialize the scaler based on type and load its parameters\n",
    "            self._initialize_scaler(self.photon_scalers, group_name, scaler_type, params)\n",
    "        \n",
    "        # Initialize vertex scaler (simple case)\n",
    "        vertex_params = self.scaler_params['vertex']\n",
    "        self.vertex_scaler = StandardScaler()\n",
    "        if 'mean' in vertex_params and 'scale' in vertex_params:\n",
    "            self.vertex_scaler.mean_ = np.array(vertex_params['mean'])\n",
    "            self.vertex_scaler.scale_ = np.array(vertex_params['scale'])\n",
    "            self.vertex_scaler.var_ = np.square(self.vertex_scaler.scale_)\n",
    "        \n",
    "        print(\"Scalers loaded successfully.\")\n",
    "\n",
    "    def _initialize_scaler(self, scalers_dict, group_name, scaler_type, params):\n",
    "        \"\"\"Initialize a specific scaler based on its type and parameters.\"\"\"\n",
    "        if scaler_type == 'StandardScaler':\n",
    "            scaler = StandardScaler()\n",
    "            if 'mean' in params and 'scale' in params:\n",
    "                scaler.mean_ = np.array(params['mean'])\n",
    "                scaler.scale_ = np.array(params['scale'])\n",
    "                scaler.var_ = np.square(scaler.scale_)\n",
    "        \n",
    "        elif scaler_type == 'RobustScaler':\n",
    "            scaler = RobustScaler()\n",
    "            if 'center' in params and 'scale' in params:\n",
    "                scaler.center_ = np.array(params['center'])\n",
    "                scaler.scale_ = np.array(params['scale'])\n",
    "        \n",
    "        elif scaler_type == 'MinMaxScaler':\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "            scaler.min_ = np.array(params[\"min_\"])\n",
    "            scaler.scale_ = np.array(params[\"scale_\"])\n",
    "        \n",
    "        elif scaler_type == 'PowerTransformer':\n",
    "            method = params.get('method', 'yeo-johnson')\n",
    "            standardize = params.get('standardize', True)\n",
    "            scaler = PowerTransformer(method=method, standardize=standardize)\n",
    "            scaler.lambdas_ = np.array(params['lambdas'])\n",
    "\n",
    "            # Restore internal StandardScaler for standardization\n",
    "            if standardize:\n",
    "                scaler._scaler = StandardScaler()\n",
    "                scaler._scaler.mean_ = np.array(params['mean'])\n",
    "                scaler._scaler.scale_ = np.array(params['scale'])\n",
    "            \n",
    "            # Restore internal scaler manually if standardization was used\n",
    "            if standardize and 'mean' in params and 'scale' in params:\n",
    "                scaler._scaler = StandardScaler()\n",
    "                scaler._scaler.mean_ = np.array(params['mean'])\n",
    "                scaler._scaler.scale_ = np.array(params['scale'])\n",
    "        \n",
    "        else:\n",
    "            # Default to StandardScaler if unknown type\n",
    "            print(f\"Warning: Unknown scaler type '{scaler_type}' for {group_name}, using StandardScaler\")\n",
    "            scaler = StandardScaler()\n",
    "        \n",
    "        # Store the initialized scaler\n",
    "        scalers_dict[group_name] = scaler\n",
    "\n",
    "    def load_all_data(self):\n",
    "        \"\"\"Load and preprocess signal data from HDF5 files.\"\"\"\n",
    "        print(\"Loading all signal data...\")\n",
    "        \n",
    "        # Initialize as None for first file\n",
    "        self.electron_features = None\n",
    "        self.photon_features = None\n",
    "        self.vertex_features = None\n",
    "        \n",
    "        file_count = 0\n",
    "        \n",
    "        for file_path in self.data_dir.glob(\"*.h5\"):\n",
    "            # Extract job ID and signal model from filename\n",
    "            job_id = self._extract_job_id(file_path.name)\n",
    "            signal_model = self._get_signal_model(job_id)\n",
    "            \n",
    "            with h5py.File(file_path, 'r', rdcc_nbytes=10*1024*1024) as f:\n",
    "                n_events = len(f['events/PV_x'])\n",
    "                print(f\"Processing {file_path.name}: {n_events} events, Signal model: {signal_model}\")\n",
    "                \n",
    "                # Load all data at once\n",
    "                electrons = {feat: f[f'events/electrons/{feat}'][:] for feat in self.file_electron_features_list}\n",
    "                photons = {feat: f[f'events/photons/{feat}'][:] for feat in self.photon_features_list}\n",
    "                vertices = np.stack([\n",
    "                    f['events/PV_x'][:],\n",
    "                    f['events/PV_y'][:],\n",
    "                    f['events/PV_z'][:]\n",
    "                ], axis=1)\n",
    "                \n",
    "                # Process all events at once - for signal, only filter based on energy\n",
    "                # e_mask = (electrons['electron_E'] > 0)\n",
    "                \n",
    "                # Initialize arrays for all events\n",
    "                e_feats = np.zeros((n_events, 4, len(self.electron_features_list)))\n",
    "                p_feats = np.zeros((n_events, 4, len(self.photon_features_list)))\n",
    "                \n",
    "                # Process all events at once\n",
    "                for feat_idx, feat in enumerate(self.electron_features_list):\n",
    "                    if feat == 'electron_chi2_over_nDoF':\n",
    "                        # Calculate chi2/ndof ratio\n",
    "                        chi2 = electrons['electron_chi2']\n",
    "                        ndof = electrons['electron_numberDoF']\n",
    "                        \n",
    "                        # Initialize ratio with zeros\n",
    "                        ratio = np.zeros_like(chi2)\n",
    "                        \n",
    "                        # Only calculate ratio where ndof > 0\n",
    "                        valid_mask = ndof > 0\n",
    "                        ratio[valid_mask] = chi2[valid_mask] / ndof[valid_mask]\n",
    "                        e_feats[..., feat_idx] = ratio\n",
    "                    else:\n",
    "                        e_feats[..., feat_idx] = electrons[feat]\n",
    "                    \n",
    "                    # e_feats[..., feat_idx] = np.where(e_mask, e_feats[..., feat_idx], 0)  # Zero out electrons failing selection\n",
    "\n",
    "                for feat_idx, feat in enumerate(self.photon_features_list):\n",
    "                    p_feats[..., feat_idx] = photons[feat]\n",
    "\n",
    "                # Apply event filtering: Require at least two objects\n",
    "                electron_count = np.sum(e_feats[:, :, 0] > 0, axis=1)\n",
    "                photon_count = np.sum(p_feats[:, :, 0] > 0, axis=1)\n",
    "                total_count = electron_count + photon_count\n",
    "\n",
    "                # Create mask for events with at least 2 objects\n",
    "                valid_events = total_count >= 2\n",
    "                \n",
    "                # Apply the filter\n",
    "                e_feats = e_feats[valid_events]\n",
    "                p_feats = p_feats[valid_events]\n",
    "                vertices = vertices[valid_events]\n",
    "                \n",
    "                # Create signal model labels for all events that passed filtering\n",
    "                models = np.array([signal_model] * len(e_feats))\n",
    "                job_ids = np.array([job_id] * len(e_feats))\n",
    "\n",
    "                # Add to main arrays\n",
    "                if self.electron_features is None:\n",
    "                    self.electron_features = e_feats\n",
    "                    self.photon_features = p_feats\n",
    "                    self.vertex_features = vertices\n",
    "                    self.signal_models = models\n",
    "                    self.job_ids = job_ids\n",
    "                else:\n",
    "                    self.electron_features = np.concatenate([self.electron_features, e_feats])\n",
    "                    self.photon_features = np.concatenate([self.photon_features, p_feats])\n",
    "                    self.vertex_features = np.concatenate([self.vertex_features, vertices])\n",
    "                    self.signal_models = np.concatenate([self.signal_models, models])\n",
    "                    self.job_ids = np.concatenate([self.job_ids, job_ids])\n",
    "                \n",
    "                file_count += 1\n",
    "                print(f\"Processed {file_count} files, total events: {len(self.electron_features):,}\")\n",
    "        \n",
    "        print(f\"\\nFinal dataset:\")\n",
    "        print(f\"Total files processed: {file_count}\")\n",
    "        print(f\"Total events: {len(self.electron_features):,}\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")\n",
    "        print(f\"Signal models: {len(np.unique(self.signal_models))} unique models\")\n",
    "        \n",
    "        # Apply saved scalers\n",
    "        print(\"\\nApplying saved scalers to signal data...\")\n",
    "        # self._transform_features()\n",
    "        \n",
    "        print(f\"Final dataset: {len(self.electron_features):,} events\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")    \n",
    "    \n",
    "    def _transform_features(self):\n",
    "        \"\"\"Transform features using loaded scalers.\"\"\"\n",
    "        # Create working copies\n",
    "        e_feats_transformed = self.electron_features.copy()\n",
    "        p_feats_transformed = self.photon_features.copy()\n",
    "        \n",
    "        # Process electron features by group\n",
    "        for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.electron_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.electron_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.electron_features.shape[0], self.electron_features.shape[1]\n",
    "                )\n",
    "                e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # Process photon features by group\n",
    "        for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.photon_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.photon_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.photon_features.shape[0], self.photon_features.shape[1]\n",
    "                )\n",
    "                p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # For vertices, simple standard scaling\n",
    "        self.vertex_features = self.vertex_scaler.transform(self.vertex_features)\n",
    "        \n",
    "        # Update features with transformed versions\n",
    "        self.electron_features = e_feats_transformed\n",
    "        self.photon_features = p_feats_transformed \n",
    "    \n",
    "    def transform_new_data(self, electron_features, photon_features, vertex_features):\n",
    "        \"\"\"Transform new data using loaded scalers.\"\"\"\n",
    "        # Create working copies\n",
    "        # e_feats_transformed = electron_features.copy()\n",
    "        # p_feats_transformed = photon_features.copy()\n",
    "        \n",
    "        # # Process electron features by group\n",
    "        # for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "        #     # Get all feature data for this group at once\n",
    "        #     group_values = np.column_stack([\n",
    "        #         electron_features[:, :, idx].reshape(-1, 1) \n",
    "        #         for idx in feature_indices\n",
    "        #     ])\n",
    "            \n",
    "        #     # Transform all features in the group together\n",
    "        #     transformed_values = self.electron_scalers[group_name].transform(group_values)\n",
    "            \n",
    "        #     # Split back into individual features and update\n",
    "        #     for i, feat_idx in enumerate(feature_indices):\n",
    "        #         feat_transformed = transformed_values[:, i].reshape(\n",
    "        #             electron_features.shape[0], electron_features.shape[1]\n",
    "        #         )\n",
    "        #         e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # # Process photon features by group\n",
    "        # for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "        #     # Get all feature data for this group at once\n",
    "        #     group_values = np.column_stack([\n",
    "        #         photon_features[:, :, idx].reshape(-1, 1) \n",
    "        #         for idx in feature_indices\n",
    "        #     ])\n",
    "            \n",
    "        #     # Transform all features in the group together\n",
    "        #     transformed_values = self.photon_scalers[group_name].transform(group_values)\n",
    "            \n",
    "        #     # Split back into individual features and update\n",
    "        #     for i, feat_idx in enumerate(feature_indices):\n",
    "        #         feat_transformed = transformed_values[:, i].reshape(\n",
    "        #             photon_features.shape[0], photon_features.shape[1]\n",
    "        #         )\n",
    "        #         p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # # For vertices, simple standard scaling\n",
    "        # v_feats_transformed = self.vertex_scaler.transform(vertex_features)\n",
    "        \n",
    "        return electron_features, photon_features, vertex_features\n",
    "\n",
    "    def get_all(self):\n",
    "        \"\"\"Return all processed data as a tuple.\"\"\"\n",
    "        all_data = (\n",
    "            self.electron_features,\n",
    "            self.photon_features,\n",
    "            self.vertex_features,\n",
    "            self.signal_models,\n",
    "            self.job_ids\n",
    "        )\n",
    "        return all_data\n",
    "    \n",
    "    def save_processed_data(self, output_dir):\n",
    "        \"\"\"Save processed data and model information to files.\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save features\n",
    "        np.save(output_dir / 'signal_data_e_v2_preserve.npy', self.electron_features)\n",
    "        np.save(output_dir / 'signal_data_p_v2_preserve.npy', self.photon_features)\n",
    "        np.save(output_dir / 'signal_data_v_v2_preserve.npy', self.vertex_features)\n",
    "        \n",
    "        # Save model information\n",
    "        np.save(output_dir / 'signal_models_v2_preserve.npy', self.signal_models)\n",
    "        np.save(output_dir / 'signal_job_ids_preserve.npy', self.job_ids)\n",
    "        \n",
    "        # Create a summary of the dataset\n",
    "        model_summary = {}\n",
    "        for model, job_id in zip(np.unique(self.signal_models), np.unique(self.job_ids)):\n",
    "            mask = self.signal_models == model\n",
    "            count = np.sum(mask)\n",
    "            model_summary[model] = {\n",
    "                'job_id': job_id,\n",
    "                'event_count': int(count),\n",
    "                'percentage': float(count / len(self.signal_models) * 100)\n",
    "            }\n",
    "        \n",
    "        # Save summary as JSON\n",
    "        with open(output_dir / 'signal_summary_preserve.json', 'w') as f:\n",
    "            json.dump(model_summary, f, indent=2)\n",
    "            \n",
    "        print(f\"Data saved to {output_dir}\")\n",
    "        print(f\"Total events saved: {len(self.electron_features)}\")\n",
    "        print(f\"Model summary saved to {output_dir / 'signal_summary_preserve.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_to_model_map = {\n",
    "  \"543783\": \"110_30_0p1ns\",\n",
    "  \"543784\": \"110_30_0p5ns\",\n",
    "  \"543785\": \"110_30_10ns\",\n",
    "  \"543786\": \"110_30_2ns\",\n",
    "  \"543787\": \"200_10_0p1ns\",\n",
    "  \"543789\": \"200_10_10ns\",\n",
    "  \"543790\": \"200_10_2ns\",\n",
    "  \"543792\": \"200_15_0p5ns\",\n",
    "  \"543793\": \"200_15_10ns\",\n",
    "  \"543794\": \"200_15_2ns\",\n",
    "  \"543796\": \"200_50_0p5ns\",\n",
    "  \"543797\": \"200_50_10ns\",\n",
    "  \"543798\": \"200_50_2ns\",\n",
    "  \"543799\": \"200_90_0p1ns\",\n",
    "  \"543800\": \"200_90_0p5ns\",\n",
    "  \"543801\": \"200_90_10ns\",\n",
    "  \"543802\": \"200_90_2ns\",\n",
    "  \"543803\": \"400_100_0p1ns\",\n",
    "  \"543804\": \"400_100_0p5ns\",\n",
    "  \"543805\": \"400_100_10ns\",\n",
    "  \"543806\": \"400_100_2ns\",\n",
    "  \"543807\": \"400_10_0p1ns\",\n",
    "  \"543808\": \"400_10_0p5ns\",\n",
    "  \"543809\": \"400_10_10ns\",\n",
    "  \"543811\": \"400_15_0p1ns\",\n",
    "  \"543812\": \"400_15_0p5ns\",\n",
    "  \"543813\": \"400_15_10ns\",\n",
    "  \"543814\": \"400_15_2ns\",\n",
    "  \"543815\": \"400_190_0p1ns\",\n",
    "  \"543816\": \"400_190_0p5ns\",\n",
    "  \"543817\": \"400_190_10ns\",\n",
    "  \"543819\": \"600_10_0p1ns\",\n",
    "  \"543821\": \"600_10_10ns\",\n",
    "  \"543822\": \"600_10_2ns\",\n",
    "  \"543823\": \"600_150_0p1ns\",\n",
    "  \"543824\": \"600_150_0p5ns\",\n",
    "  \"543825\": \"600_150_10ns\",\n",
    "  \"543826\": \"600_150_2ns\",\n",
    "  \"543827\": \"600_15_0p1ns\",\n",
    "  \"543828\": \"600_15_0p5ns\",\n",
    "  \"543829\": \"600_15_10ns\",\n",
    "  \"543830\": \"600_15_2ns\",\n",
    "  \"543831\": \"600_290_0p1ns\",\n",
    "  \"543832\": \"600_290_0p5ns\",\n",
    "  \"543833\": \"600_290_10ns\",\n",
    "  \"543834\": \"600_290_2ns\",\n",
    "  \"543836\": \"60_25_0p5ns\",\n",
    "  \"543837\": \"60_25_10ns\",\n",
    "  \"543838\": \"60_25_2ns\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading specialized scalers from /fs/ddn/sdf/group/atlas/d/hjia625/VLL-DP/VLL_classifier/src/output/scaler_params_v2.json...\n",
      "Scalers loaded successfully.\n",
      "Loading all signal data...\n",
      "Processing signal_543784.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297402._000001.trees.h5: 50000 events, Signal model: 110_30_0p5ns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 files, total events: 38,720\n",
      "Processing signal_543785.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297406._000001.trees.h5: 50000 events, Signal model: 110_30_10ns\n",
      "Processed 2 files, total events: 46,987\n",
      "Processing signal_543828.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297651._000001.trees.h5: 50000 events, Signal model: 600_15_0p5ns\n",
      "Processed 3 files, total events: 59,845\n",
      "Processing signal_543822.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297639._000001.trees.h5: 50000 events, Signal model: 600_10_2ns\n",
      "Processed 4 files, total events: 61,561\n",
      "Processing signal_543832.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297658._000001.trees.h5: 50000 events, Signal model: 600_290_0p5ns\n",
      "Processed 5 files, total events: 110,277\n",
      "Processing signal_543790.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297432._000001.trees.h5: 50000 events, Signal model: 200_10_2ns\n",
      "Processed 6 files, total events: 118,060\n",
      "Processing signal_543815.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297624._000001.trees.h5: 50000 events, Signal model: 400_190_0p1ns\n",
      "Processed 7 files, total events: 167,050\n",
      "Processing signal_543831.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297656._000001.trees.h5: 50000 events, Signal model: 600_290_0p1ns\n",
      "Processed 8 files, total events: 216,615\n",
      "Processing signal_543783.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297394._000001.trees.h5: 50000 events, Signal model: 110_30_0p1ns\n",
      "Processed 9 files, total events: 258,180\n",
      "Processing signal_543830.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297654._000001.trees.h5: 50000 events, Signal model: 600_15_2ns\n",
      "Processed 10 files, total events: 261,997\n",
      "Processing signal_543789.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297426._000001.trees.h5: 50000 events, Signal model: 200_10_10ns\n",
      "Processed 11 files, total events: 263,723\n",
      "Processing signal_543798.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297461._000001.trees.h5: 50000 events, Signal model: 200_50_2ns\n",
      "Processed 12 files, total events: 297,811\n",
      "Processing signal_543802.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297485._000001.trees.h5: 50000 events, Signal model: 200_90_2ns\n",
      "Processed 13 files, total events: 334,904\n",
      "Processing signal_543808.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297603._000001.trees.h5: 50000 events, Signal model: 400_10_0p5ns\n",
      "Processed 14 files, total events: 346,726\n",
      "Processing signal_543803.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297488._000001.trees.h5: 50000 events, Signal model: 400_100_0p1ns\n",
      "Processed 15 files, total events: 395,797\n",
      "Processing signal_543790.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297430._000002.trees.h5: 50000 events, Signal model: 200_10_2ns\n",
      "Processed 16 files, total events: 403,831\n",
      "Processing signal_543815.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297625._000001.trees.h5: 50000 events, Signal model: 400_190_0p1ns\n",
      "Processed 17 files, total events: 452,763\n",
      "Processing signal_543799.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297466._000001.trees.h5: 50000 events, Signal model: 200_90_0p1ns\n",
      "Processed 18 files, total events: 499,455\n",
      "Processing signal_543792.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297439._000001.trees.h5: 49999 events, Signal model: 200_15_0p5ns\n",
      "Processed 19 files, total events: 531,648\n",
      "Processing signal_543800.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297468._000001.trees.h5: 50000 events, Signal model: 200_90_0p5ns\n",
      "Processed 20 files, total events: 576,048\n",
      "Processing signal_543805.e8564_e8528_a930_s4114_r15540_r15516_p6069.43297516._000001.trees.h5: 50000 events, Signal model: 400_100_10ns\n",
      "Processed 21 files, total events: 603,237\n",
      "Processing signal_543824.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297643._000001.trees.h5: 50000 events, Signal model: 600_150_0p5ns\n",
      "Processed 22 files, total events: 652,424\n",
      "Processing signal_543784.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297400._000001.trees.h5: 50000 events, Signal model: 110_30_0p5ns\n",
      "Processed 23 files, total events: 691,414\n",
      "Processing signal_543838.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297707._000001.trees.h5: 50000 events, Signal model: 60_25_2ns\n",
      "Processed 24 files, total events: 710,188\n",
      "Processing signal_543797.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297459._000001.trees.h5: 50000 events, Signal model: 200_50_10ns\n",
      "Processed 25 files, total events: 722,071\n",
      "Processing signal_543816.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297626._000001.trees.h5: 50000 events, Signal model: 400_190_0p5ns\n",
      "Processed 26 files, total events: 769,696\n",
      "Processing signal_543812.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297612._000001.trees.h5: 50000 events, Signal model: 400_15_0p5ns\n",
      "Processed 27 files, total events: 790,837\n",
      "Processing signal_543798.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297463._000001.trees.h5: 50000 events, Signal model: 200_50_2ns\n",
      "Processed 28 files, total events: 824,809\n",
      "Processing signal_543831.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297657._000001.trees.h5: 50000 events, Signal model: 600_290_0p1ns\n",
      "Processed 29 files, total events: 874,334\n",
      "Processing signal_543832.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297659._000001.trees.h5: 50000 events, Signal model: 600_290_0p5ns\n",
      "Processed 30 files, total events: 923,012\n",
      "Processing signal_543793.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297440._000001.trees.h5: 50000 events, Signal model: 200_15_10ns\n",
      "Processed 31 files, total events: 926,309\n",
      "Processing signal_543813.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297614._000001.trees.h5: 50000 events, Signal model: 400_15_10ns\n",
      "Processed 32 files, total events: 927,803\n",
      "Processing signal_543794.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297444._000001.trees.h5: 50000 events, Signal model: 200_15_2ns\n",
      "Processed 33 files, total events: 941,720\n",
      "Processing signal_543829.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297653._000001.trees.h5: 50000 events, Signal model: 600_15_10ns\n",
      "Processed 34 files, total events: 942,582\n",
      "Processing signal_543809.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297605._000001.trees.h5: 50000 events, Signal model: 400_10_10ns\n",
      "Processed 35 files, total events: 943,235\n",
      "Processing signal_543806.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297520._000001.trees.h5: 50000 events, Signal model: 400_100_2ns\n",
      "Processed 36 files, total events: 982,696\n",
      "Processing signal_543826.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297646._000001.trees.h5: 50000 events, Signal model: 600_150_2ns\n",
      "Processed 37 files, total events: 1,024,025\n",
      "Processing signal_543786.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297417._000001.trees.h5: 49999 events, Signal model: 110_30_2ns\n",
      "Processed 38 files, total events: 1,050,988\n",
      "Processing signal_543825.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297644._000001.trees.h5: 50000 events, Signal model: 600_150_10ns\n",
      "Processed 39 files, total events: 1,067,472\n",
      "Processing signal_543808.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297604._000001.trees.h5: 50000 events, Signal model: 400_10_0p5ns\n",
      "Processed 40 files, total events: 1,079,104\n",
      "Processing signal_543793.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297442._000001.trees.h5: 50000 events, Signal model: 200_15_10ns\n",
      "Processed 41 files, total events: 1,082,294\n",
      "Processing signal_543837.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297705._000001.trees.h5: 50000 events, Signal model: 60_25_10ns\n",
      "Processed 42 files, total events: 1,087,634\n",
      "Processing signal_543803.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297495._000001.trees.h5: 50000 events, Signal model: 400_100_0p1ns\n",
      "Processed 43 files, total events: 1,136,661\n",
      "Processing signal_543783.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297180._000001.trees.h5: 50000 events, Signal model: 110_30_0p1ns\n",
      "Processed 44 files, total events: 1,178,448\n",
      "Processing signal_543836.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297704._000001.trees.h5: 50000 events, Signal model: 60_25_0p5ns\n",
      "Processed 45 files, total events: 1,205,726\n",
      "Processing signal_543785.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297404._000001.trees.h5: 50000 events, Signal model: 110_30_10ns\n",
      "Processed 46 files, total events: 1,214,203\n",
      "Processing signal_543801.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297483._000001.trees.h5: 50000 events, Signal model: 200_90_10ns\n",
      "Processed 47 files, total events: 1,232,125\n",
      "Processing signal_543809.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297606._000001.trees.h5: 50000 events, Signal model: 400_10_10ns\n",
      "Processed 48 files, total events: 1,232,802\n",
      "Processing signal_543819.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297633._000001.trees.h5: 49999 events, Signal model: 600_10_0p1ns\n",
      "Processed 49 files, total events: 1,254,708\n",
      "Processing signal_543787.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297421._000001.trees.h5: 50000 events, Signal model: 200_10_0p1ns\n",
      "Processed 50 files, total events: 1,294,571\n",
      "Processing signal_543802.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297486._000001.trees.h5: 50000 events, Signal model: 200_90_2ns\n",
      "Processed 51 files, total events: 1,331,634\n",
      "Processing signal_543821.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297637._000001.trees.h5: 50000 events, Signal model: 600_10_10ns\n",
      "Processed 52 files, total events: 1,332,061\n",
      "Processing signal_543789.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297428._000001.trees.h5: 50000 events, Signal model: 200_10_10ns\n",
      "Processed 53 files, total events: 1,333,702\n",
      "Processing signal_543800.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297479._000001.trees.h5: 50000 events, Signal model: 200_90_0p5ns\n",
      "Processed 54 files, total events: 1,378,206\n",
      "Processing signal_543817.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297628._000001.trees.h5: 50000 events, Signal model: 400_190_10ns\n",
      "Processed 55 files, total events: 1,401,006\n",
      "Processing signal_543811.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297610._000001.trees.h5: 50000 events, Signal model: 400_15_0p1ns\n",
      "Processed 56 files, total events: 1,441,963\n",
      "Processing signal_543799.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297465._000001.trees.h5: 50000 events, Signal model: 200_90_0p1ns\n",
      "Processed 57 files, total events: 1,488,662\n",
      "Processing signal_543836.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297703._000001.trees.h5: 50000 events, Signal model: 60_25_0p5ns\n",
      "Processed 58 files, total events: 1,516,441\n",
      "Processing signal_543823.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297641._000001.trees.h5: 50000 events, Signal model: 600_150_0p1ns\n",
      "Processed 59 files, total events: 1,566,061\n",
      "Processing signal_543813.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297615._000001.trees.h5: 50000 events, Signal model: 400_15_10ns\n",
      "Processed 60 files, total events: 1,567,520\n",
      "Processing signal_543819.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297632._000001.trees.h5: 50000 events, Signal model: 600_10_0p1ns\n",
      "Processed 61 files, total events: 1,589,844\n",
      "Processing signal_543812.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297613._000001.trees.h5: 50000 events, Signal model: 400_15_0p5ns\n",
      "Processed 62 files, total events: 1,610,792\n",
      "Processing signal_543834.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297694._000001.trees.h5: 50000 events, Signal model: 600_290_2ns\n",
      "Processed 63 files, total events: 1,653,961\n",
      "Processing signal_543817.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297629._000001.trees.h5: 50000 events, Signal model: 400_190_10ns\n",
      "Processed 64 files, total events: 1,676,662\n",
      "Processing signal_543816.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297627._000001.trees.h5: 50000 events, Signal model: 400_190_0p5ns\n",
      "Processed 65 files, total events: 1,724,224\n",
      "Processing signal_543822.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297638._000001.trees.h5: 50000 events, Signal model: 600_10_2ns\n",
      "Processed 66 files, total events: 1,726,024\n",
      "Processing signal_543804.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297515._000001.trees.h5: 50000 events, Signal model: 400_100_0p5ns\n",
      "Processed 67 files, total events: 1,774,191\n",
      "Processing signal_543787.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297419._000001.trees.h5: 50000 events, Signal model: 200_10_0p1ns\n",
      "Processed 68 files, total events: 1,814,120\n",
      "Processing signal_543833.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297670._000001.trees.h5: 50000 events, Signal model: 600_290_10ns\n",
      "Processed 69 files, total events: 1,839,392\n",
      "Processing signal_543807.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297551._000001.trees.h5: 50000 events, Signal model: 400_10_0p1ns\n",
      "Processed 70 files, total events: 1,870,027\n",
      "Processing signal_543821.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297636._000001.trees.h5: 50000 events, Signal model: 600_10_10ns\n",
      "Processed 71 files, total events: 1,870,449\n",
      "Processing signal_543792.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297437._000001.trees.h5: 50000 events, Signal model: 200_15_0p5ns\n",
      "Processed 72 files, total events: 1,903,202\n",
      "Processing signal_543797.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297457._000001.trees.h5: 50000 events, Signal model: 200_50_10ns\n",
      "Processed 73 files, total events: 1,915,272\n",
      "Processing signal_543811.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297611._000001.trees.h5: 50000 events, Signal model: 400_15_0p1ns\n",
      "Processed 74 files, total events: 1,955,723\n",
      "Processing signal_543823.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297640._000001.trees.h5: 50000 events, Signal model: 600_150_0p1ns\n",
      "Processed 75 files, total events: 2,005,335\n",
      "Processing signal_543827.e8564_e8528_s4277_s4114_r15530_r15514_p6069.43297649._000001.trees.h5: 50000 events, Signal model: 600_15_0p1ns\n",
      "Processed 76 files, total events: 2,037,086\n",
      "Processing signal_543834.e8564_e8528_s4237_s4114_r15540_r15516_p6069.43297682._000001.trees.h5: 50000 events, Signal model: 600_290_2ns\n",
      "Processed 77 files, total events: 2,080,280\n",
      "\n",
      "Final dataset:\n",
      "Total files processed: 77\n",
      "Total events: 2,080,280\n",
      "Shapes: electrons (2080280, 4, 15), photons (2080280, 4, 13), vertices (2080280, 3)\n",
      "Signal models: 47 unique models\n",
      "\n",
      "Applying saved scalers to signal data...\n",
      "Final dataset: 2,080,280 events\n",
      "Shapes: electrons (2080280, 4, 15), photons (2080280, 4, 13), vertices (2080280, 3)\n"
     ]
    }
   ],
   "source": [
    "# Test data loading and preprocessing\n",
    "data_dir = \"/fs/ddn/sdf/group/atlas/d/hjia625/VLL-DP/VLL_classifier/hdf5_signal_output\"\n",
    "scalar_path = \"/fs/ddn/sdf/group/atlas/d/hjia625/VLL-DP/VLL_classifier/src/output/scaler_params_v2.json\"\n",
    "reader = SignalDataReader(data_dir, scalar_path, job_id_to_model_map=job_id_to_model_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to output_model_directory\n",
      "Total events saved: 2080280\n",
      "Model summary saved to output_model_directory/signal_summary_preserve.json\n"
     ]
    }
   ],
   "source": [
    "# Process and get data\n",
    "data = reader.get_all()\n",
    "electron_features, photon_features, vertex_features, signal_models, job_ids = data\n",
    "\n",
    "# Or save everything to files\n",
    "reader.save_processed_data(\"output_model_directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
