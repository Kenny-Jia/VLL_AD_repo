{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 14:56:28.320380: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 14:56:30.756763: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-11 14:56:31.404684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744408592.112442 1962804 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744408592.530232 1962804 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744408594.255866 1962804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744408594.255986 1962804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744408594.255995 1962804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744408594.256002 1962804 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-11 14:56:34.396971: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Scikit-learn for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventReader:\n",
    "    \"\"\"Handles reading and preprocessing of particle physics event data.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "        # Define feature lists to read from files - KEEP ORIGINAL FEATURES\n",
    "        self.file_electron_features_list = [\n",
    "            'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2', 'electron_numberDoF',  # Keep original features\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "\n",
    "        # Define feature lists based on README\n",
    "        self.electron_features_list = [\n",
    "            'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "            'electron_time',\n",
    "            'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "            'electron_nPIX', 'electron_nMissingLayers',\n",
    "            'electron_chi2', 'electron_numberDoF', #'electron_chi2_over_nDoF',\n",
    "            'electron_f1', 'electron_f3', 'electron_z'\n",
    "        ]\n",
    "        \n",
    "        self.photon_features_list = [\n",
    "            'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "            'photon_time',\n",
    "            'photon_maxEcell_E',\n",
    "            'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "            'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "        ]\n",
    "\n",
    "        # Group electron features by type\n",
    "        self.electron_feature_groups = {\n",
    "            'kinematics': [0, 1],         # E, pt - positive valued, potentially skewed\n",
    "            'angles': [2, 3],             # eta, phi - special circular treatment\n",
    "            'time': [4],                  # time - potentially outlier-sensitive\n",
    "            'track_params': [5, 6, 7],    # d0, z0, dpt - potentially outlier-sensitive\n",
    "            'count_data': [8, 9],         # nPIX, nMissingLayers - discrete values\n",
    "            'quality': [10, 11],              # chi2_over_nDoF - potentially skewed\n",
    "            'shower_shape': [12, 13],     # f1, f3 - shape, ratios, potentially saturated\n",
    "            'position': [14]              # z - potentially normal distribution\n",
    "        }\n",
    "        \n",
    "        # Group photon features by type\n",
    "        self.photon_feature_groups = {\n",
    "            'kinematics': [0, 1],         # E, pt - positive valued, potentially skewed\n",
    "            'angles': [2, 3],             # eta, phi - special circular treatment\n",
    "            'time': [4],                  # time - potentially outlier-sensitive\n",
    "            'energy_cell': [5],           # maxEcell_E - potentially skewed  \n",
    "            'shower_shape': [6, 7, 8, 9, 10, 11],  # f1, f3, r1, r2, etas1, phis1\n",
    "            'position': [12]              # z - potentially normal distribution\n",
    "        }\n",
    "\n",
    "        # Initialize scalers for each group\n",
    "        self.initialize_scalers()\n",
    "\n",
    "        # Load and preprocess all data\n",
    "        self.load_all_data()\n",
    "    def initialize_scalers(self):\n",
    "        \"\"\"Initialize specialized scalers for each feature group.\"\"\"\n",
    "        # Electron scalers\n",
    "        self.electron_scalers = {\n",
    "            'kinematics': PowerTransformer(method='yeo-johnson', standardize=True),  # For positive, skewed data\n",
    "            'angles': MinMaxScaler(feature_range=(-1, 1)),        # For angular variables\n",
    "            'time': RobustScaler(),                               # Handle outliers\n",
    "            'track_params': RobustScaler(),                       # Handle outliers\n",
    "            'count_data': StandardScaler(),                       # For discrete data\n",
    "            'quality': PowerTransformer(method='yeo-johnson', standardize=True),  # For skewed data\n",
    "            'shower_shape': StandardScaler(),                     # For shape data\n",
    "            'position': StandardScaler()                          # For positions\n",
    "        }\n",
    "        \n",
    "        # Photon scalers\n",
    "        self.photon_scalers = {\n",
    "            'kinematics': PowerTransformer(method='yeo-johnson', standardize=True),  # For positive, skewed data\n",
    "            'angles': MinMaxScaler(feature_range=(-1, 1)),        # For angular variables\n",
    "            'time': RobustScaler(),                               # Handle outliers\n",
    "            'energy_cell': PowerTransformer(method='yeo-johnson', standardize=True),  # For energy, likely skewed\n",
    "            'shower_shape': StandardScaler(),                     # For shape data\n",
    "            'position': StandardScaler()                          # For positions\n",
    "        }\n",
    "        \n",
    "        # Vertex scalers (simple case - 3 features)\n",
    "        self.vertex_scaler = StandardScaler()\n",
    "        \n",
    "    def load_all_data(self, max_files=70):\n",
    "        \"\"\"Load and preprocess data from HDF5 files.\"\"\"\n",
    "        print(\"Loading all data...\")\n",
    "        \n",
    "        # Initialize as None for first file\n",
    "        self.electron_features = None\n",
    "        self.photon_features = None\n",
    "        self.vertex_features = None\n",
    "        \n",
    "        file_count = 0\n",
    "        \n",
    "        for file_path in self.data_dir.glob(\"*.h5\"):\n",
    "            if file_count >= max_files:\n",
    "                break\n",
    "                \n",
    "            with h5py.File(file_path, 'r', rdcc_nbytes=10*1024*1024) as f:\n",
    "                n_events = len(f['events/PV_x'])\n",
    "                print(f\"Processing {file_path.name}: {n_events} events\")\n",
    "                \n",
    "                # Load all data at once\n",
    "                electrons = {feat: f[f'events/electrons/{feat}'][:] for feat in self.file_electron_features_list}\n",
    "                photons = {feat: f[f'events/photons/{feat}'][:] for feat in self.photon_features_list}\n",
    "                vertices = np.stack([\n",
    "                    f['events/PV_x'][:],\n",
    "                    f['events/PV_y'][:],\n",
    "                    f['events/PV_z'][:]\n",
    "                ], axis=1)\n",
    "                \n",
    "                # Process all events at once\n",
    "                # e_mask = (electrons['electron_E'] > 0) # & (f[f'events/electrons/electron_isIsolated_Loose_VarRad'][:] == 0)\n",
    "                # p_mask = f[f'events/photons/photon_isIsolated_FixedCutLoose'][:] == 0\n",
    "\n",
    "                # Initialize arrays for all events\n",
    "                e_feats = np.zeros((n_events, 4, len(self.electron_features_list)))\n",
    "                p_feats = np.zeros((n_events, 4, len(self.photon_features_list)))\n",
    "                \n",
    "                # Process all events at once\n",
    "                for feat_idx, feat in enumerate(self.electron_features_list):\n",
    "                    if feat == 'electron_chi2_over_nDoF':\n",
    "                        # Calculate chi2/ndof ratio\n",
    "                        chi2 = electrons['electron_chi2']\n",
    "                        ndof = electrons['electron_numberDoF']\n",
    "                        \n",
    "                        # Initialize ratio with zeros\n",
    "                        ratio = np.zeros_like(chi2)\n",
    "                        \n",
    "                        # Only calculate ratio where ndof > 0\n",
    "                        valid_mask = ndof > 0\n",
    "                        ratio[valid_mask] = chi2[valid_mask] / ndof[valid_mask]\n",
    "                        e_feats[..., feat_idx] = ratio\n",
    "                    else:\n",
    "                        e_feats[..., feat_idx] = electrons[feat]\n",
    "                        \n",
    "                    # e_feats[..., feat_idx] = np.where(e_mask, e_feats[..., feat_idx], 0)  # Zero out electrons failing selection\n",
    "                \n",
    "                for feat_idx, feat in enumerate(self.photon_features_list):\n",
    "                    p_feats[..., feat_idx] = photons[feat]\n",
    "                    # p_feats[..., feat_idx] = np.where(p_mask, p_feats[..., feat_idx], 0)\n",
    "\n",
    "                # Apply event filtering: Require at least two objects\n",
    "                electron_count = np.sum(e_feats[:, :, 0] > 0, axis=1)\n",
    "                photon_count = np.sum(p_feats[:, :, 0] > 0, axis=1)\n",
    "                total_count = electron_count + photon_count\n",
    "\n",
    "                # Create mask for events with at least 2 objects\n",
    "                valid_events = total_count >= 2\n",
    "                \n",
    "                # Apply the filter\n",
    "                e_feats = e_feats[valid_events]\n",
    "                p_feats = p_feats[valid_events]\n",
    "                vertices = vertices[valid_events]\n",
    "\n",
    "                # Add to main arrays\n",
    "                if self.electron_features is None:\n",
    "                    self.electron_features = e_feats\n",
    "                    self.photon_features = p_feats\n",
    "                    self.vertex_features = vertices\n",
    "                else:\n",
    "                    self.electron_features = np.concatenate([self.electron_features, e_feats])\n",
    "                    self.photon_features = np.concatenate([self.photon_features, p_feats])\n",
    "                    self.vertex_features = np.concatenate([self.vertex_features, vertices])\n",
    "                \n",
    "                file_count += 1\n",
    "                print(f\"Processed {file_count} files, total events: {len(self.electron_features):,}\")\n",
    "        \n",
    "        print(f\"\\nFinal dataset:\")\n",
    "        print(f\"Total files processed: {file_count}\")\n",
    "        print(f\"Total events: {len(self.electron_features):,}\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")\n",
    "        \n",
    "        # Fit and apply specialized scalers\n",
    "        print(\"\\nFitting and applying specialized scalers...\")\n",
    "        self._fit_transform_features()\n",
    "\n",
    "        print(f\"Final dataset: {len(self.electron_features):,} events\")\n",
    "        print(f\"Shapes: electrons {self.electron_features.shape}, photons {self.photon_features.shape}, vertices {self.vertex_features.shape}\")    \n",
    "        \n",
    "    def _fit_transform_features(self):\n",
    "        \"\"\"Fit and transform features using specialized scalers.\"\"\"\n",
    "        # Create working copies to avoid modifying originals during processing\n",
    "        e_feats_transformed = self.electron_features.copy()\n",
    "        p_feats_transformed = self.photon_features.copy()\n",
    "        \n",
    "        # Process electron features by group\n",
    "        for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.electron_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Fit and transform all features in the group together\n",
    "            transformed_values = self.electron_scalers[group_name].fit_transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.electron_features.shape[0], self.electron_features.shape[1]\n",
    "                )\n",
    "                e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # Process photon features by group\n",
    "        for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                self.photon_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Fit and transform all features in the group together\n",
    "            transformed_values = self.photon_scalers[group_name].fit_transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    self.photon_features.shape[0], self.photon_features.shape[1]\n",
    "                )\n",
    "                p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # For vertices, simple standard scaling\n",
    "        self.vertex_features = self.vertex_scaler.fit_transform(self.vertex_features)\n",
    "        \n",
    "        # Update features with transformed versions\n",
    "        self.electron_features = e_feats_transformed\n",
    "        self.photon_features = p_feats_transformed\n",
    "    \n",
    "    def transform_new_data(self, electron_features, photon_features, vertex_features):\n",
    "        \"\"\"Transform new data using fitted scalers.\"\"\"\n",
    "        # Create working copies\n",
    "        e_feats_transformed = electron_features.copy()\n",
    "        p_feats_transformed = photon_features.copy()\n",
    "        \n",
    "        # Process electron features by group\n",
    "        for group_name, feature_indices in self.electron_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                electron_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.electron_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    electron_features.shape[0], electron_features.shape[1]\n",
    "                )\n",
    "                e_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # Process photon features by group\n",
    "        for group_name, feature_indices in self.photon_feature_groups.items():\n",
    "            # Get all feature data for this group at once\n",
    "            group_values = np.column_stack([\n",
    "                photon_features[:, :, idx].reshape(-1, 1) \n",
    "                for idx in feature_indices\n",
    "            ])\n",
    "            \n",
    "            # Transform all features in the group together\n",
    "            transformed_values = self.photon_scalers[group_name].transform(group_values)\n",
    "            \n",
    "            # Split back into individual features and update\n",
    "            for i, feat_idx in enumerate(feature_indices):\n",
    "                feat_transformed = transformed_values[:, i].reshape(\n",
    "                    photon_features.shape[0], photon_features.shape[1]\n",
    "                )\n",
    "                p_feats_transformed[:, :, feat_idx] = feat_transformed\n",
    "        \n",
    "        # For vertices, simple standard scaling\n",
    "        v_feats_transformed = self.vertex_scaler.transform(vertex_features)\n",
    "        \n",
    "        return e_feats_transformed, p_feats_transformed, v_feats_transformed\n",
    "    \n",
    "    def get_train_val_test_split(self, val_size=0.33, test_size=0.33, shuffle=True):\n",
    "        \"\"\"Split data into train, validation, and test sets.\"\"\"\n",
    "        indices = np.arange(len(self.vertex_features))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        # Calculate split points\n",
    "        test_split = int(len(indices) * (1 - test_size))\n",
    "        val_split = int(len(indices) * (1 - test_size - val_size))\n",
    "        \n",
    "        # Split indices\n",
    "        train_idx = indices[:val_split]\n",
    "        val_idx = indices[val_split:test_split]\n",
    "        test_idx = indices[test_split:]\n",
    "        \n",
    "        # Create split datasets\n",
    "        train_data = (\n",
    "            self.electron_features[train_idx],\n",
    "            self.photon_features[train_idx],\n",
    "            self.vertex_features[train_idx]\n",
    "        )\n",
    "        \n",
    "        val_data = (\n",
    "            self.electron_features[val_idx],\n",
    "            self.photon_features[val_idx],\n",
    "            self.vertex_features[val_idx]\n",
    "        )\n",
    "        \n",
    "        test_data = (\n",
    "            self.electron_features[test_idx],\n",
    "            self.photon_features[test_idx],\n",
    "            self.vertex_features[test_idx]\n",
    "        )\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "        \n",
    "    def save_scalers(self, output_dir):\n",
    "        \"\"\"Save scaler parameters for later use.\"\"\"\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save electron scalers\n",
    "        electron_scaler_params = {}\n",
    "        for group_name, scaler in self.electron_scalers.items():\n",
    "            # Save relevant parameters based on scaler type\n",
    "            params = {}\n",
    "            # Save scaler type\n",
    "            params['type'] = scaler.__class__.__name__\n",
    "            # Save feature indices this scaler applies to\n",
    "            params['feature_indices'] = self.electron_feature_groups[group_name]\n",
    "            \n",
    "            # Add parameters specific to each scaler type\n",
    "            if isinstance(scaler, StandardScaler):\n",
    "                params['mean'] = scaler.mean_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, RobustScaler):\n",
    "                params['center'] = scaler.center_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, MinMaxScaler):\n",
    "                params['feature_range'] = scaler.feature_range\n",
    "                params['min_'] = scaler.min_.tolist()\n",
    "                params['scale_'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, PowerTransformer):\n",
    "                params['lambdas'] = scaler.lambdas_.tolist()\n",
    "                params['method'] = scaler.method\n",
    "                params['standardize'] = scaler.standardize\n",
    "                if scaler.standardize:\n",
    "                    params['mean'] = scaler._scaler.mean_.tolist()\n",
    "                    params['scale'] = scaler._scaler.scale_.tolist()\n",
    "\n",
    "            electron_scaler_params[group_name] = params\n",
    "        \n",
    "        # Save photon scalers\n",
    "        photon_scaler_params = {}\n",
    "        for group_name, scaler in self.photon_scalers.items():\n",
    "            # Save relevant parameters based on scaler type\n",
    "            params = {}\n",
    "            # Save scaler type\n",
    "            params['type'] = scaler.__class__.__name__\n",
    "            # Save feature indices this scaler applies to\n",
    "            params['feature_indices'] = self.photon_feature_groups[group_name]\n",
    "            \n",
    "            # Add parameters specific to each scaler type\n",
    "            if isinstance(scaler, StandardScaler):\n",
    "                params['mean'] = scaler.mean_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, RobustScaler):\n",
    "                params['center'] = scaler.center_.tolist()\n",
    "                params['scale'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, MinMaxScaler):\n",
    "                params['feature_range'] = scaler.feature_range\n",
    "                params['min_'] = scaler.min_.tolist()\n",
    "                params['scale_'] = scaler.scale_.tolist()\n",
    "            \n",
    "            elif isinstance(scaler, PowerTransformer):\n",
    "                params['lambdas'] = scaler.lambdas_.tolist()\n",
    "                params['method'] = scaler.method\n",
    "                params['standardize'] = scaler.standardize\n",
    "                if scaler.standardize:\n",
    "                    params['mean'] = scaler._scaler.mean_.tolist()\n",
    "                    params['scale'] = scaler._scaler.scale_.tolist()\n",
    "            \n",
    "            # elif isinstance(scaler, QuantileTransformer):\n",
    "            #     params['quantiles'] = scaler.quantiles_.tolist()\n",
    "            #     params['n_quantiles'] = scaler.n_quantiles_\n",
    "            #     params['output_distribution'] = scaler.output_distribution\n",
    "            #     params['ignore_implicit_zeros'] = scaler.ignore_implicit_zeros\n",
    "            #     params['subsample'] = scaler.subsample\n",
    "            #     params['random_state'] = scaler.random_state if scaler.random_state is not None else None\n",
    "            #     params['references'] = scaler.references_\n",
    "            \n",
    "            photon_scaler_params[group_name] = params\n",
    "        \n",
    "        # Save vertex scaler\n",
    "        vertex_scaler_params = {\n",
    "            'mean': self.vertex_scaler.mean_.tolist(),\n",
    "            'scale': self.vertex_scaler.scale_.tolist(),\n",
    "            'type': self.vertex_scaler.__class__.__name__\n",
    "        }\n",
    "        \n",
    "        # Combine all scaler parameters\n",
    "        scaler_params = {\n",
    "            'electron': electron_scaler_params,\n",
    "            'photon': photon_scaler_params,\n",
    "            'vertex': vertex_scaler_params,\n",
    "            'electron_features_list': self.electron_features_list,\n",
    "            'photon_features_list': self.photon_features_list\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / 'scaler_params_v2.json', 'w') as f:\n",
    "            json.dump(scaler_params, f, indent=2)\n",
    "        \n",
    "        print(f\"Saved scaler parameters to {output_dir / 'scaler_params_v2.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data...\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000780.trees.h5: 7291 events\n",
      "Processed 1 files, total events: 7,291\n",
      "Processing data_00440499.f1321_m2153_p6000.43297168._000704.trees.h5: 354255 events\n",
      "Processed 2 files, total events: 361,546\n",
      "Processing data_00439607.f1310_m2149_p6000.43297168._000459.trees.h5: 4800 events\n",
      "Processed 3 files, total events: 366,346\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000284.trees.h5: 5337 events\n",
      "Processed 4 files, total events: 371,683\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000461.trees.h5: 183495 events\n",
      "Processed 5 files, total events: 555,178\n",
      "Processing data_00438277.f1307_m2145_p6000.43297168._000628.trees.h5: 200309 events\n",
      "Processed 6 files, total events: 755,487\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000661.trees.h5: 3178 events\n",
      "Processed 7 files, total events: 758,665\n",
      "Processing data_00436169.f1287_m2137_p6000.43297168._000157.trees.h5: 213958 events\n",
      "Processed 8 files, total events: 972,623\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000487.trees.h5: 9654 events\n",
      "Processed 9 files, total events: 982,277\n",
      "Processing data_00437744.f1305_m2142_p6000.43297168._000285.trees.h5: 166725 events\n",
      "Processed 10 files, total events: 1,149,002\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000785.trees.h5: 6270 events\n",
      "Processed 11 files, total events: 1,155,272\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000470.trees.h5: 249445 events\n",
      "Processed 12 files, total events: 1,404,717\n",
      "Processing data_00435831.f1283_m2137_p6000.43297168._000344.trees.h5: 89691 events\n",
      "Processed 13 files, total events: 1,494,408\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000485.trees.h5: 7988 events\n",
      "Processed 14 files, total events: 1,502,396\n",
      "Processing data_00440570.f1321_m2153_p6000.43297168._000745.trees.h5: 7728 events\n",
      "Processed 15 files, total events: 1,510,124\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000101.trees.h5: 174003 events\n",
      "Processed 16 files, total events: 1,684,127\n",
      "Processing data_00436377.f1287_m2137_p6000.43297168._000671.trees.h5: 12932 events\n",
      "Processed 17 files, total events: 1,697,059\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000707.trees.h5: 7365 events\n",
      "Processed 18 files, total events: 1,704,424\n",
      "Processing data_00438446.f1307_m2145_p6000.43297168._000298.trees.h5: 233700 events\n",
      "Processed 19 files, total events: 1,938,124\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000731.trees.h5: 63837 events\n",
      "Processed 20 files, total events: 2,001,961\n",
      "Processing data_00429027.r14190_p5449_p6000.43297168._000146.trees.h5: 179176 events\n",
      "Processed 21 files, total events: 2,181,137\n",
      "Processing data_00439798.f1313_m2149_p6000.43297168._000348.trees.h5: 4952 events\n",
      "Processed 22 files, total events: 2,186,089\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000755.trees.h5: 8385 events\n",
      "Processed 23 files, total events: 2,194,474\n",
      "Processing data_00439830.f1310_m2149_p6000.43297168._000576.trees.h5: 367171 events\n",
      "Processed 24 files, total events: 2,561,645\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000614.trees.h5: 140392 events\n",
      "Processed 25 files, total events: 2,702,037\n",
      "Processing data_00438219.f1305_m2145_p6000.43297168._000597.trees.h5: 229374 events\n",
      "Processed 26 files, total events: 2,931,411\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000715.trees.h5: 19103 events\n",
      "Processed 27 files, total events: 2,950,514\n",
      "Processing data_00428777.r14190_p5449_p6000.43297168._000087.trees.h5: 36015 events\n",
      "Processed 28 files, total events: 2,986,529\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000383.trees.h5: 13964 events\n",
      "Processed 29 files, total events: 3,000,493\n",
      "Processing data_00437744.f1305_m2142_p6000.43297168._000053.trees.h5: 3396 events\n",
      "Processed 30 files, total events: 3,003,889\n",
      "Processing data_00437062.f1294_m2137_p6000.43297168._000119.trees.h5: 3888 events\n",
      "Processed 31 files, total events: 3,007,777\n",
      "Processing data_00436656.f1294_m2137_p6000.43297168._000325.trees.h5: 6066 events\n",
      "Processed 32 files, total events: 3,013,843\n",
      "Processing data_00439927.f1310_m2149_p6000.43297168._000751.trees.h5: 162185 events\n",
      "Processed 33 files, total events: 3,176,028\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000103.trees.h5: 146965 events\n",
      "Processed 34 files, total events: 3,322,993\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000702.trees.h5: 30925 events\n",
      "Processed 35 files, total events: 3,353,918\n",
      "Processing data_00436041.f1287_m2137_p6000.43297168._000327.trees.h5: 251203 events\n",
      "Processed 36 files, total events: 3,605,121\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000401.trees.h5: 38707 events\n",
      "Processed 37 files, total events: 3,643,828\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000626.trees.h5: 3532 events\n",
      "Processed 38 files, total events: 3,647,360\n",
      "Processing data_00435854.f1284_m2137_p6000.43297168._000312.trees.h5: 196780 events\n",
      "Processed 39 files, total events: 3,844,140\n",
      "Processing data_00432180.r14190_p5449_p6000.43297168._000514.trees.h5: 172652 events\n",
      "Processed 40 files, total events: 4,016,792\n",
      "Processing data_00437898.f1305_m2142_p6000.43297168._000139.trees.h5: 394550 events\n",
      "Processed 41 files, total events: 4,411,342\n",
      "Processing data_00438234.f1307_m2145_p6000.43297168._000418.trees.h5: 79637 events\n",
      "Processed 42 files, total events: 4,490,979\n",
      "Processing data_00438234.f1307_m2145_p6000.43297168._000417.trees.h5: 202193 events\n",
      "Processed 43 files, total events: 4,693,172\n",
      "Processing data_00437711.f1305_m2142_p6000.43297168._000651.trees.h5: 288264 events\n",
      "Processed 44 files, total events: 4,981,436\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000624.trees.h5: 3270 events\n",
      "Processed 45 files, total events: 4,984,706\n",
      "Processing data_00431178.r14190_p5449_p6000.43297168._000239.trees.h5: 125902 events\n",
      "Processed 46 files, total events: 5,110,608\n",
      "Processing data_00431215.r14190_p5449_p6000.43297168._000562.trees.h5: 330198 events\n",
      "Processed 47 files, total events: 5,440,806\n",
      "Processing data_00430341.r14190_p5449_p6000.43297168._000426.trees.h5: 6156 events\n",
      "Processed 48 files, total events: 5,446,962\n",
      "Processing data_00435931.f1284_m2137_p6000.43297168._000105.trees.h5: 122986 events\n",
      "Processed 49 files, total events: 5,569,948\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000809.trees.h5: 8071 events\n",
      "Processed 50 files, total events: 5,578,019\n",
      "Processing data_00436863.f1294_m2137_p6000.43297168._000749.trees.h5: 1425 events\n",
      "Processed 51 files, total events: 5,579,444\n",
      "Processing data_00439529.f1310_m2149_p6000.43297168._000708.trees.h5: 8396 events\n",
      "Processed 52 files, total events: 5,587,840\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000718.trees.h5: 21361 events\n",
      "Processed 53 files, total events: 5,609,201\n",
      "Processing data_00438481.f1307_m2145_p6000.43297168._000538.trees.h5: 18435 events\n",
      "Processed 54 files, total events: 5,627,636\n",
      "Processing data_00431037.r14190_p5449_p6000.43297168._000235.trees.h5: 273824 events\n",
      "Processed 55 files, total events: 5,901,460\n",
      "Processing data_00430648.r14190_p5449_p6000.43297168._000294.trees.h5: 94321 events\n",
      "Processed 56 files, total events: 5,995,781\n",
      "Processing data_00436354.f1287_m2137_p6000.43297168._000583.trees.h5: 23763 events\n",
      "Processed 57 files, total events: 6,019,544\n",
      "Processing data_00440543.f1321_m2153_p6000.43297168._000754.trees.h5: 8939 events\n",
      "Processed 58 files, total events: 6,028,483\n",
      "Processing data_00432180.r14190_p5449_p6000.43297168._000511.trees.h5: 276966 events\n",
      "Processed 59 files, total events: 6,305,449\n",
      "Processing data_00437898.f1305_m2142_p6000.43297168._000140.trees.h5: 415881 events\n",
      "Processed 60 files, total events: 6,721,330\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000602.trees.h5: 3333 events\n",
      "Processed 61 files, total events: 6,724,663\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000542.trees.h5: 104819 events\n",
      "Processed 62 files, total events: 6,829,482\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000643.trees.h5: 5222 events\n",
      "Processed 63 files, total events: 6,834,704\n",
      "Processing data_00429697.r14190_p5449_p6000.43297168._000116.trees.h5: 7316 events\n",
      "Processed 64 files, total events: 6,842,020\n",
      "Processing data_00437580.f1302_m2142_p6000.43297168._000347.trees.h5: 15770 events\n",
      "Processed 65 files, total events: 6,857,790\n",
      "Processing data_00436496.f1294_m2137_p6000.43297168._000320.trees.h5: 191275 events\n",
      "Processed 66 files, total events: 7,049,065\n",
      "Processing data_00430542.r14190_p5449_p6000.43297168._000136.trees.h5: 299091 events\n",
      "Processed 67 files, total events: 7,348,156\n",
      "Processing data_00437548.f1302_m2142_p6000.43297168._000582.trees.h5: 6631 events\n",
      "Processed 68 files, total events: 7,354,787\n",
      "Processing data_00430536.r14190_p5449_p6000.43297168._000161.trees.h5: 25415 events\n",
      "Processed 69 files, total events: 7,380,202\n",
      "Processing data_00431906.r14190_p5449_p6000.43297168._000282.trees.h5: 146089 events\n",
      "Processed 70 files, total events: 7,526,291\n",
      "\n",
      "Final dataset:\n",
      "Total files processed: 70\n",
      "Total events: 7,526,291\n",
      "Shapes: electrons (7526291, 4, 15), photons (7526291, 4, 13), vertices (7526291, 3)\n",
      "\n",
      "Fitting and applying specialized scalers...\n",
      "Final dataset: 7,526,291 events\n",
      "Shapes: electrons (7526291, 4, 15), photons (7526291, 4, 13), vertices (7526291, 3)\n",
      "Saved scaler parameters to output/scaler_params_v2.json\n"
     ]
    }
   ],
   "source": [
    "# Test data loading and preprocessing\n",
    "data_dir = \"/fs/ddn/sdf/group/atlas/d/hjia625/VLL-DP/VLL_classifier/hdf5_output\"\n",
    "reader = EventReader(data_dir)\n",
    "reader.save_scalers(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/val/test splits\n",
    "train_data, val_data, test_data = reader.get_train_val_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2558938, 4, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electron_features, photon_features, vertices = train_data\n",
    "np.array(electron_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_data_e.npy', electron_features)\n",
    "np.save('train_data_p.npy', photon_features)\n",
    "np.save('train_data_v.npy', vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_electron_features, val_photon_features, val_vertives = val_data\n",
    "np.save('val_data_e.npy', val_electron_features)\n",
    "np.save('val_data_p.npy', val_photon_features)\n",
    "np.save('val_data_v.npy', val_vertives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_electron_features, test_photon_features, test_vertives = test_data\n",
    "np.save('test_data_e.npy', test_electron_features)\n",
    "np.save('test_data_p.npy', test_photon_features)\n",
    "np.save('test_data_v.npy', test_vertives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_network(input_dim, hidden_dim, output_dim):\n",
    "    \"\"\"Create a deep embedding network.\"\"\"\n",
    "    return keras.Sequential([\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(output_dim)\n",
    "    ])\n",
    "\n",
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer encoder block with multi-head attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        attention_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerDecoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer decoder block with multi-head self and cross attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.cross_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.layernorm3 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        self.dropout3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, encoder_outputs):\n",
    "        # Self attention\n",
    "        self_attention_output = self.self_attention(\n",
    "            query=inputs,\n",
    "            key=inputs,\n",
    "            value=inputs\n",
    "        )\n",
    "        self_attention_output = self.dropout1(self_attention_output)\n",
    "        out1 = self.layernorm1(inputs + self_attention_output)\n",
    "        \n",
    "        # Cross attention with encoder outputs\n",
    "        cross_attention_output = self.cross_attention(\n",
    "            query=out1,\n",
    "            key=encoder_outputs,\n",
    "            value=encoder_outputs\n",
    "        )\n",
    "        cross_attention_output = self.dropout2(cross_attention_output)\n",
    "        out2 = self.layernorm2(out1 + cross_attention_output)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        return self.layernorm3(out2 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_features_list = [\n",
    "    'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "    'electron_time',\n",
    "    'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "    'electron_nPIX', 'electron_nMissingLayers',\n",
    "    'electron_chi2', 'electron_numberDoF', #'electron_chi2_over_nDoF',\n",
    "    'electron_f1', 'electron_f3', 'electron_z'\n",
    "]\n",
    "\n",
    "photon_features_list = [\n",
    "    'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "    'photon_time',\n",
    "    'photon_maxEcell_E',\n",
    "    'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "    'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleTransformer(keras.Model):\n",
    "    \"\"\"Complete transformer model for particle physics data.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_electrons=4,\n",
    "        max_photons=4,\n",
    "        electron_embedding_dim=15,\n",
    "        photon_embedding_dim=13,\n",
    "        vertex_embedding_dim=3,\n",
    "        common_embedding_dim=8,\n",
    "        num_encoder_layers=4,\n",
    "        num_decoder_layers=4,\n",
    "        num_heads=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input embeddings with different dimensions\n",
    "        self.electron_embedding = create_embedding_network(\n",
    "            len(electron_features_list),  # electron feature dim\n",
    "            electron_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.photon_embedding = create_embedding_network(\n",
    "            len(photon_features_list),  # photon feature dim\n",
    "            photon_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.vertex_embedding = create_embedding_network(\n",
    "            3,   # vertex feature dim\n",
    "            vertex_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "              \n",
    "        # Transformer encoder layers\n",
    "        self.encoder_layers = [\n",
    "            TransformerEncoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Transformer decoder layers\n",
    "        self.decoder_layers = [\n",
    "            TransformerDecoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Output projection layers\n",
    "        self.electron_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(electron_features_list))  # electron features\n",
    "        ])\n",
    "        self.photon_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(photon_features_list))  # photon features\n",
    "        ])\n",
    "        \n",
    "    def encode_particles(self, electron_inputs, photon_inputs, vertex_inputs):\n",
    "        # Embed particles\n",
    "        e_embedded = self.electron_embedding(electron_inputs)\n",
    "        p_embedded = self.photon_embedding(photon_inputs)\n",
    "        v_embedded = self.vertex_embedding(vertex_inputs)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = tf.concat([e_embedded, p_embedded, v_embedded], axis=1)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        encoded = combined\n",
    "        intermediates = []\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoded = encoder_layer(encoded)\n",
    "            intermediates.append(encoded)\n",
    "            \n",
    "        return encoded, intermediates\n",
    "        \n",
    "    def decode_particles(self, encoded, encoder_intermediates):\n",
    "        decoded = encoded\n",
    "        \n",
    "        # Pass through decoder layers with corresponding encoder outputs\n",
    "        for decoder_layer, encoder_output in zip(self.decoder_layers, encoder_intermediates):\n",
    "            decoded = decoder_layer(decoded, encoder_output)\n",
    "            \n",
    "        return decoded\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Unpack inputs\n",
    "        electron_inputs = inputs['electron_input']\n",
    "        photon_inputs = inputs['photon_input']\n",
    "        vertex_inputs = inputs['vertex_input']\n",
    "        \n",
    "        # Encode\n",
    "        encoded, encoder_intermediates = self.encode_particles(\n",
    "            electron_inputs, photon_inputs, vertex_inputs)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decode_particles(encoded, encoder_intermediates)\n",
    "        \n",
    "        # Split and reconstruct\n",
    "        e_len = electron_inputs.shape[1]\n",
    "        electron_decoded = decoded[:, :e_len]\n",
    "        photon_decoded = decoded[:, e_len:-1]\n",
    "        \n",
    "        # Output\n",
    "        return {\n",
    "            'electron_output': self.electron_reconstruction(electron_decoded),\n",
    "            'photon_output': self.photon_reconstruction(photon_decoded)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Data generator for particle physics events.\"\"\"\n",
    "    def __init__(self, data, batch_size=32, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.electron_data, self.photon_data, self.vertex_data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.vertex_data))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch.\"\"\"\n",
    "        return len(self.indices) // self.batch_size\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called at the end of every epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get one batch of data.\"\"\"\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Prepare batch data\n",
    "        x = {\n",
    "            'electron_input': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_input': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32),\n",
    "            'vertex_input': tf.convert_to_tensor(self.vertex_data[batch_indices, np.newaxis, :], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        y = {\n",
    "            'electron_output': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_output': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "Electrons: (2000000, 4, 15)\n",
      "Photons: (2000000, 4, 13)\n",
      "Vertices: (2000000, 3)\n",
      "\n",
      "Validation data shapes:\n",
      "Electrons: (1000000, 4, 15)\n",
      "Photons: (1000000, 4, 13)\n",
      "Vertices: (1000000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Set maximum number of events\n",
    "max_events = 2000000\n",
    "val_max_events = 1000000\n",
    "# Load and slice training data\n",
    "train_electron_features = np.load('train_data_e.npy')[:max_events]\n",
    "train_photon_features = np.load('train_data_p.npy')[:max_events]\n",
    "train_vertices = np.load('train_data_v.npy')[:max_events]\n",
    "\n",
    "# Load and slice validation data\n",
    "val_electron_features = np.load('val_data_e.npy')[:val_max_events]\n",
    "val_photon_features = np.load('val_data_p.npy')[:val_max_events]\n",
    "val_vertices = np.load('val_data_v.npy')[:val_max_events]\n",
    "\n",
    "# Group data into tuples for the generator\n",
    "train_data = (train_electron_features, train_photon_features, train_vertices)\n",
    "val_data = (val_electron_features, val_photon_features, val_vertices)\n",
    "\n",
    "print(f\"Training data shapes:\")\n",
    "print(f\"Electrons: {train_electron_features.shape}\")\n",
    "print(f\"Photons: {train_photon_features.shape}\")\n",
    "print(f\"Vertices: {train_vertices.shape}\")\n",
    "\n",
    "print(f\"\\nValidation data shapes:\")\n",
    "print(f\"Electrons: {val_electron_features.shape}\")\n",
    "print(f\"Photons: {val_photon_features.shape}\")\n",
    "print(f\"Vertices: {val_vertices.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    'batch_size': 2048,\n",
    "    'epochs': 20,\n",
    "    'learning_rate': 1e-3,\n",
    "    'early_stopping_patience': 3,\n",
    "    'model_checkpoint_path': 'particle_transformer_v2.keras'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator = ParticleDataGenerator(train_data, batch_size=training_config['batch_size'])\n",
    "val_generator = ParticleDataGenerator(val_data, batch_size=training_config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 16:01:49.298189: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)      </span><span style=\"font-weight: bold\"> Output Shape    </span><span style=\"font-weight: bold\">   Param # </span><span style=\"font-weight: bold\"> Connected to   </span><span style=\"font-weight: bold\"> Trai </span>\n",
       "\n",
       " electron_input     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                         \n",
       "\n",
       " photon_input       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                         \n",
       "\n",
       " vertex_input       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                         \n",
       "\n",
       " particle_transfo  [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>),      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,996</span>  electron_inpu    <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ParticleTransfo</span>  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)]              photon_input[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span>        \n",
       "                                                vertex_input[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span>        \n",
       "\n",
       "     sequential    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">668</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                                                         \n",
       "\n",
       "        dense      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu                                                          \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_1    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_1                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_2    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "     sequential_1  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                                                         \n",
       "\n",
       "        dense_3    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_2                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_4    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_3                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_5    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "     sequential_2  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                                                         \n",
       "\n",
       "        dense_6    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_4                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_7    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " layer_normalizat                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizat</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_5                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_8    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   ?                      <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_enco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEnco</span>                                                    \n",
       "\n",
       "                   ?                      <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_enco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEnco</span>                                                    \n",
       "\n",
       "                   ?                      <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_enco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEnco</span>                                                    \n",
       "\n",
       "                   ?                      <span style=\"color: #00af00; text-decoration-color: #00af00\">872</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_enco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEnco</span>                                                    \n",
       "\n",
       "                   ?                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_deco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDeco</span>                                                    \n",
       "\n",
       "                   ?                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_deco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDeco</span>                                                    \n",
       "\n",
       "                   ?                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_deco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDeco</span>                                                    \n",
       "\n",
       "                   ?                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " transformer_deco                                                    \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDeco</span>                                                    \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">279</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " sequential_11                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                                                         \n",
       "\n",
       "        dense_25   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_14                                                       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_26   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_15                                                       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_27   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">261</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " sequential_12                                                        \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                                                         \n",
       "\n",
       "        dense_28   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_16                                                       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_29   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 <span style=\"font-weight: bold\">-</span>   \n",
       " leaky_re_lu_17                                                       \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)                                                          \n",
       "\n",
       "        dense_30   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>  -                 <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                              \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to  \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTrai\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " electron_input     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                         \n",
       "\n",
       " photon_input       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                         \n",
       "\n",
       " vertex_input       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " (\u001b[38;5;33mInputLayer\u001b[0m)                                                         \n",
       "\n",
       " particle_transfo  [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m),      \u001b[38;5;34m9,996\u001b[0m  electron_inpu    \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mParticleTransfo\u001b[0m  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)]              photon_input[\u001b[38;5;34m\u001b[0m        \n",
       "                                                vertex_input[\u001b[38;5;34m\u001b[0m        \n",
       "\n",
       "     sequential    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m668\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mSequential\u001b[0m)                                                         \n",
       "\n",
       "        dense      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)          \u001b[38;5;34m240\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)           \u001b[38;5;34m30\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu                                                          \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_1    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)          \u001b[38;5;34m240\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)           \u001b[38;5;34m30\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_1                                                        \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_2    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m128\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "     sequential_1  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m528\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mSequential\u001b[0m)                                                         \n",
       "\n",
       "        dense_3    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)          \u001b[38;5;34m182\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)           \u001b[38;5;34m26\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_2                                                        \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_4    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)          \u001b[38;5;34m182\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)           \u001b[38;5;34m26\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)            \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_3                                                        \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_5    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           \u001b[38;5;34m112\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "     sequential_2  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m68\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mSequential\u001b[0m)                                                         \n",
       "\n",
       "        dense_6    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)            \u001b[38;5;34m12\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m6\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_4                                                        \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_7    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)            \u001b[38;5;34m12\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m6\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " layer_normalizat                                                    \n",
       " (\u001b[38;5;33mLayerNormalizat\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_5                                                        \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_8    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m32\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   ?                      \u001b[38;5;34m872\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_enco                                                    \n",
       " (\u001b[38;5;33mTransformerEnco\u001b[0m                                                    \n",
       "\n",
       "                   ?                      \u001b[38;5;34m872\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_enco                                                    \n",
       " (\u001b[38;5;33mTransformerEnco\u001b[0m                                                    \n",
       "\n",
       "                   ?                      \u001b[38;5;34m872\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_enco                                                    \n",
       " (\u001b[38;5;33mTransformerEnco\u001b[0m                                                    \n",
       "\n",
       "                   ?                      \u001b[38;5;34m872\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_enco                                                    \n",
       " (\u001b[38;5;33mTransformerEnco\u001b[0m                                                    \n",
       "\n",
       "                   ?                    \u001b[38;5;34m1,176\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_deco                                                    \n",
       " (\u001b[38;5;33mTransformerDeco\u001b[0m                                                    \n",
       "\n",
       "                   ?                    \u001b[38;5;34m1,176\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_deco                                                    \n",
       " (\u001b[38;5;33mTransformerDeco\u001b[0m                                                    \n",
       "\n",
       "                   ?                    \u001b[38;5;34m1,176\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_deco                                                    \n",
       " (\u001b[38;5;33mTransformerDeco\u001b[0m                                                    \n",
       "\n",
       "                   ?                    \u001b[38;5;34m1,176\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " transformer_deco                                                    \n",
       " (\u001b[38;5;33mTransformerDeco\u001b[0m                                                    \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)          \u001b[38;5;34m279\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " sequential_11                                                        \n",
       " (\u001b[38;5;33mSequential\u001b[0m)                                                         \n",
       "\n",
       "        dense_25   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m72\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_14                                                       \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_26   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m72\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_15                                                       \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_27   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)          \u001b[38;5;34m135\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)          \u001b[38;5;34m261\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " sequential_12                                                        \n",
       " (\u001b[38;5;33mSequential\u001b[0m)                                                         \n",
       "\n",
       "        dense_28   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m72\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_16                                                       \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_29   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)            \u001b[38;5;34m72\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n",
       "                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)             \u001b[38;5;34m0\u001b[0m  -                 \u001b[1m-\u001b[0m   \n",
       " leaky_re_lu_17                                                       \n",
       " (\u001b[38;5;33mLeakyReLU\u001b[0m)                                                          \n",
       "\n",
       "        dense_30   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m13\u001b[0m)          \u001b[38;5;34m117\u001b[0m  -                 \u001b[1;38;5;34mY\u001b[0m   \n",
       " (\u001b[38;5;33mDense\u001b[0m)                                                              \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,996</span> (39.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,996\u001b[0m (39.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,996</span> (39.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,996\u001b[0m (39.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create model with specified input shapes\n",
    "electron_input = keras.Input(shape=(4, len(electron_features_list)), name='electron_input')\n",
    "photon_input = keras.Input(shape=(4, len(photon_features_list)), name='photon_input')\n",
    "vertex_input = keras.Input(shape=(1, 3), name='vertex_input')\n",
    "\n",
    "# Initialize transformer model\n",
    "model = ParticleTransformer(\n",
    "    max_electrons=4,\n",
    "    max_photons=4,\n",
    "    electron_embedding_dim=15,\n",
    "    photon_embedding_dim=13,\n",
    "    vertex_embedding_dim=3,\n",
    "    common_embedding_dim=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "outputs = model({\n",
    "    'electron_input': electron_input,\n",
    "    'photon_input': photon_input,\n",
    "    'vertex_input': vertex_input\n",
    "})\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        'electron_input': electron_input,\n",
    "        'photon_input': photon_input,\n",
    "        'vertex_input': vertex_input\n",
    "    },\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        training_config['model_checkpoint_path'],\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=training_config['early_stopping_patience'],\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-5\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='./logs',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=training_config['learning_rate'], epsilon=1e-7, clipnorm=1.0),\n",
    "    loss={\n",
    "        'electron_output': tf.keras.losses.Huber(delta=20.0),\n",
    "        'photon_output': tf.keras.losses.Huber(delta=20.0)\n",
    "    },\n",
    "    loss_weights={\n",
    "        'electron_output': 1,#15/28,\n",
    "        'photon_output': 1#13/28\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 254ms/step - electron_output_loss: 272.1737 - loss: 605.4150 - photon_output_loss: 333.2413 - val_electron_output_loss: 253.9977 - val_loss: 509.9737 - val_photon_output_loss: 255.9759 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 260ms/step - electron_output_loss: 225.4586 - loss: 394.5655 - photon_output_loss: 169.1071 - val_electron_output_loss: 42.9392 - val_loss: 43.0619 - val_photon_output_loss: 0.1226 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 247ms/step - electron_output_loss: 8.5519 - loss: 8.7217 - photon_output_loss: 0.1698 - val_electron_output_loss: 0.8767 - val_loss: 1.0005 - val_photon_output_loss: 0.1238 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 240ms/step - electron_output_loss: 1.0062 - loss: 1.1453 - photon_output_loss: 0.1391 - val_electron_output_loss: 0.7561 - val_loss: 0.8715 - val_photon_output_loss: 0.1155 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 252ms/step - electron_output_loss: 0.8223 - loss: 0.9558 - photon_output_loss: 0.1335 - val_electron_output_loss: 0.7110 - val_loss: 0.8313 - val_photon_output_loss: 0.1203 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 245ms/step - electron_output_loss: 0.7864 - loss: 0.9113 - photon_output_loss: 0.1249 - val_electron_output_loss: 0.6209 - val_loss: 0.7322 - val_photon_output_loss: 0.1114 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 234ms/step - electron_output_loss: 0.7198 - loss: 0.8492 - photon_output_loss: 0.1294 - val_electron_output_loss: 0.6821 - val_loss: 0.8096 - val_photon_output_loss: 0.1275 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 258ms/step - electron_output_loss: 0.6891 - loss: 0.8164 - photon_output_loss: 0.1273 - val_electron_output_loss: 0.5816 - val_loss: 0.7133 - val_photon_output_loss: 0.1317 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 259ms/step - electron_output_loss: 0.6454 - loss: 0.7668 - photon_output_loss: 0.1214 - val_electron_output_loss: 0.5624 - val_loss: 0.6757 - val_photon_output_loss: 0.1133 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 339ms/step - electron_output_loss: 0.6512 - loss: 0.7704 - photon_output_loss: 0.1192 - val_electron_output_loss: 0.6766 - val_loss: 0.7912 - val_photon_output_loss: 0.1146 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 349ms/step - electron_output_loss: 0.6258 - loss: 0.7466 - photon_output_loss: 0.1208 - val_electron_output_loss: 0.5600 - val_loss: 0.6664 - val_photon_output_loss: 0.1064 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 331ms/step - electron_output_loss: 0.5817 - loss: 0.6984 - photon_output_loss: 0.1167 - val_electron_output_loss: 0.5441 - val_loss: 0.6811 - val_photon_output_loss: 0.1369 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 354ms/step - electron_output_loss: 0.6866 - loss: 0.8430 - photon_output_loss: 0.1564 - val_electron_output_loss: 0.5122 - val_loss: 0.6296 - val_photon_output_loss: 0.1173 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 262ms/step - electron_output_loss: 0.5613 - loss: 0.6914 - photon_output_loss: 0.1300 - val_electron_output_loss: 0.5150 - val_loss: 0.6208 - val_photon_output_loss: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 373ms/step - electron_output_loss: 0.6093 - loss: 0.7279 - photon_output_loss: 0.1186 - val_electron_output_loss: 0.4754 - val_loss: 0.5985 - val_photon_output_loss: 0.1231 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 349ms/step - electron_output_loss: 0.5535 - loss: 0.6690 - photon_output_loss: 0.1155 - val_electron_output_loss: 0.4965 - val_loss: 0.6034 - val_photon_output_loss: 0.1069 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 286ms/step - electron_output_loss: 0.5664 - loss: 0.6804 - photon_output_loss: 0.1140 - val_electron_output_loss: 0.4917 - val_loss: 0.5981 - val_photon_output_loss: 0.1064 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 376ms/step - electron_output_loss: 0.5229 - loss: 0.6350 - photon_output_loss: 0.1121 - val_electron_output_loss: 0.4775 - val_loss: 0.5941 - val_photon_output_loss: 0.1165 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 294ms/step - electron_output_loss: 0.5892 - loss: 0.7015 - photon_output_loss: 0.1123 - val_electron_output_loss: 0.4736 - val_loss: 0.5980 - val_photon_output_loss: 0.1244 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m976/976\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 260ms/step - electron_output_loss: 0.5051 - loss: 0.6271 - photon_output_loss: 0.1220 - val_electron_output_loss: 0.4578 - val_loss: 0.5641 - val_photon_output_loss: 0.1063 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=training_config['epochs'],\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_v2.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
