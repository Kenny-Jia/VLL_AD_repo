{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Deep learning imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import os\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate reconstruction MSE\n",
    "# def calculate_mse(model, electron_features, photon_features, vertices):\n",
    "#     vertices = vertices.reshape(vertices.shape[0], 1, vertices.shape[1])\n",
    "#     # Prepare inputs\n",
    "#     inputs = {\n",
    "#         'electron_input': electron_features,\n",
    "#         'photon_input': photon_features,\n",
    "#         'vertex_input': vertices\n",
    "#     }\n",
    "    \n",
    "#     # Get model predictions\n",
    "#     predictions = model.predict(inputs, batch_size=2048)\n",
    "    \n",
    "#     # Calculate MSE for electrons\n",
    "#     electron_mse = np.mean(\n",
    "#         np.square(predictions['electron_output'] - electron_features),\n",
    "#         axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "#     )\n",
    "    \n",
    "#     # Calculate MSE for photons\n",
    "#     photon_mse = np.mean(\n",
    "#         np.square(predictions['photon_output'] - photon_features),\n",
    "#         axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "#     )\n",
    "    \n",
    "#     # Total MSE (average of electron and photon MSEs)\n",
    "#     total_mse = (electron_mse + photon_mse) / 2\n",
    "    \n",
    "#     return total_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to calculate reconstruction MAE\n",
    "# def calculate_mae(model, electron_features, photon_features, vertices):\n",
    "#     vertices = vertices.reshape(vertices.shape[0], 1, vertices.shape[1])\n",
    "#     # Prepare inputs\n",
    "#     inputs = {\n",
    "#         'electron_input': electron_features,\n",
    "#         'photon_input': photon_features,\n",
    "#         'vertex_input': vertices\n",
    "#     }\n",
    "    \n",
    "#     # Get model predictions\n",
    "#     predictions = model.predict(inputs, batch_size=2048)\n",
    "    \n",
    "#     # Calculate MAE for electrons\n",
    "#     electron_mae = np.mean(\n",
    "#         np.absolute(predictions['electron_output'] - electron_features),\n",
    "#         axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "#     )\n",
    "    \n",
    "#     # Calculate MAE for photons\n",
    "#     photon_mae = np.mean(\n",
    "#         np.square(predictions['photon_output'] - photon_features),\n",
    "#         axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "#     )\n",
    "    \n",
    "#     # Total MAE (average of electron and photon MAEs)\n",
    "#     total_mae = (electron_mae + photon_mae) / 2\n",
    "    \n",
    "#     return total_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tanh_error(model, electron_features, photon_features, vertices):\n",
    "    vertices = vertices.reshape(vertices.shape[0], 1, vertices.shape[1])\n",
    "    \n",
    "    # Prepare inputs\n",
    "    inputs = {\n",
    "        'electron_input': electron_features,\n",
    "        'photon_input': photon_features,\n",
    "        'vertex_input': vertices\n",
    "    }\n",
    "    \n",
    "    # Get model predictions\n",
    "    predictions = model.predict(inputs, batch_size=512)\n",
    "    \n",
    "    # Calculate sigmoid of error for electrons\n",
    "    electron_error = predictions['electron_output'] - electron_features\n",
    "    electron_squared_error = np.square(electron_error)\n",
    "    electron_squared_tanh_error = np.tanh(electron_squared_error)\n",
    "    \n",
    "    electron_mean_squared_tanh = np.mean(\n",
    "        electron_squared_tanh_error,\n",
    "        axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "    )\n",
    "    \n",
    "    # Calculate sigmoid of error for photons\n",
    "    photon_error = predictions['photon_output'] - photon_features\n",
    "    photon_tanh_error = np.tanh(photon_error)\n",
    "    photon_squared_tanh_error = np.square(photon_tanh_error)\n",
    "    photon_mean_squared_tanh = np.mean(\n",
    "        photon_squared_tanh_error,\n",
    "        axis=(1, 2)  # Reduce over particle and feature dimensions\n",
    "    )\n",
    "    \n",
    "    # Total mean of squared sigmoid of error (average of electron and photon values)\n",
    "    total_mean_squared_tanh = (electron_mean_squared_tanh + photon_mean_squared_tanh) / 2\n",
    "    \n",
    "    return total_mean_squared_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Loading signal data...\n",
      "Test data shapes: electrons (100000, 4, 15), photons (100000, 4, 13), vertices (100000, 3)\n",
      "Signal data shapes: electrons (2080280, 4, 15), photons (2080280, 4, 13), vertices (2080280, 3)\n",
      "Signal models shape: (2080280,)\n",
      "Unique signal models: ['110_30_0p1ns' '110_30_0p5ns' '110_30_10ns' '110_30_2ns' '200_10_0p1ns'\n",
      " '200_10_10ns' '200_10_2ns' '200_15_0p5ns' '200_15_10ns' '200_15_2ns'\n",
      " '200_50_10ns' '200_50_2ns' '200_90_0p1ns' '200_90_0p5ns' '200_90_10ns'\n",
      " '200_90_2ns' '400_100_0p1ns' '400_100_0p5ns' '400_100_10ns' '400_100_2ns'\n",
      " '400_10_0p1ns' '400_10_0p5ns' '400_10_10ns' '400_15_0p1ns' '400_15_0p5ns'\n",
      " '400_15_10ns' '400_190_0p1ns' '400_190_0p5ns' '400_190_10ns'\n",
      " '600_10_0p1ns' '600_10_10ns' '600_10_2ns' '600_150_0p1ns' '600_150_0p5ns'\n",
      " '600_150_10ns' '600_150_2ns' '600_15_0p1ns' '600_15_0p5ns' '600_15_10ns'\n",
      " '600_15_2ns' '600_290_0p1ns' '600_290_0p5ns' '600_290_10ns' '600_290_2ns'\n",
      " '60_25_0p5ns' '60_25_10ns' '60_25_2ns']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "max_events = 100000\n",
    "print(\"Loading test data...\")\n",
    "test_electron_features = np.load('test_data_e.npy')[:max_events]\n",
    "test_photon_features = np.load('test_data_p.npy')[:max_events]\n",
    "test_vertices = np.load('test_data_v.npy')[:max_events]\n",
    "\n",
    "print(\"Loading signal data...\")\n",
    "signal_electron_features = np.load('output_model_directory/signal_data_e_models.npy')\n",
    "signal_photon_features = np.load('output_model_directory/signal_data_p_models.npy')\n",
    "signal_vertices = np.load('output_model_directory/signal_data_v_models.npy')\n",
    "signal_models = np.load('output_model_directory/signal_models.npy')\n",
    "signal_job_ids = np.load('output_model_directory/signal_job_ids.npy')\n",
    "\n",
    "print(f\"Test data shapes: electrons {test_electron_features.shape}, photons {test_photon_features.shape}, vertices {test_vertices.shape}\")\n",
    "print(f\"Signal data shapes: electrons {signal_electron_features.shape}, photons {signal_photon_features.shape}, vertices {signal_vertices.shape}\")\n",
    "print(f\"Signal models shape: {signal_models.shape}\")\n",
    "print(f\"Unique signal models: {np.unique(signal_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4, 15)\n"
     ]
    }
   ],
   "source": [
    "print(test_electron_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_network(input_dim, hidden_dim, output_dim):\n",
    "    \"\"\"Create a deep embedding network.\"\"\"\n",
    "    return keras.Sequential([\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(hidden_dim),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.LeakyReLU(negative_slope=0.1),\n",
    "        layers.Dense(output_dim)\n",
    "    ])\n",
    "\n",
    "class TransformerEncoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer encoder block with multi-head attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        attention_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TransformerDecoderBlock(layers.Layer):\n",
    "    \"\"\"Transformer decoder block with multi-head self and cross attention.\"\"\"\n",
    "    def __init__(self, embedding_dim, num_heads=4, ff_dim_factor=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.cross_attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dim // num_heads\n",
    "        )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(embedding_dim * ff_dim_factor),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.layernorm3 = layers.LayerNormalization()\n",
    "\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        self.dropout3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def call(self, inputs, encoder_outputs):\n",
    "        # Self attention\n",
    "        self_attention_output = self.self_attention(\n",
    "            query=inputs,\n",
    "            key=inputs,\n",
    "            value=inputs\n",
    "        )\n",
    "        self_attention_output = self.dropout1(self_attention_output)\n",
    "        out1 = self.layernorm1(inputs + self_attention_output)\n",
    "        \n",
    "        # Cross attention with encoder outputs\n",
    "        cross_attention_output = self.cross_attention(\n",
    "            query=out1,\n",
    "            key=encoder_outputs,\n",
    "            value=encoder_outputs\n",
    "        )\n",
    "        cross_attention_output = self.dropout2(cross_attention_output)\n",
    "        out2 = self.layernorm2(out1 + cross_attention_output)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        return self.layernorm3(out2 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "electron_features_list = [\n",
    "    'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "    'electron_time',\n",
    "    'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "    'electron_nPIX', 'electron_nMissingLayers',\n",
    "    'electron_chi2', 'electron_numberDoF',  # Will need to handle ratio\n",
    "    'electron_f1', 'electron_f3', 'electron_z'\n",
    "]\n",
    "\n",
    "photon_features_list = [\n",
    "    'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "    'photon_time',\n",
    "    'photon_maxEcell_E',\n",
    "    'photon_f1', 'photon_f3', 'photon_r1', 'photon_r2',\n",
    "    'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleTransformer(keras.Model):\n",
    "    \"\"\"Complete transformer model for particle physics data.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_electrons=4,\n",
    "        max_photons=4,\n",
    "        electron_embedding_dim=15,\n",
    "        photon_embedding_dim=13,\n",
    "        vertex_embedding_dim=3,\n",
    "        common_embedding_dim=31,\n",
    "        num_encoder_layers=4,\n",
    "        num_decoder_layers=4,\n",
    "        num_heads=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input embeddings with different dimensions\n",
    "        self.electron_embedding = create_embedding_network(\n",
    "            len(electron_features_list),  # electron feature dim\n",
    "            electron_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.photon_embedding = create_embedding_network(\n",
    "            len(photon_features_list),  # photon feature dim\n",
    "            photon_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "        self.vertex_embedding = create_embedding_network(\n",
    "            3,   # vertex feature dim\n",
    "            vertex_embedding_dim,\n",
    "            common_embedding_dim\n",
    "        )\n",
    "              \n",
    "        # Transformer encoder layers\n",
    "        self.encoder_layers = [\n",
    "            TransformerEncoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Transformer decoder layers\n",
    "        self.decoder_layers = [\n",
    "            TransformerDecoderBlock(common_embedding_dim, num_heads)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ]\n",
    "        \n",
    "        # Output projection layers\n",
    "        self.electron_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(electron_features_list))  # electron features\n",
    "        ])\n",
    "        self.photon_reconstruction = keras.Sequential([\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(common_embedding_dim),\n",
    "            layers.LeakyReLU(negative_slope=0.1),\n",
    "            layers.Dense(len(photon_features_list))  # photon features\n",
    "        ])\n",
    "        \n",
    "    def encode_particles(self, electron_inputs, photon_inputs, vertex_inputs):\n",
    "        # Embed particles\n",
    "        e_embedded = self.electron_embedding(electron_inputs)\n",
    "        p_embedded = self.photon_embedding(photon_inputs)\n",
    "        v_embedded = self.vertex_embedding(vertex_inputs)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined = tf.concat([e_embedded, p_embedded, v_embedded], axis=1)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        encoded = combined\n",
    "        intermediates = []\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoded = encoder_layer(encoded)\n",
    "            intermediates.append(encoded)\n",
    "            \n",
    "        return encoded, intermediates\n",
    "        \n",
    "    def decode_particles(self, encoded, encoder_intermediates):\n",
    "        decoded = encoded\n",
    "        \n",
    "        # Pass through decoder layers with corresponding encoder outputs\n",
    "        for decoder_layer, encoder_output in zip(self.decoder_layers, encoder_intermediates):\n",
    "            decoded = decoder_layer(decoded, encoder_output)\n",
    "            \n",
    "        return decoded\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Unpack inputs\n",
    "        electron_inputs = inputs['electron_input']\n",
    "        photon_inputs = inputs['photon_input']\n",
    "        vertex_inputs = inputs['vertex_input']\n",
    "        \n",
    "        # Encode\n",
    "        encoded, encoder_intermediates = self.encode_particles(\n",
    "            electron_inputs, photon_inputs, vertex_inputs)\n",
    "        \n",
    "        # Decode\n",
    "        decoded = self.decode_particles(encoded, encoder_intermediates)\n",
    "        \n",
    "        # Split and reconstruct\n",
    "        e_len = electron_inputs.shape[1]\n",
    "        electron_decoded = decoded[:, :e_len]\n",
    "        photon_decoded = decoded[:, e_len:-1]\n",
    "        \n",
    "        # Output\n",
    "        return {\n",
    "            'electron_output': self.electron_reconstruction(electron_decoded),\n",
    "            'photon_output': self.photon_reconstruction(photon_decoded)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Data generator for particle physics events.\"\"\"\n",
    "    def __init__(self, data, batch_size=32, shuffle=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.electron_data, self.photon_data, self.vertex_data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.vertex_data))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch.\"\"\"\n",
    "        return len(self.indices) // self.batch_size\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called at the end of every epoch.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get one batch of data.\"\"\"\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # Prepare batch data\n",
    "        x = {\n",
    "            'electron_input': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_input': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32),\n",
    "            'vertex_input': tf.convert_to_tensor(self.vertex_data[batch_indices, np.newaxis, :], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        y = {\n",
    "            'electron_output': tf.convert_to_tensor(self.electron_data[batch_indices], dtype=tf.float32),\n",
    "            'photon_output': tf.convert_to_tensor(self.photon_data[batch_indices], dtype=tf.float32)\n",
    "        }\n",
    "        \n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from particle_transformer_v1.keras...\n",
      "Weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the model with the correct dimensions\n",
    "model = ParticleTransformer(\n",
    "    max_electrons=4,\n",
    "    max_photons=4,\n",
    "    electron_embedding_dim=15,\n",
    "    photon_embedding_dim=13,\n",
    "    vertex_embedding_dim=3,\n",
    "    common_embedding_dim=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "\n",
    "# Create model with specified input shapes\n",
    "electron_input = keras.Input(shape=(4, len(electron_features_list)), name='electron_input')\n",
    "photon_input = keras.Input(shape=(4, len(photon_features_list)), name='photon_input')\n",
    "vertex_input = keras.Input(shape=(1, 3), name='vertex_input')\n",
    "\n",
    "outputs = model({\n",
    "    'electron_input': electron_input,\n",
    "    'photon_input': photon_input,\n",
    "    'vertex_input': vertex_input\n",
    "})\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs={\n",
    "        'electron_input': electron_input,\n",
    "        'photon_input': photon_input,\n",
    "        'vertex_input': vertex_input\n",
    "    },\n",
    "    outputs=outputs\n",
    ")\n",
    "\n",
    "# Load weights\n",
    "model_path = 'particle_transformer_v1.keras'\n",
    "# model_path = 'model_v1.weights.h5'\n",
    "print(f\"Loading weights from {model_path}...\")\n",
    "# Try first with load_weights\n",
    "model.load_weights(model_path)\n",
    "print(\"Weights loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.36558436e-01 -6.36682108e-01 -1.46194748e-03 -3.79454986e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.91689508e-01 -2.97815966e-01 -6.36035711e-01 -6.36941296e-01\n",
      "  -5.94128432e-01 -4.22699628e-01  2.57189577e-04]\n",
      " [-6.36558436e-01 -6.36682108e-01 -1.46194748e-03 -3.79454986e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.91689508e-01 -2.97815966e-01 -6.36035711e-01 -6.36941296e-01\n",
      "  -5.94128432e-01 -4.22699628e-01  2.57189577e-04]\n",
      " [-6.36558436e-01 -6.36682108e-01 -1.46194748e-03 -3.79454986e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.91689508e-01 -2.97815966e-01 -6.36035711e-01 -6.36941296e-01\n",
      "  -5.94128432e-01 -4.22699628e-01  2.57189577e-04]\n",
      " [-6.36558436e-01 -6.36682108e-01 -1.46194748e-03 -3.79454986e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -5.91689508e-01 -2.97815966e-01 -6.36035711e-01 -6.36941296e-01\n",
      "  -5.94128432e-01 -4.22699628e-01  2.57189577e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(signal_electron_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating test data anomaly scores...\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 80ms/step\n",
      "Calculating signal data anomaly scores...\n",
      "\u001b[1m4064/4064\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 69ms/step\n",
      "Overall ROC AUC: 0.908911\n"
     ]
    }
   ],
   "source": [
    "# Calculate anomaly scores\n",
    "print(\"Calculating test data anomaly scores...\")\n",
    "test_scores = calculate_tanh_error(model, test_electron_features, test_photon_features, test_vertices)\n",
    "\n",
    "print(\"Calculating signal data anomaly scores...\")\n",
    "signal_scores = calculate_tanh_error(model, signal_electron_features, signal_photon_features, signal_vertices)\n",
    "\n",
    "# Create labels (0 for test/background, 1 for signal)\n",
    "test_labels = np.zeros(len(test_scores))\n",
    "signal_labels = np.ones(len(signal_scores))\n",
    "\n",
    "# Combine scores and labels\n",
    "all_scores = np.concatenate([test_scores, signal_scores])\n",
    "all_labels = np.concatenate([test_labels, signal_labels])\n",
    "\n",
    "# Calculate overall ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"Overall ROC AUC: {roc_auc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_highest_score_events(model, e_feats, p_feats, vertices, scores, n_events=2, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Display the highest-scoring events from a dataset with detailed error analysis.\n",
    "    Shows both raw differences and tanh(diff²) for each feature with feature names.\n",
    "    \"\"\"\n",
    "    # Define feature names\n",
    "    electron_features_list = [\n",
    "        'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "        'electron_time', 'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "        'electron_nPIX', 'electron_nMissingLayers', 'electron_chi2', \n",
    "        'electron_numberDoF', 'electron_f1', 'electron_f3', 'electron_z'\n",
    "    ]\n",
    "    \n",
    "    photon_features_list = [\n",
    "        'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "        'photon_time', 'photon_maxEcell_E', 'photon_f1', 'photon_f3', \n",
    "        'photon_r1', 'photon_r2', 'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "    ]\n",
    "    \n",
    "    # Find indices of highest scoring events\n",
    "    top_indices = np.argsort(scores)[-n_events:][::-1]\n",
    "    \n",
    "    print(f\"\\n===== Top {n_events} highest scoring events from {dataset_name} =====\")\n",
    "    \n",
    "    for i, idx in enumerate(top_indices):\n",
    "        # Get input features for this event\n",
    "        electron_input = e_feats[idx:idx+1]\n",
    "        photon_input = p_feats[idx:idx+1]\n",
    "        \n",
    "        # Handle vertex input - reshape if necessary\n",
    "        vertex_input = vertices[idx:idx+1]\n",
    "        if len(vertex_input.shape) == 2:\n",
    "            vertex_input = vertex_input.reshape(vertex_input.shape[0], 1, vertex_input.shape[1])\n",
    "        \n",
    "        # Get model prediction\n",
    "        inputs = {\n",
    "            'electron_input': electron_input,\n",
    "            'photon_input': photon_input,\n",
    "            'vertex_input': vertex_input\n",
    "        }\n",
    "        prediction = model.predict(inputs, verbose=0)\n",
    "        \n",
    "        # Print event information\n",
    "        print(f\"\\nEvent {i+1} (index {idx}): Score = {scores[idx]:.6f}\")\n",
    "        \n",
    "        # Print basic event properties\n",
    "        if vertex_input.shape[1] == 1:\n",
    "            print(f\"  Vertex position: {vertex_input[0, 0]}\")\n",
    "        \n",
    "        # Count total particles\n",
    "        n_electrons = 4\n",
    "        n_photons = 4\n",
    "        print(f\"  Number of electrons: {n_electrons}\")\n",
    "        print(f\"  Number of photons: {n_photons}\")\n",
    "        \n",
    "        # Print features of all particles with comparisons\n",
    "        print(\"\\n  ELECTRONS (actual vs predicted):\")\n",
    "        all_electron_errors = []\n",
    "        \n",
    "        for e_idx in range(4):\n",
    "            print(f\"  Electron #{e_idx+1}:\")\n",
    "            \n",
    "            # Calculate tanh errors for this electron\n",
    "            e_tanh_errors = []\n",
    "            e_feature_errors = {}  # Store errors by feature name\n",
    "            \n",
    "            for feat_idx in range(min(len(electron_features_list), electron_input.shape[2])):\n",
    "                feat_name = electron_features_list[feat_idx]\n",
    "                actual = electron_input[0, e_idx, feat_idx]\n",
    "                pred = prediction['electron_output'][0, e_idx, feat_idx]\n",
    "                diff = actual - pred\n",
    "                diff_squared = diff**2\n",
    "                tanh_diff_squared = np.tanh(diff_squared)\n",
    "                \n",
    "                e_tanh_errors.append(tanh_diff_squared)\n",
    "                e_feature_errors[feat_name] = tanh_diff_squared\n",
    "                \n",
    "                # Print feature details\n",
    "                print(f\"    {feat_name}: {actual:.4f} vs {pred:.4f} (diff: {diff:.4f}, tanh(diff²): {tanh_diff_squared:.4f})\")\n",
    "            \n",
    "            # Add individual errors to the flat list\n",
    "            all_electron_errors.extend(e_tanh_errors)\n",
    "            \n",
    "            # Find and print top 3 error features\n",
    "            top_error_features = sorted(e_feature_errors.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(f\"    Mean tanh(diff²) for this electron: {np.mean(e_tanh_errors):.4f}\")\n",
    "            print(f\"    Top error features: \" + \", \".join([f\"{name} ({val:.4f})\" for name, val in top_error_features]))\n",
    "            print(\"\")\n",
    "        \n",
    "        # Calculate overall electron error\n",
    "        if all_electron_errors:\n",
    "            avg_electron_error = np.mean(all_electron_errors)\n",
    "            print(f\"  Overall mean electron tanh(diff²): {avg_electron_error:.4f}\")\n",
    "        \n",
    "        print(\"\\n  PHOTONS (actual vs predicted):\")\n",
    "        all_photon_errors = []\n",
    "        \n",
    "        for p_idx in range(4):\n",
    "            print(f\"  Photon #{p_idx+1}:\")\n",
    "            \n",
    "            # Calculate tanh errors for this photon\n",
    "            p_tanh_errors = []\n",
    "            p_feature_errors = {}  # Store errors by feature name\n",
    "            \n",
    "            for feat_idx in range(min(len(photon_features_list), photon_input.shape[2])):\n",
    "                feat_name = photon_features_list[feat_idx]\n",
    "                actual = photon_input[0, p_idx, feat_idx]\n",
    "                pred = prediction['photon_output'][0, p_idx, feat_idx]\n",
    "                diff = actual - pred\n",
    "                diff_squared = diff**2\n",
    "                tanh_diff_squared = np.tanh(diff_squared)\n",
    "                \n",
    "                p_tanh_errors.append(tanh_diff_squared)\n",
    "                p_feature_errors[feat_name] = tanh_diff_squared\n",
    "                \n",
    "                # Print feature details\n",
    "                print(f\"    {feat_name}: {actual:.4f} vs {pred:.4f} (diff: {diff:.4f}, tanh(diff²): {tanh_diff_squared:.4f})\")\n",
    "            \n",
    "            # Add individual errors to the flat list\n",
    "            all_photon_errors.extend(p_tanh_errors)\n",
    "            \n",
    "            # Find and print top 3 error features\n",
    "            top_error_features = sorted(p_feature_errors.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(f\"    Mean tanh(diff²) for this photon: {np.mean(p_tanh_errors):.4f}\")\n",
    "            print(f\"    Top error features: \" + \", \".join([f\"{name} ({val:.4f})\" for name, val in top_error_features]))\n",
    "            print(\"\")\n",
    "        \n",
    "        # Calculate overall photon error\n",
    "        if all_photon_errors:\n",
    "            avg_photon_error = np.mean(all_photon_errors)\n",
    "            print(f\"  Overall mean photon tanh(diff²): {avg_photon_error:.4f}\")\n",
    "        \n",
    "        # Calculate and print total event error\n",
    "        all_errors = all_electron_errors + all_photon_errors\n",
    "        if all_errors:\n",
    "            total_avg_error = np.mean(all_errors)\n",
    "            print(f\"\\n  Total event mean tanh(diff²): {total_avg_error:.4f}\")\n",
    "            print(f\"  Compare with event score: {scores[idx]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Top 3 highest scoring events from Background =====\n",
      "\n",
      "Event 1 (index 73557): Score = 0.161420\n",
      "  Vertex position: [ 0.14672647 -0.12636682  0.12413128]\n",
      "  Number of electrons: 4\n",
      "  Number of photons: 4\n",
      "\n",
      "  ELECTRONS (actual vs predicted):\n",
      "  Electron #1:\n",
      "    electron_E: 1.4555 vs 1.5099 (diff: -0.0544, tanh(diff²): 0.0030)\n",
      "    electron_pt: 1.4285 vs 1.5241 (diff: -0.0956, tanh(diff²): 0.0091)\n",
      "    electron_eta: 0.4730 vs 0.0037 (diff: 0.4693, tanh(diff²): 0.2167)\n",
      "    electron_phi: 0.2704 vs -0.0038 (diff: 0.2742, tanh(diff²): 0.0751)\n",
      "    electron_time: -0.4543 vs -0.5626 (diff: 0.1083, tanh(diff²): 0.0117)\n",
      "    electron_d0: 0.0078 vs -0.0362 (diff: 0.0440, tanh(diff²): 0.0019)\n",
      "    electron_z0: 34.0875 vs 35.4865 (diff: -1.3990, tanh(diff²): 0.9609)\n",
      "    electron_dpt: -0.1804 vs -0.1644 (diff: -0.0161, tanh(diff²): 0.0003)\n",
      "    electron_nPIX: 1.6372 vs 1.3861 (diff: 0.2511, tanh(diff²): 0.0630)\n",
      "    electron_nMissingLayers: -0.2978 vs 0.7202 (diff: -1.0180, tanh(diff²): 0.7764)\n",
      "    electron_chi2: 1.5506 vs 1.5235 (diff: 0.0271, tanh(diff²): 0.0007)\n",
      "    electron_numberDoF: 1.5980 vs 1.4847 (diff: 0.1132, tanh(diff²): 0.0128)\n",
      "    electron_f1: 1.2939 vs 1.3652 (diff: -0.0713, tanh(diff²): 0.0051)\n",
      "    electron_f3: 3.1764 vs 1.0009 (diff: 2.1755, tanh(diff²): 0.9998)\n",
      "    electron_z: -0.0020 vs -0.0109 (diff: 0.0089, tanh(diff²): 0.0001)\n",
      "    Mean tanh(diff²) for this electron: 0.2091\n",
      "    Top error features: electron_f3 (0.9998), electron_z0 (0.9609), electron_nMissingLayers (0.7764)\n",
      "\n",
      "  Electron #2:\n",
      "    electron_E: -0.6366 vs -0.6183 (diff: -0.0183, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6161 (diff: -0.0206, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0500 (diff: 0.0500, tanh(diff²): 0.0025)\n",
      "    electron_d0: 0.0000 vs -0.0013 (diff: 0.0013, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0953 (diff: -0.0953, tanh(diff²): 0.0091)\n",
      "    electron_dpt: 0.0000 vs -0.0000 (diff: 0.0000, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5727 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2895 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6153 (diff: -0.0207, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6179 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5769 (diff: -0.0173, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4110 (diff: -0.0117, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0009\n",
      "    Top error features: electron_z0 (0.0091), electron_time (0.0025), electron_chi2 (0.0004)\n",
      "\n",
      "  Electron #3:\n",
      "    electron_E: -0.6366 vs -0.6183 (diff: -0.0183, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6161 (diff: -0.0206, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0500 (diff: 0.0500, tanh(diff²): 0.0025)\n",
      "    electron_d0: 0.0000 vs -0.0013 (diff: 0.0013, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0953 (diff: -0.0953, tanh(diff²): 0.0091)\n",
      "    electron_dpt: 0.0000 vs -0.0000 (diff: 0.0000, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5727 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2895 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6153 (diff: -0.0207, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6179 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5769 (diff: -0.0173, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4110 (diff: -0.0117, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0009\n",
      "    Top error features: electron_z0 (0.0091), electron_time (0.0025), electron_chi2 (0.0004)\n",
      "\n",
      "  Electron #4:\n",
      "    electron_E: -0.6366 vs -0.6183 (diff: -0.0183, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6161 (diff: -0.0206, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0500 (diff: 0.0500, tanh(diff²): 0.0025)\n",
      "    electron_d0: 0.0000 vs -0.0013 (diff: 0.0013, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0953 (diff: -0.0953, tanh(diff²): 0.0091)\n",
      "    electron_dpt: 0.0000 vs -0.0000 (diff: 0.0000, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5727 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2895 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6153 (diff: -0.0207, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6179 (diff: -0.0190, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5769 (diff: -0.0173, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4110 (diff: -0.0117, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0009\n",
      "    Top error features: electron_z0 (0.0091), electron_time (0.0025), electron_chi2 (0.0004)\n",
      "\n",
      "  Overall mean electron tanh(diff²): 0.0530\n",
      "\n",
      "  PHOTONS (actual vs predicted):\n",
      "  Photon #1:\n",
      "    photon_E: 1.9121 vs 1.8610 (diff: 0.0511, tanh(diff²): 0.0026)\n",
      "    photon_pt: 1.5993 vs 0.9915 (diff: 0.6078, tanh(diff²): 0.3535)\n",
      "    photon_eta: 0.9990 vs 0.9894 (diff: 0.0096, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9899 vs 1.0016 (diff: -0.0117, tanh(diff²): 0.0001)\n",
      "    photon_time: -0.5619 vs -0.0680 (diff: -0.4939, tanh(diff²): 0.2392)\n",
      "    photon_maxEcell_E: 4.8939 vs 1.0043 (diff: 3.8896, tanh(diff²): 1.0000)\n",
      "    photon_f1: 0.2000 vs 1.6193 (diff: -1.4193, tanh(diff²): 0.9650)\n",
      "    photon_f3: 4.0749 vs 0.8923 (diff: 3.1827, tanh(diff²): 1.0000)\n",
      "    photon_r1: 1.2534 vs 1.8142 (diff: -0.5608, tanh(diff²): 0.3045)\n",
      "    photon_r2: 1.2002 vs 1.8100 (diff: -0.6099, tanh(diff²): 0.3557)\n",
      "    photon_etas1: 1.9221 vs 0.0000 (diff: 1.9221, tanh(diff²): 0.9988)\n",
      "    photon_phis1: -1.5951 vs 0.0059 (diff: -1.6009, tanh(diff²): 0.9882)\n",
      "    photon_z: 0.0008 vs 0.0045 (diff: -0.0036, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.4775\n",
      "    Top error features: photon_maxEcell_E (1.0000), photon_f3 (1.0000), photon_etas1 (0.9988)\n",
      "\n",
      "  Photon #2:\n",
      "    photon_E: 1.9043 vs 1.8588 (diff: 0.0456, tanh(diff²): 0.0021)\n",
      "    photon_pt: 0.5348 vs 0.9741 (diff: -0.4392, tanh(diff²): 0.1906)\n",
      "    photon_eta: 0.9995 vs 0.9902 (diff: 0.0093, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9990 vs 0.9855 (diff: 0.0135, tanh(diff²): 0.0002)\n",
      "    photon_time: -0.5289 vs -0.3688 (diff: -0.1601, tanh(diff²): 0.0256)\n",
      "    photon_maxEcell_E: 2.3499 vs 0.9862 (diff: 1.3636, tanh(diff²): 0.9526)\n",
      "    photon_f1: 0.5157 vs 1.6083 (diff: -1.0926, tanh(diff²): 0.8317)\n",
      "    photon_f3: 3.2862 vs 0.8789 (diff: 2.4073, tanh(diff²): 1.0000)\n",
      "    photon_r1: 0.8753 vs 1.8064 (diff: -0.9310, tanh(diff²): 0.6998)\n",
      "    photon_r2: 0.8325 vs 1.7929 (diff: -0.9604, tanh(diff²): 0.7271)\n",
      "    photon_etas1: 2.1493 vs -0.0008 (diff: 2.1501, tanh(diff²): 0.9998)\n",
      "    photon_phis1: 2.2253 vs 0.0061 (diff: 2.2191, tanh(diff²): 0.9999)\n",
      "    photon_z: 0.0025 vs 0.0125 (diff: -0.0100, tanh(diff²): 0.0001)\n",
      "    Mean tanh(diff²) for this photon: 0.4946\n",
      "    Top error features: photon_f3 (1.0000), photon_phis1 (0.9999), photon_etas1 (0.9998)\n",
      "\n",
      "  Photon #3:\n",
      "    photon_E: 1.8579 vs 1.8644 (diff: -0.0065, tanh(diff²): 0.0000)\n",
      "    photon_pt: 0.2976 vs 1.0157 (diff: -0.7182, tanh(diff²): 0.4744)\n",
      "    photon_eta: 0.9976 vs 0.9883 (diff: 0.0093, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9979 vs 1.0237 (diff: -0.0259, tanh(diff²): 0.0007)\n",
      "    photon_time: 0.7169 vs 0.3610 (diff: 0.3560, tanh(diff²): 0.1260)\n",
      "    photon_maxEcell_E: -0.0103 vs 1.0297 (diff: -1.0400, tanh(diff²): 0.7938)\n",
      "    photon_f1: 1.8848 vs 1.6347 (diff: 0.2501, tanh(diff²): 0.0624)\n",
      "    photon_f3: 1.2264 vs 0.9110 (diff: 0.3153, tanh(diff²): 0.0991)\n",
      "    photon_r1: 1.9443 vs 1.8253 (diff: 0.1190, tanh(diff²): 0.0141)\n",
      "    photon_r2: 1.9168 vs 1.8342 (diff: 0.0826, tanh(diff²): 0.0068)\n",
      "    photon_etas1: 1.2104 vs 0.0011 (diff: 1.2093, tanh(diff²): 0.8981)\n",
      "    photon_phis1: 1.7427 vs 0.0055 (diff: 1.7372, tanh(diff²): 0.9952)\n",
      "    photon_z: 0.0006 vs -0.0067 (diff: 0.0073, tanh(diff²): 0.0001)\n",
      "    Mean tanh(diff²) for this photon: 0.2670\n",
      "    Top error features: photon_phis1 (0.9952), photon_etas1 (0.8981), photon_maxEcell_E (0.7938)\n",
      "\n",
      "  Photon #4:\n",
      "    photon_E: -0.5367 vs -0.5372 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    photon_pt: -0.0053 vs -0.0039 (diff: -0.0014, tanh(diff²): 0.0000)\n",
      "    photon_eta: 0.9951 vs 0.9977 (diff: -0.0025, tanh(diff²): 0.0000)\n",
      "    photon_phi: 0.9937 vs 0.9950 (diff: -0.0013, tanh(diff²): 0.0000)\n",
      "    photon_time: 0.0000 vs 0.0204 (diff: -0.0204, tanh(diff²): 0.0004)\n",
      "    photon_maxEcell_E: -0.2646 vs -0.2581 (diff: -0.0065, tanh(diff²): 0.0000)\n",
      "    photon_f1: -0.4895 vs -0.4889 (diff: -0.0007, tanh(diff²): 0.0000)\n",
      "    photon_f3: -0.2691 vs -0.2677 (diff: -0.0015, tanh(diff²): 0.0000)\n",
      "    photon_r1: -0.5299 vs -0.5299 (diff: -0.0001, tanh(diff²): 0.0000)\n",
      "    photon_r2: -0.5291 vs -0.5299 (diff: 0.0009, tanh(diff²): 0.0000)\n",
      "    photon_etas1: 0.0004 vs 0.0012 (diff: -0.0008, tanh(diff²): 0.0000)\n",
      "    photon_phis1: 0.0010 vs 0.0004 (diff: 0.0006, tanh(diff²): 0.0000)\n",
      "    photon_z: 0.0002 vs -0.0002 (diff: 0.0004, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.0000\n",
      "    Top error features: photon_time (0.0004), photon_maxEcell_E (0.0000), photon_eta (0.0000)\n",
      "\n",
      "  Overall mean photon tanh(diff²): 0.3098\n",
      "\n",
      "  Total event mean tanh(diff²): 0.1722\n",
      "  Compare with event score: 0.161420\n",
      "\n",
      "Event 2 (index 50803): Score = 0.156756\n",
      "  Vertex position: [ 0.16256283 -0.34623396  1.5986288 ]\n",
      "  Number of electrons: 4\n",
      "  Number of photons: 4\n",
      "\n",
      "  ELECTRONS (actual vs predicted):\n",
      "  Electron #1:\n",
      "    electron_E: -0.6366 vs -0.6293 (diff: -0.0073, tanh(diff²): 0.0001)\n",
      "    electron_pt: -0.6367 vs -0.6283 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_eta: -0.0015 vs -0.0007 (diff: -0.0007, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0127 (diff: 0.0127, tanh(diff²): 0.0002)\n",
      "    electron_d0: 0.0000 vs -0.0015 (diff: 0.0015, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0324 (diff: -0.0324, tanh(diff²): 0.0011)\n",
      "    electron_dpt: 0.0000 vs 0.0003 (diff: -0.0003, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5843 (diff: -0.0074, tanh(diff²): 0.0001)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2946 (diff: -0.0032, tanh(diff²): 0.0000)\n",
      "    electron_chi2: -0.6360 vs -0.6278 (diff: -0.0082, tanh(diff²): 0.0001)\n",
      "    electron_numberDoF: -0.6369 vs -0.6291 (diff: -0.0078, tanh(diff²): 0.0001)\n",
      "    electron_f1: -0.5941 vs -0.5875 (diff: -0.0066, tanh(diff²): 0.0000)\n",
      "    electron_f3: -0.4227 vs -0.4188 (diff: -0.0039, tanh(diff²): 0.0000)\n",
      "    electron_z: 0.0003 vs 0.0002 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0001\n",
      "    Top error features: electron_z0 (0.0011), electron_time (0.0002), electron_pt (0.0001)\n",
      "\n",
      "  Electron #2:\n",
      "    electron_E: -0.6366 vs -0.6293 (diff: -0.0073, tanh(diff²): 0.0001)\n",
      "    electron_pt: -0.6367 vs -0.6283 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_eta: -0.0015 vs -0.0007 (diff: -0.0007, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0127 (diff: 0.0127, tanh(diff²): 0.0002)\n",
      "    electron_d0: 0.0000 vs -0.0015 (diff: 0.0015, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0324 (diff: -0.0324, tanh(diff²): 0.0011)\n",
      "    electron_dpt: 0.0000 vs 0.0003 (diff: -0.0003, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5843 (diff: -0.0074, tanh(diff²): 0.0001)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2946 (diff: -0.0032, tanh(diff²): 0.0000)\n",
      "    electron_chi2: -0.6360 vs -0.6278 (diff: -0.0082, tanh(diff²): 0.0001)\n",
      "    electron_numberDoF: -0.6369 vs -0.6291 (diff: -0.0078, tanh(diff²): 0.0001)\n",
      "    electron_f1: -0.5941 vs -0.5875 (diff: -0.0066, tanh(diff²): 0.0000)\n",
      "    electron_f3: -0.4227 vs -0.4188 (diff: -0.0039, tanh(diff²): 0.0000)\n",
      "    electron_z: 0.0003 vs 0.0002 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0001\n",
      "    Top error features: electron_z0 (0.0011), electron_time (0.0002), electron_pt (0.0001)\n",
      "\n",
      "  Electron #3:\n",
      "    electron_E: -0.6366 vs -0.6293 (diff: -0.0073, tanh(diff²): 0.0001)\n",
      "    electron_pt: -0.6367 vs -0.6283 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_eta: -0.0015 vs -0.0007 (diff: -0.0007, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0127 (diff: 0.0127, tanh(diff²): 0.0002)\n",
      "    electron_d0: 0.0000 vs -0.0015 (diff: 0.0015, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0324 (diff: -0.0324, tanh(diff²): 0.0011)\n",
      "    electron_dpt: 0.0000 vs 0.0003 (diff: -0.0003, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5843 (diff: -0.0074, tanh(diff²): 0.0001)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2946 (diff: -0.0032, tanh(diff²): 0.0000)\n",
      "    electron_chi2: -0.6360 vs -0.6278 (diff: -0.0082, tanh(diff²): 0.0001)\n",
      "    electron_numberDoF: -0.6369 vs -0.6291 (diff: -0.0078, tanh(diff²): 0.0001)\n",
      "    electron_f1: -0.5941 vs -0.5875 (diff: -0.0066, tanh(diff²): 0.0000)\n",
      "    electron_f3: -0.4227 vs -0.4188 (diff: -0.0039, tanh(diff²): 0.0000)\n",
      "    electron_z: 0.0003 vs 0.0002 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0001\n",
      "    Top error features: electron_z0 (0.0011), electron_time (0.0002), electron_pt (0.0001)\n",
      "\n",
      "  Electron #4:\n",
      "    electron_E: -0.6366 vs -0.6293 (diff: -0.0073, tanh(diff²): 0.0001)\n",
      "    electron_pt: -0.6367 vs -0.6283 (diff: -0.0083, tanh(diff²): 0.0001)\n",
      "    electron_eta: -0.0015 vs -0.0007 (diff: -0.0007, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0127 (diff: 0.0127, tanh(diff²): 0.0002)\n",
      "    electron_d0: 0.0000 vs -0.0015 (diff: 0.0015, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0324 (diff: -0.0324, tanh(diff²): 0.0011)\n",
      "    electron_dpt: 0.0000 vs 0.0003 (diff: -0.0003, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5843 (diff: -0.0074, tanh(diff²): 0.0001)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2946 (diff: -0.0032, tanh(diff²): 0.0000)\n",
      "    electron_chi2: -0.6360 vs -0.6278 (diff: -0.0082, tanh(diff²): 0.0001)\n",
      "    electron_numberDoF: -0.6369 vs -0.6291 (diff: -0.0078, tanh(diff²): 0.0001)\n",
      "    electron_f1: -0.5941 vs -0.5875 (diff: -0.0066, tanh(diff²): 0.0000)\n",
      "    electron_f3: -0.4227 vs -0.4188 (diff: -0.0039, tanh(diff²): 0.0000)\n",
      "    electron_z: 0.0003 vs 0.0002 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0001\n",
      "    Top error features: electron_z0 (0.0011), electron_time (0.0002), electron_pt (0.0001)\n",
      "\n",
      "  Overall mean electron tanh(diff²): 0.0001\n",
      "\n",
      "  PHOTONS (actual vs predicted):\n",
      "  Photon #1:\n",
      "    photon_E: 1.9128 vs 1.8630 (diff: 0.0497, tanh(diff²): 0.0025)\n",
      "    photon_pt: 4.5755 vs 0.9976 (diff: 3.5779, tanh(diff²): 1.0000)\n",
      "    photon_eta: 0.9973 vs 0.9895 (diff: 0.0078, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9975 vs 1.0064 (diff: -0.0089, tanh(diff²): 0.0001)\n",
      "    photon_time: -0.1021 vs 0.0534 (diff: -0.1555, tanh(diff²): 0.0242)\n",
      "    photon_maxEcell_E: 1.9920 vs 1.0109 (diff: 0.9811, tanh(diff²): 0.7454)\n",
      "    photon_f1: 1.2576 vs 1.6237 (diff: -0.3661, tanh(diff²): 0.1332)\n",
      "    photon_f3: 0.4288 vs 0.8971 (diff: -0.4683, tanh(diff²): 0.2159)\n",
      "    photon_r1: 1.9486 vs 1.8180 (diff: 0.1306, tanh(diff²): 0.0171)\n",
      "    photon_r2: 1.9374 vs 1.8170 (diff: 0.1205, tanh(diff²): 0.0145)\n",
      "    photon_etas1: 1.0865 vs 0.0003 (diff: 1.0862, tanh(diff²): 0.8274)\n",
      "    photon_phis1: 1.5897 vs 0.0057 (diff: 1.5840, tanh(diff²): 0.9869)\n",
      "    photon_z: 0.0014 vs 0.0019 (diff: -0.0004, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.3052\n",
      "    Top error features: photon_pt (1.0000), photon_phis1 (0.9869), photon_etas1 (0.8274)\n",
      "\n",
      "  Photon #2:\n",
      "    photon_E: 1.9140 vs 1.8608 (diff: 0.0533, tanh(diff²): 0.0028)\n",
      "    photon_pt: 1.7756 vs 0.9828 (diff: 0.7927, tanh(diff²): 0.5570)\n",
      "    photon_eta: 0.9994 vs 0.9901 (diff: 0.0093, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9914 vs 0.9930 (diff: -0.0016, tanh(diff²): 0.0000)\n",
      "    photon_time: -0.5412 vs -0.2088 (diff: -0.3325, tanh(diff²): 0.1101)\n",
      "    photon_maxEcell_E: 2.9357 vs 0.9954 (diff: 1.9403, tanh(diff²): 0.9989)\n",
      "    photon_f1: 0.2352 vs 1.6142 (diff: -1.3789, tanh(diff²): 0.9564)\n",
      "    photon_f3: 5.9245 vs 0.8857 (diff: 5.0388, tanh(diff²): 1.0000)\n",
      "    photon_r1: 0.9279 vs 1.8111 (diff: -0.8832, tanh(diff²): 0.6527)\n",
      "    photon_r2: 0.8647 vs 1.8021 (diff: -0.9374, tanh(diff²): 0.7058)\n",
      "    photon_etas1: 2.1141 vs -0.0004 (diff: 2.1145, tanh(diff²): 0.9997)\n",
      "    photon_phis1: -0.9734 vs 0.0060 (diff: -0.9794, tanh(diff²): 0.7439)\n",
      "    photon_z: -0.0775 vs 0.0087 (diff: -0.0862, tanh(diff²): 0.0074)\n",
      "    Mean tanh(diff²) for this photon: 0.5181\n",
      "    Top error features: photon_f3 (1.0000), photon_etas1 (0.9997), photon_maxEcell_E (0.9989)\n",
      "\n",
      "  Photon #3:\n",
      "    photon_E: 1.8352 vs 1.8026 (diff: 0.0326, tanh(diff²): 0.0011)\n",
      "    photon_pt: 0.1349 vs 0.1625 (diff: -0.0276, tanh(diff²): 0.0008)\n",
      "    photon_eta: 0.9920 vs 0.9962 (diff: -0.0042, tanh(diff²): 0.0000)\n",
      "    photon_phi: 0.9927 vs 1.0355 (diff: -0.0428, tanh(diff²): 0.0018)\n",
      "    photon_time: -9999.0000 vs -9999.1924 (diff: 0.1924, tanh(diff²): 0.0370)\n",
      "    photon_maxEcell_E: -0.1405 vs 0.0931 (diff: -0.2335, tanh(diff²): 0.0545)\n",
      "    photon_f1: 3.4724 vs 1.9246 (diff: 1.5477, tanh(diff²): 0.9835)\n",
      "    photon_f3: -0.4264 vs 1.1694 (diff: -1.5957, tanh(diff²): 0.9878)\n",
      "    photon_r1: 2.0780 vs 1.8896 (diff: 0.1884, tanh(diff²): 0.0355)\n",
      "    photon_r2: 2.0076 vs 1.9187 (diff: 0.0889, tanh(diff²): 0.0079)\n",
      "    photon_etas1: -1.5685 vs -0.3441 (diff: -1.2244, tanh(diff²): 0.9050)\n",
      "    photon_phis1: -0.4221 vs -0.0305 (diff: -0.3916, tanh(diff²): 0.1522)\n",
      "    photon_z: -0.0156 vs 0.0464 (diff: -0.0620, tanh(diff²): 0.0038)\n",
      "    Mean tanh(diff²) for this photon: 0.2439\n",
      "    Top error features: photon_f3 (0.9878), photon_f1 (0.9835), photon_etas1 (0.9050)\n",
      "\n",
      "  Photon #4:\n",
      "    photon_E: 1.8296 vs 1.8604 (diff: -0.0308, tanh(diff²): 0.0009)\n",
      "    photon_pt: 0.1319 vs 0.9788 (diff: -0.8469, tanh(diff²): 0.6152)\n",
      "    photon_eta: 0.9982 vs 0.9904 (diff: 0.0078, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9903 vs 0.9892 (diff: 0.0011, tanh(diff²): 0.0000)\n",
      "    photon_time: -0.6257 vs -0.2782 (diff: -0.3476, tanh(diff²): 0.1202)\n",
      "    photon_maxEcell_E: 0.0043 vs 0.9912 (diff: -0.9869, tanh(diff²): 0.7504)\n",
      "    photon_f1: 2.3244 vs 1.6117 (diff: 0.7127, tanh(diff²): 0.4684)\n",
      "    photon_f3: 5.5288 vs 0.8826 (diff: 4.6462, tanh(diff²): 1.0000)\n",
      "    photon_r1: 2.2347 vs 1.8094 (diff: 0.4253, tanh(diff²): 0.1789)\n",
      "    photon_r2: 2.1327 vs 1.7983 (diff: 0.3344, tanh(diff²): 0.1114)\n",
      "    photon_etas1: 1.5166 vs -0.0006 (diff: 1.5172, tanh(diff²): 0.9802)\n",
      "    photon_phis1: -1.4269 vs 0.0060 (diff: -1.4329, tanh(diff²): 0.9676)\n",
      "    photon_z: -0.0146 vs 0.0106 (diff: -0.0251, tanh(diff²): 0.0006)\n",
      "    Mean tanh(diff²) for this photon: 0.3995\n",
      "    Top error features: photon_f3 (1.0000), photon_etas1 (0.9802), photon_phis1 (0.9676)\n",
      "\n",
      "  Overall mean photon tanh(diff²): 0.3667\n",
      "\n",
      "  Total event mean tanh(diff²): 0.1703\n",
      "  Compare with event score: 0.156756\n",
      "\n",
      "Event 3 (index 92763): Score = 0.154041\n",
      "  Vertex position: [-0.6655843 -1.5432374  1.1810405]\n",
      "  Number of electrons: 4\n",
      "  Number of photons: 4\n",
      "\n",
      "  ELECTRONS (actual vs predicted):\n",
      "  Electron #1:\n",
      "    electron_E: 1.4578 vs 1.5142 (diff: -0.0564, tanh(diff²): 0.0032)\n",
      "    electron_pt: 1.4054 vs 1.5252 (diff: -0.1198, tanh(diff²): 0.0144)\n",
      "    electron_eta: -0.5300 vs 0.0050 (diff: -0.5350, tanh(diff²): 0.2786)\n",
      "    electron_phi: -0.3936 vs -0.0074 (diff: -0.3862, tanh(diff²): 0.1481)\n",
      "    electron_time: 0.1248 vs -0.6718 (diff: 0.7966, tanh(diff²): 0.5612)\n",
      "    electron_d0: 0.0171 vs -0.0460 (diff: 0.0631, tanh(diff²): 0.0040)\n",
      "    electron_z0: 36.7209 vs 38.5054 (diff: -1.7845, tanh(diff²): 0.9966)\n",
      "    electron_dpt: -0.1309 vs -0.1677 (diff: 0.0368, tanh(diff²): 0.0014)\n",
      "    electron_nPIX: 2.1944 vs 1.3800 (diff: 0.8144, tanh(diff²): 0.5805)\n",
      "    electron_nMissingLayers: -0.2978 vs 0.7330 (diff: -1.0308, tanh(diff²): 0.7867)\n",
      "    electron_chi2: 1.4306 vs 1.5251 (diff: -0.0945, tanh(diff²): 0.0089)\n",
      "    electron_numberDoF: 1.6096 vs 1.4943 (diff: 0.1153, tanh(diff²): 0.0133)\n",
      "    electron_f1: 0.0048 vs 1.3692 (diff: -1.3644, tanh(diff²): 0.9528)\n",
      "    electron_f3: 0.5622 vs 1.0076 (diff: -0.4455, tanh(diff²): 0.1959)\n",
      "    electron_z: -0.0423 vs -0.0070 (diff: -0.0353, tanh(diff²): 0.0012)\n",
      "    Mean tanh(diff²) for this electron: 0.3031\n",
      "    Top error features: electron_z0 (0.9966), electron_f1 (0.9528), electron_nMissingLayers (0.7867)\n",
      "\n",
      "  Electron #2:\n",
      "    electron_E: -0.6366 vs -0.6179 (diff: -0.0186, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6157 (diff: -0.0210, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0524 (diff: 0.0524, tanh(diff²): 0.0027)\n",
      "    electron_d0: 0.0000 vs -0.0012 (diff: 0.0012, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0961 (diff: -0.0961, tanh(diff²): 0.0092)\n",
      "    electron_dpt: 0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5724 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2894 (diff: -0.0085, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6150 (diff: -0.0211, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6176 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5766 (diff: -0.0176, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4108 (diff: -0.0119, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0010\n",
      "    Top error features: electron_z0 (0.0092), electron_time (0.0027), electron_chi2 (0.0004)\n",
      "\n",
      "  Electron #3:\n",
      "    electron_E: -0.6366 vs -0.6179 (diff: -0.0186, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6157 (diff: -0.0210, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0524 (diff: 0.0524, tanh(diff²): 0.0027)\n",
      "    electron_d0: 0.0000 vs -0.0012 (diff: 0.0012, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0961 (diff: -0.0961, tanh(diff²): 0.0092)\n",
      "    electron_dpt: 0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5724 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2894 (diff: -0.0085, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6150 (diff: -0.0211, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6176 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5766 (diff: -0.0176, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4108 (diff: -0.0119, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0010\n",
      "    Top error features: electron_z0 (0.0092), electron_time (0.0027), electron_chi2 (0.0004)\n",
      "\n",
      "  Electron #4:\n",
      "    electron_E: -0.6366 vs -0.6179 (diff: -0.0186, tanh(diff²): 0.0003)\n",
      "    electron_pt: -0.6367 vs -0.6157 (diff: -0.0210, tanh(diff²): 0.0004)\n",
      "    electron_eta: -0.0015 vs -0.0005 (diff: -0.0010, tanh(diff²): 0.0000)\n",
      "    electron_phi: -0.0000 vs -0.0003 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    electron_time: 0.0000 vs -0.0524 (diff: 0.0524, tanh(diff²): 0.0027)\n",
      "    electron_d0: 0.0000 vs -0.0012 (diff: 0.0012, tanh(diff²): 0.0000)\n",
      "    electron_z0: 0.0000 vs 0.0961 (diff: -0.0961, tanh(diff²): 0.0092)\n",
      "    electron_dpt: 0.0000 vs -0.0001 (diff: 0.0001, tanh(diff²): 0.0000)\n",
      "    electron_nPIX: -0.5917 vs -0.5724 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_nMissingLayers: -0.2978 vs -0.2894 (diff: -0.0085, tanh(diff²): 0.0001)\n",
      "    electron_chi2: -0.6360 vs -0.6150 (diff: -0.0211, tanh(diff²): 0.0004)\n",
      "    electron_numberDoF: -0.6369 vs -0.6176 (diff: -0.0193, tanh(diff²): 0.0004)\n",
      "    electron_f1: -0.5941 vs -0.5766 (diff: -0.0176, tanh(diff²): 0.0003)\n",
      "    electron_f3: -0.4227 vs -0.4108 (diff: -0.0119, tanh(diff²): 0.0001)\n",
      "    electron_z: 0.0003 vs -0.0002 (diff: 0.0005, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this electron: 0.0010\n",
      "    Top error features: electron_z0 (0.0092), electron_time (0.0027), electron_chi2 (0.0004)\n",
      "\n",
      "  Overall mean electron tanh(diff²): 0.0765\n",
      "\n",
      "  PHOTONS (actual vs predicted):\n",
      "  Photon #1:\n",
      "    photon_E: 1.9135 vs 1.8624 (diff: 0.0511, tanh(diff²): 0.0026)\n",
      "    photon_pt: 2.0932 vs 1.0020 (diff: 1.0913, tanh(diff²): 0.8308)\n",
      "    photon_eta: 0.9989 vs 0.9889 (diff: 0.0101, tanh(diff²): 0.0001)\n",
      "    photon_phi: 0.9892 vs 1.0113 (diff: -0.0221, tanh(diff²): 0.0005)\n",
      "    photon_time: -0.2502 vs 0.1167 (diff: -0.3670, tanh(diff²): 0.1339)\n",
      "    photon_maxEcell_E: 5.1036 vs 1.0154 (diff: 4.0883, tanh(diff²): 1.0000)\n",
      "    photon_f1: 0.7522 vs 1.6260 (diff: -0.8738, tanh(diff²): 0.6431)\n",
      "    photon_f3: 1.6900 vs 0.9004 (diff: 0.7896, tanh(diff²): 0.5535)\n",
      "    photon_r1: 1.3438 vs 1.8189 (diff: -0.4751, tanh(diff²): 0.2220)\n",
      "    photon_r2: 1.2877 vs 1.8204 (diff: -0.5328, tanh(diff²): 0.2765)\n",
      "    photon_etas1: 1.8754 vs 0.0005 (diff: 1.8749, tanh(diff²): 0.9982)\n",
      "    photon_phis1: -1.9150 vs 0.0057 (diff: -1.9207, tanh(diff²): 0.9988)\n",
      "    photon_z: -0.0024 vs -0.0004 (diff: -0.0020, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.4354\n",
      "    Top error features: photon_maxEcell_E (1.0000), photon_phis1 (0.9988), photon_etas1 (0.9982)\n",
      "\n",
      "  Photon #2:\n",
      "    photon_E: 1.8552 vs 1.8604 (diff: -0.0052, tanh(diff²): 0.0000)\n",
      "    photon_pt: 0.5834 vs 0.9850 (diff: -0.4015, tanh(diff²): 0.1598)\n",
      "    photon_eta: 0.9957 vs 0.9898 (diff: 0.0059, tanh(diff²): 0.0000)\n",
      "    photon_phi: 0.9971 vs 0.9954 (diff: 0.0017, tanh(diff²): 0.0000)\n",
      "    photon_time: -0.2421 vs -0.1786 (diff: -0.0635, tanh(diff²): 0.0040)\n",
      "    photon_maxEcell_E: 0.2071 vs 0.9976 (diff: -0.7905, tanh(diff²): 0.5545)\n",
      "    photon_f1: 2.6775 vs 1.6152 (diff: 1.0622, tanh(diff²): 0.8104)\n",
      "    photon_f3: 0.3594 vs 0.8873 (diff: -0.5278, tanh(diff²): 0.2716)\n",
      "    photon_r1: 1.9943 vs 1.8114 (diff: 0.1828, tanh(diff²): 0.0334)\n",
      "    photon_r2: 2.0447 vs 1.8038 (diff: 0.2409, tanh(diff²): 0.0580)\n",
      "    photon_etas1: 0.2590 vs -0.0003 (diff: 0.2593, tanh(diff²): 0.0671)\n",
      "    photon_phis1: 1.4194 vs 0.0060 (diff: 1.4134, tanh(diff²): 0.9639)\n",
      "    photon_z: 0.0059 vs 0.0075 (diff: -0.0017, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.2248\n",
      "    Top error features: photon_phis1 (0.9639), photon_f1 (0.8104), photon_maxEcell_E (0.5545)\n",
      "\n",
      "  Photon #3:\n",
      "    photon_E: 1.8602 vs 1.8697 (diff: -0.0095, tanh(diff²): 0.0001)\n",
      "    photon_pt: 0.1508 vs 1.0544 (diff: -0.9036, tanh(diff²): 0.6731)\n",
      "    photon_eta: 0.9989 vs 0.9863 (diff: 0.0126, tanh(diff²): 0.0002)\n",
      "    photon_phi: 0.9891 vs 1.0591 (diff: -0.0700, tanh(diff²): 0.0049)\n",
      "    photon_time: 1.5535 vs 1.0506 (diff: 0.5029, tanh(diff²): 0.2477)\n",
      "    photon_maxEcell_E: 0.0872 vs 1.0704 (diff: -0.9833, tanh(diff²): 0.7473)\n",
      "    photon_f1: 3.1438 vs 1.6594 (diff: 1.4844, tanh(diff²): 0.9759)\n",
      "    photon_f3: 1.6410 vs 0.9411 (diff: 0.7000, tanh(diff²): 0.4542)\n",
      "    photon_r1: 1.4087 vs 1.8431 (diff: -0.4344, tanh(diff²): 0.1865)\n",
      "    photon_r2: 1.3425 vs 1.8728 (diff: -0.5304, tanh(diff²): 0.2741)\n",
      "    photon_etas1: 1.8434 vs 0.0029 (diff: 1.8405, tanh(diff²): 0.9977)\n",
      "    photon_phis1: -1.9400 vs 0.0049 (diff: -1.9449, tanh(diff²): 0.9990)\n",
      "    photon_z: -0.0198 vs -0.0248 (diff: 0.0049, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.4277\n",
      "    Top error features: photon_phis1 (0.9990), photon_etas1 (0.9977), photon_f1 (0.9759)\n",
      "\n",
      "  Photon #4:\n",
      "    photon_E: -0.5367 vs -0.5370 (diff: 0.0003, tanh(diff²): 0.0000)\n",
      "    photon_pt: -0.0053 vs -0.0035 (diff: -0.0018, tanh(diff²): 0.0000)\n",
      "    photon_eta: 0.9951 vs 0.9981 (diff: -0.0030, tanh(diff²): 0.0000)\n",
      "    photon_phi: 0.9937 vs 0.9953 (diff: -0.0015, tanh(diff²): 0.0000)\n",
      "    photon_time: 0.0000 vs 0.0159 (diff: -0.0159, tanh(diff²): 0.0003)\n",
      "    photon_maxEcell_E: -0.2646 vs -0.2582 (diff: -0.0063, tanh(diff²): 0.0000)\n",
      "    photon_f1: -0.4895 vs -0.4888 (diff: -0.0008, tanh(diff²): 0.0000)\n",
      "    photon_f3: -0.2691 vs -0.2678 (diff: -0.0014, tanh(diff²): 0.0000)\n",
      "    photon_r1: -0.5299 vs -0.5297 (diff: -0.0002, tanh(diff²): 0.0000)\n",
      "    photon_r2: -0.5291 vs -0.5299 (diff: 0.0008, tanh(diff²): 0.0000)\n",
      "    photon_etas1: 0.0004 vs 0.0011 (diff: -0.0008, tanh(diff²): 0.0000)\n",
      "    photon_phis1: 0.0010 vs 0.0004 (diff: 0.0006, tanh(diff²): 0.0000)\n",
      "    photon_z: 0.0002 vs -0.0000 (diff: 0.0002, tanh(diff²): 0.0000)\n",
      "    Mean tanh(diff²) for this photon: 0.0000\n",
      "    Top error features: photon_time (0.0003), photon_maxEcell_E (0.0000), photon_eta (0.0000)\n",
      "\n",
      "  Overall mean photon tanh(diff²): 0.2720\n",
      "\n",
      "  Total event mean tanh(diff²): 0.1673\n",
      "  Compare with event score: 0.154041\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "# Display highest scoring background events\n",
    "background_indices = np.where(all_labels == 0)[0]\n",
    "background_only_scores = all_scores[background_indices]\n",
    "display_highest_score_events(\n",
    "    model,\n",
    "    test_electron_features,\n",
    "    test_photon_features,\n",
    "    test_vertices,\n",
    "    background_only_scores,\n",
    "    n_events=3,\n",
    "    dataset_name=\"Background\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store per-model results\n",
    "model_results = {}\n",
    "\n",
    "# Get list of unique models\n",
    "unique_models = np.unique(signal_models)\n",
    "print(f\"Analyzing {len(unique_models)} unique signal models...\")\n",
    "\n",
    "# Perform analysis for each model separately\n",
    "for model_name in unique_models:\n",
    "    # Get mask for this model\n",
    "    model_mask = signal_models == model_name\n",
    "    \n",
    "    # Get scores for this model only\n",
    "    model_scores = signal_scores[model_mask]\n",
    "    \n",
    "    # Create model-specific labels\n",
    "    model_labels = np.ones(len(model_scores))\n",
    "    \n",
    "    # Combine with test data for ROC calculation\n",
    "    model_all_scores = np.concatenate([test_scores, model_scores])\n",
    "    model_all_labels = np.concatenate([test_labels, model_labels])\n",
    "    \n",
    "    # Calculate model-specific ROC\n",
    "    model_fpr, model_tpr, model_thresholds = roc_curve(model_all_labels, model_all_scores)\n",
    "    model_roc_auc = auc(model_fpr, model_tpr)\n",
    "    \n",
    "    # Parse parameters from model name\n",
    "    parts = model_name.split('_')\n",
    "    mass1 = int(parts[0])\n",
    "    mass2 = int(parts[1])\n",
    "    \n",
    "    # Handle lifetime format (convert 0p1ns to 0.1)\n",
    "    lifetime_str = parts[2].replace('ns', '')\n",
    "    lifetime = float(lifetime_str.replace('p', '.'))\n",
    "    \n",
    "    # Calculate statistics for this model\n",
    "    model_results[model_name] = {\n",
    "        'num_events': np.sum(model_mask),\n",
    "        'mean_score': np.mean(model_scores),\n",
    "        'scores': model_scores,\n",
    "        'roc_auc': model_roc_auc,\n",
    "        'mass1': mass1,\n",
    "        'mass2': mass2,\n",
    "        'lifetime': lifetime\n",
    "    }\n",
    "    \n",
    "    print(f\"Model {model_name}: {np.sum(model_mask)} events, ROC AUC = {model_roc_auc:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = []\n",
    "for model_name, results in model_results.items():\n",
    "    model_params.append({\n",
    "        'name': model_name,\n",
    "        'mass1': results['mass1'],\n",
    "        'mass2': results['mass2'],\n",
    "        'lifetime': results['lifetime'],\n",
    "        'roc_auc': results['roc_auc'],\n",
    "        'mean_score': results['mean_score'],\n",
    "        'num_events': results['num_events']\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "params_df = pd.DataFrame(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Distribution of anomaly scores by lifetime\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot background distribution first\n",
    "plt.hist(test_scores, bins=50, alpha=0.5, label='Background', density=True, color='gray')\n",
    "\n",
    "# Group models by lifetime\n",
    "lifetime_groups = {}\n",
    "for model_name, results in model_results.items():\n",
    "    lifetime = results['lifetime']\n",
    "    if lifetime not in lifetime_groups:\n",
    "        lifetime_groups[lifetime] = []\n",
    "    lifetime_groups[lifetime].extend(results['scores'])\n",
    "\n",
    "# Use a colormap to distinguish different lifetimes\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(lifetime_groups)))\n",
    "\n",
    "# Plot score distribution for each lifetime\n",
    "for (lifetime, scores), color in zip(lifetime_groups.items(), colors):\n",
    "    if len(scores) > 10:\n",
    "        plt.hist(\n",
    "            scores, \n",
    "            bins=50, \n",
    "            alpha=0.4, \n",
    "            density=True,\n",
    "            color=color,\n",
    "            label=f'Lifetime = {lifetime}ns'\n",
    "        )\n",
    "\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Anomaly Scores by Lifetime')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Distribution of anomaly scores by mass combination\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot background distribution first\n",
    "plt.hist(test_scores, bins=50, alpha=0.5, label='Background', density=True, color='gray')\n",
    "\n",
    "# Group models by mass combination\n",
    "mass_groups = {}\n",
    "for model_name, results in model_results.items():\n",
    "    mass_key = f\"{results['mass1']}_{results['mass2']}\"\n",
    "    if mass_key not in mass_groups:\n",
    "        mass_groups[mass_key] = []\n",
    "    mass_groups[mass_key].extend(results['scores'])\n",
    "\n",
    "# Use a colormap to distinguish different mass combinations\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(mass_groups)))\n",
    "\n",
    "# Plot score distribution for each mass combination\n",
    "for (mass_key, scores), color in zip(mass_groups.items(), colors):\n",
    "    if len(scores) > 10:\n",
    "        plt.hist(\n",
    "            scores, \n",
    "            bins=50, \n",
    "            alpha=0.4, \n",
    "            density=True,\n",
    "            color=color,\n",
    "            label=f'Mass = {mass_key} GeV'\n",
    "        )\n",
    "\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Anomaly Scores by Mass Combination')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Distribution of anomaly scores by model\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot background distribution first\n",
    "plt.hist(test_scores, bins=50, alpha=0.5, label='Background', density=True, color='gray')\n",
    "\n",
    "# Use a colormap to distinguish different models\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(model_results)))\n",
    "\n",
    "# Plot score distribution for each model\n",
    "for (model_name, results), color in zip(model_results.items(), colors):\n",
    "    scores = results['scores']\n",
    "    if len(scores) > 10:\n",
    "        plt.hist(\n",
    "            scores, \n",
    "            bins=50, \n",
    "            alpha=0.3, \n",
    "            density=True,\n",
    "            color=color,\n",
    "            label=model_name\n",
    "        )\n",
    "\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Anomaly Scores by Model')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_correlations(scores, e_feats, p_feats, method='pearson'):\n",
    "    \"\"\"\n",
    "    Calculate correlations between anomaly scores and each feature.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scores: numpy array of anomaly scores\n",
    "    e_feats: electron features (shape: [n_events, n_electrons, n_features])\n",
    "    p_feats: photon features (shape: [n_events, n_photons, n_features])\n",
    "    method: correlation method ('pearson' or 'spearman')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dictionary with correlations for electron and photon features\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'electron': [],\n",
    "        'photon': []\n",
    "    }\n",
    "    \n",
    "    # Define correlation function based on method\n",
    "    if method == 'pearson':\n",
    "        corr_func = pearsonr\n",
    "    else:  # spearman\n",
    "        corr_func = spearmanr\n",
    "    \n",
    "    # Calculate for electron features\n",
    "    for feat_idx in range(e_feats.shape[2]):\n",
    "        # Average feature value across all electrons in each event\n",
    "        feat_values = np.mean(e_feats[:, :, feat_idx], axis=1)\n",
    "        # Only consider events where feature exists (non-zero)\n",
    "        mask = ~np.isnan(feat_values) & (np.abs(feat_values) > 1e-10)\n",
    "        \n",
    "        if np.sum(mask) > 10:  # Need enough data points\n",
    "            corr, p_value = corr_func(scores[mask], feat_values[mask])\n",
    "            results['electron'].append({\n",
    "                'feature_idx': feat_idx,\n",
    "                'correlation': corr,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "    \n",
    "    # Calculate for photon features\n",
    "    for feat_idx in range(p_feats.shape[2]):\n",
    "        # Average feature value across all photons in each event\n",
    "        feat_values = np.mean(p_feats[:, :, feat_idx], axis=1)\n",
    "        # Only consider events where feature exists (non-zero)\n",
    "        mask = ~np.isnan(feat_values) & (np.abs(feat_values) > 1e-10)\n",
    "        \n",
    "        if np.sum(mask) > 10:  # Need enough data points\n",
    "            corr, p_value = corr_func(scores[mask], feat_values[mask])\n",
    "            results['photon'].append({\n",
    "                'feature_idx': feat_idx,\n",
    "                'correlation': corr,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_correlation_results(correlation_results, e_feat_names=None, p_feat_names=None):\n",
    "    \"\"\"\n",
    "    Plot correlation results between scores and features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    correlation_results: Output from calculate_feature_correlations\n",
    "    e_feat_names: List of electron feature names (optional)\n",
    "    p_feat_names: List of photon feature names (optional)\n",
    "    \"\"\"\n",
    "    # Prepare data for plotting\n",
    "    e_corrs = pd.DataFrame(correlation_results['electron'])\n",
    "    p_corrs = pd.DataFrame(correlation_results['photon'])\n",
    "    \n",
    "    # Add feature names if provided\n",
    "    if e_feat_names:\n",
    "        e_corrs['feature_name'] = e_corrs['feature_idx'].apply(lambda x: e_feat_names[x])\n",
    "    else:\n",
    "        e_corrs['feature_name'] = e_corrs['feature_idx'].apply(lambda x: f\"Electron_{x}\")\n",
    "        \n",
    "    if p_feat_names:\n",
    "        p_corrs['feature_name'] = p_corrs['feature_idx'].apply(lambda x: p_feat_names[x])\n",
    "    else:\n",
    "        p_corrs['feature_name'] = p_corrs['feature_idx'].apply(lambda x: f\"Photon_{x}\")\n",
    "    \n",
    "    # Sort by absolute correlation\n",
    "    e_corrs['abs_corr'] = np.abs(e_corrs['correlation'])\n",
    "    p_corrs['abs_corr'] = np.abs(p_corrs['correlation'])\n",
    "    e_corrs = e_corrs.sort_values('abs_corr', ascending=False)\n",
    "    p_corrs = p_corrs.sort_values('abs_corr', ascending=False)\n",
    "    \n",
    "    # Plot electron correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(x='feature_name', y='correlation', data=e_corrs)\n",
    "    plt.title('Correlation Between Anomaly Score and Electron Features')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('electron_feature_correlations.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot photon correlations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(x='feature_name', y='correlation', data=p_corrs)\n",
    "    plt.title('Correlation Between Anomaly Score and Photon Features')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('photon_feature_correlations.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top correlations\n",
    "    print(\"\\nTop electron feature correlations:\")\n",
    "    for _, row in e_corrs.iloc[:10].iterrows():\n",
    "        print(f\"  {row['feature_name']} (idx {row['feature_idx']}): {row['correlation']:.4f} (p={row['p_value']:.4e})\")\n",
    "    \n",
    "    print(\"\\nTop photon feature correlations:\")\n",
    "    for _, row in p_corrs.iloc[:10].iterrows():\n",
    "        print(f\"  {row['feature_name']} (idx {row['feature_idx']}): {row['correlation']:.4f} (p={row['p_value']:.4e})\")\n",
    "    \n",
    "    return e_corrs, p_corrs\n",
    "\n",
    "# Define feature names (from README)\n",
    "electron_features_list = [\n",
    "    'electron_E', 'electron_pt', 'electron_eta', 'electron_phi',\n",
    "    'electron_time', 'electron_d0', 'electron_z0', 'electron_dpt',\n",
    "    'electron_nPIX', 'electron_nMissingLayers', 'electron_chi2', \n",
    "    'electron_numberDoF', 'electron_f1', 'electron_f3', 'electron_z'\n",
    "]\n",
    "\n",
    "photon_features_list = [\n",
    "    'photon_E', 'photon_pt', 'photon_eta', 'photon_phi',\n",
    "    'photon_time', 'photon_maxEcell_E', 'photon_f1', 'photon_f3', \n",
    "    'photon_r1', 'photon_r2', 'photon_etas1', 'photon_phis1', 'photon_z'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "# 1. Calculate correlations\n",
    "corr_results = calculate_feature_correlations(all_scores, \n",
    "                                             np.concatenate([test_electron_features, signal_electron_features]), \n",
    "                                             np.concatenate([test_photon_features, signal_photon_features]), \n",
    "                                             method='spearman')\n",
    "\n",
    "# 2. Plot correlation results\n",
    "e_corrs, p_corrs = plot_correlation_results(corr_results, \n",
    "                                           electron_features_list, \n",
    "                                           photon_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_electron_pt_distributions(e_feats, background_mask):\n",
    "    \"\"\"\n",
    "    Create 1D histograms of pT for all 4 electrons in background events.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    e_feats: Electron features array [events, electrons, features]\n",
    "    background_mask: Boolean mask for background events\n",
    "    \"\"\"\n",
    "    # PT index in feature arrays\n",
    "    pt_idx = 1  # Electron pt is at index 1\n",
    "    \n",
    "    # Create a figure with 4 subplots (one for each electron)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()  # Flatten for easier indexing\n",
    "    \n",
    "    # Plot PT distribution for each electron\n",
    "    for i in range(4):\n",
    "        # Extract pt for the i-th electron in each event\n",
    "        e_pt = e_feats[background_mask, i, pt_idx]\n",
    "        \n",
    "        # Filter out events where this electron doesn't exist (energy = 0)\n",
    "        valid_mask = e_feats[background_mask, i, 0] > 0  # Energy > 0\n",
    "        valid_e_pt = e_pt[valid_mask]\n",
    "        \n",
    "        # Only plot if we have enough data points\n",
    "        if len(valid_e_pt) > 10:\n",
    "            # Plot histogram\n",
    "            axes[i].hist(valid_e_pt, bins=50, alpha=0.75, color='blue')\n",
    "            \n",
    "            # Calculate and show basic statistics\n",
    "            mean_pt = np.mean(valid_e_pt)\n",
    "            median_pt = np.median(valid_e_pt)\n",
    "            std_pt = np.std(valid_e_pt)\n",
    "            \n",
    "            # Electron label based on index\n",
    "            if i == 0:\n",
    "                electron_label = \"Leading Electron\"\n",
    "            elif i == 1:\n",
    "                electron_label = \"Sub-leading Electron\"\n",
    "            elif i == 2:\n",
    "                electron_label = \"Third Electron\"\n",
    "            else:\n",
    "                electron_label = \"Fourth Electron\"\n",
    "                \n",
    "            axes[i].set_xlabel('Transverse Momentum (pT)')\n",
    "            axes[i].set_ylabel('Count')\n",
    "            axes[i].set_title(f'{electron_label} pT Distribution\\nMean: {mean_pt:.2f}, Median: {median_pt:.2f}, Std: {std_pt:.2f}')\n",
    "            axes[i].grid(alpha=0.3)\n",
    "            \n",
    "            # Add count of valid events\n",
    "            axes[i].text(0.95, 0.95, f'Events: {len(valid_e_pt)}',\n",
    "                       transform=axes[i].transAxes, \n",
    "                       horizontalalignment='right',\n",
    "                       verticalalignment='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "            \n",
    "            # Optional: set log scale for y-axis\n",
    "            axes[i].set_yscale('log')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, \"Insufficient data\", \n",
    "                       horizontalalignment='center', verticalalignment='center',\n",
    "                       transform=axes[i].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('electron_pt_distributions.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "background_mask = all_labels == 0  # Get only background events\n",
    "\n",
    "plot_electron_pt_distributions(\n",
    "    np.concatenate([test_electron_features, signal_electron_features]),\n",
    "    background_mask\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
